���# ru.lng
# ��������������������/����������������-->��������������
# -----------------------
# This is a part of YaCy, a peer-to-peer based web search engine
#
# (C) by Michael Peter Christen; mc@anomic.de
# first published on http://www.anomic.de
# Frankfurt, Germany, 2005
#
# Testing the new SVN Properties http://forum.yacy-websuche.de/viewtopic.php?f=15&t=2906
#
# $Revision::                                                $
# $Date::                                                    $
# $Tag::                                                     $
# $Author::                                                  $
# 
# This file is maintained by Oliver Wunder <webmaster@daburna.de>
# This file is written by (chronological order) Roland Ramthun <admin@yacy-forum.de>, Oliver Wunder <webmaster@daburna.de>, Jan Sandbrink,
# Thomas S���� <th-suess@gmx.de>

# If you find any mistakes or untranslated strings in this file please don't hesitate to email them to the maintainer.

#File: ConfigLanguage_p.html
#---------------------------
# Only part 1.
# Contributors are in chronological order, not how much they did absolutely.
# Thank you for your help!
<!-- lang -->default\(english\)==��������������
<!-- author -->==SEVEN, �������������� "Orion" ��������������
<!-- maintainer -->==&lt;icewind@hotmail.ru&gt;
#-----------------------------

#File: AccessGrid_p.html
#---------------------------
YaCy Network Access==������������ �� �������� YaCy
Server Access Grid==���������� ��������������������
This images shows incoming connections to your YaCy peer and outgoing connections from your peer to other peers and web servers==���������� ���������������� ���������������� �������������������� �� ������������ �������� �� ������������������ �������������������� ���� ������������ �������� �� ������������ ���������� �� ������-����������������.
#-----------------------------

#File: AccessTracker_p.html
#---------------------------
Access Tracker==������������ �� ��������������
Server Access Overview==������������������ �� ��������������
This is a list of \#\[num\]\# requests to the local http server within the last hour.==���������� ���������������� ���� ������������������ http-������������ �� �������������� �������������������� �������� - #[num]#
This is a list of requests to the local http server within the last hour.==������ ������������ ���������������� ���� ������������������ http-������������ �� �������������� ��������.
Showing \#\[num\]\# requests.==���������������� #[num]# ����������������.
>Host<==>��������<
>Path<==>��������<
Date<==��������<
Access Count During==�������������������� ����������������
last Second==������������������ ��������������
last Minute==������������������ ������������
last Minutes==������������������ 10 ����������
last Hour==������������������ ������
The following hosts are registered as source for brute-force requests to protected pages==������������������ ���������� ��������������������������������, ������ �������������������� ���������������� ������������ �� �������������������� ������������������ �� �������������� ���������������� ������������.
#>Host==>��������
Access Times==���������� ��������������
Server Access Details==������������������ ���������������� �� �������������� �� ��������������
Local Search Log==������ �������������������� ������������
Local Search Host Tracker==������������������ ���������� ���� ��������
Remote Search Log==������ �������������������� ������������
#Total:==����������:
Success:==��������������:
Remote Search Host Tracker==������������������ ���������� ���� ��������
This is a list of searches that had been requested from this\' peer search interface==������ ������������ ����������������, �������������������� ���� ������������ ������������������ ����������
Showing \#\[num\]\# entries from a total of \#\[total\]\# requests.==���������������� \#\[num\]\# ���� \#\[total\]\# ����������������.
Requesting Host==�������������������������� ��������
Offset==����������������
Expected Results==������������������ ��������������������
Returned Results==������������������ ��������������������
Used Time \(ms\)==��c������������������������ ���������� (�� ����)
URL fetch \(ms\)==URL �������������� (�� ����)
Snippet comp \(ms\)==���������������� ������������(�� ����)
Query==������������
#>User Agent<==>User Agent<
Search Word Hashes==���������� ���������� ���� ��������
Count</td>==��������������������</td>
Queries Per Last Hour==���������������� ���� ������������������ ������
Access Dates==���������� ��������������
This is a list of searches that had been requested from remote peer search interface==������ ������������ ������������������ ����������������, �������������� �������� ������������������ �������������������� ������������. 
#-----------------------------

#File: AugmentedBrowsing_p.html
#---------------------------
Augmented Browsing<==���������������������� ����������������<
URL Proxy Settings<==������������������ URL-������������<
With this settings you can activate or deactivate URL proxy which is the method used for augmentation.==������ ������������������ ������������������ ���������������� ������ ������������������ URL-������������ - ������������ ������������������������ ������ ������������������������ ������������������.
Service call: ==���������� ��������������: 
, where parameter is the url of an external web page.==, ������ ���������������� ������ ������������ ���� �������������� ������-����������������
>URL proxy:<==>URL-������������:<
>Enabled<==>����������������<
Globally enables or disables URL proxy via ==�������������������� ������������������ ������ �������������������� URL-������������ ���������� 
Show search results via URL proxy:==�������������������� �������������������� ������������ ���������� URL-������������:
Enables or disables URL proxy for all search results. If enabled, all search results will be tunneled through URL proxy.==������������������ ������ �������������������� URL-������������ ������ �������� ���������������������� ������������. �������� ����������������, ���� ������ �������������������� ������������ ���������� �������������������� ���������� URL-������������. 
Alternatively you may add this javascript to your browser favorites/short-cuts, which will reload the current browser address==�������������������������� ���� ������������ ���������������� �������� javascript �� ������������������ ����������������/���������������� ������������ ����������������, �������������� ���������� ������������������ �������������������������� ���������� 
via the YaCy proxy servlet.==���������� ������������-��������������.
or right-click this link and add to favorites:==������ �������������� ������������ �������������� �������� ���� ������ ������������ �� ���������������� �� ����������������: 
Restrict URL proxy use:==������������������ �������������������������� URL-������������ ������:
Define client filter. Default: ==������������ ������������ ������ ��������������. ����-������������������: 
URL substitution:==������������ ������������:
Define URL substitution rules which allow navigating in proxy environment. Possible values: all, domainlist. Default: domainlist.==������������ �������������� ������������ ������������, �������������� ���������������� ������������������ ���������� ������������. ������������������ ����������������: all, domainlist. ����-������������������: domainlist.
"Submit"=="������������������"
Augmented Browsing Settings==������������������ ������������������������ ������������������
With this settings you can activate or deactivate augmented browsing which happens usually via the URL proxy.==������ ������������������ ������������������ ������ ���������������� ������ ������������������ ���������������������� ���������������� ���������� URL-������������.
Augmented Browsing:==���������������������� ����������������:
#>Enabled<==>����������������<
Enables or disables augmented browsing. If enabled, all websites will be modified during loading.==������������������ ������ �������������������� ������������������������ ������������������. �������� ����������������, ���� ������ ������-���������������� ���������� �������������������� ���� ���������� ����������������.
#"Submit"=="������������������"
#-----------------------------

#File: AugmentedBrowsingFilters_p.html
#---------------------------
Augmented Browsing - Filters and Modules==���������������������� ���������������� - ������������ �� ������������
Augmented Browsing Filters<==�������������� ������������������������ ������������������<
Select the desired functionality.==���������������� ������������ ��������������������.
External REFLECT:<==�������������� REFLECT:<
>Enabled<==>����������������<
Send webpages to REFLECT \(==�������������������� ������-���������������� ���� REFLECT (
Select the desired inbuilt functionality==���������������� ������������ �������������������� ��������������������.
Add DOCTYPE:==���������������� DOCTYPE:
Add DOCTYPE information if not given. This is required for IE to render position:absolute correctly.==���������������� �������������������� DOCTYPE, �������� ���� ������������. ������ ���������� �������������������������� ������ ������������������ �������������� ���������� Internet Explorer.
Reparse webpage:==������������������ ������������������ ������-����������������:
Put webpage back into schema \(htmlparser document\) to allow node by node manipulation.==Setze Webseite zur��ck ins Schema (htmlpaser Dokuement), um Knoten bei Knoten Manipulation zu erm��glichen.
Show overlay interaction buttons:==Zeige Overlay Schaltfl��chen zur Interaktion:
Show overlay interaction buttons.==Zeige Overlay Schaltfl��chen zur Interaktion.
"Submit"=="������������������"
#-----------------------------

#File: AugmentedParsing_p.html
#---------------------------
Augmented Parsing<==���������������������� ������������<
Global Status==�������������������� ������������
With this settings you can activate or deactivate augmented parsing which combines the documents with information from external sources \(tags etc.\).==������ ������������������ ������������������ ���������������� ������ ������������������ ���������������������� ������������, �������������� ������������������ ������������������ �� ���������������������� ���� �������������� ��������������������  (����������������, ��������, �� ��.��.).
Augmented Parser:==���������������������� ������������:
>Enabled<==>����������������<
Globally enables or disables the augmented parser. This setting requires a restart.==�������������������� ������������������ ������ �������������������� ������������������������ ��������������. ������������������ �������� ������������������ ������������������ �������������������� ������������������.
Augmented Parser - RDFa:==���������������������� ������������ RDFa:
Globally enables or disables the RDFa parser. This setting requires a restart.==�������������������� ������������������ ������ �������������������� �������������� RDFa. ������������������ �������� ������������������ ������������������ �������������������� ������������������.
"Submit"=="������������������"
#-----------------------------

#File: Blacklist_p.html
#---------------------------
Blacklist Administration==�������������������� �������������� ����������������
#Used Blacklist engine:==������������������������ ������������ ������������:
This function provides an URL filter to the proxy; any blacklisted URL is blocked==������ �������������� ������������������������ ���������� URL-������������ ������ ������������-��������������; ������������ �� ������������ ������������ ����
from being loaded. You can define several blacklists and activate them separately.==����������������������. ���� ������������ ������������ ������������������ ������������ �������������� �� ������������������������ ���� ���� ����������������������.
You may also provide your blacklist to other peers by sharing them; in return you may==���� ���������� ������������ �������������� ������������ �� ������������ �������������� ������������ ������������ ����������; ������
collect blacklist entries from other peers.==������������������ �������������� ���� ������������ �������������� ������������ ����������.
Active list:==���������������� ������������:
No blacklist selected==������������ ������������ ���� ������������
Select list to edit:==�������������� ������������ ������ ������������������
not shared::shared==������ ������������ ��������������::���������� ������������
"select"=="��������������"
Create new list:==�������������� ���������� ������������
"create"=="��������������"
Settings for this list==������������������ ������ ���������� ������������
"Save"=="������������������"
Share/don't share this list==��������������/�������������� ���������� ������������ ���������� �� ������������
Delete this list==�������������� �������� ������������
Edit list==���������������� ������������
These are the domain name/path patterns in==������ ���������������� ������/���������� �������� ��
Blacklist Pattern==������������ �������������� ������������
Edit selected pattern\(s\)==�������������������������� ������������������ ������������
Delete selected pattern\(s\)==�������������� ������������������ ������������
Move selected pattern\(s\) to==���������������������� ������������������ ������������ ��
#You can select them here for deletion==���� ������������ �������������� ���� ���������� ������ ����������������
Add new pattern:==���������������� ���������� ������������:
"Add URL pattern"=="���������������� URL ������������"
The right \'\*\', after the \'\/\', can be replaced by a==���������������� '*' (������������������), ���������� '/' ���������� �������� ����������������
>regular expression<==>�������������������� ��������������������<
domain.net\/fullpath<==domain.net/������������ ��������<
>domain.net\/\*<==>domain.net/*<
\*.domain.net\/\*<==*.domain.net/*<
\*.sub.domain.net\/\*<==*.sub.domain.net/*<
#sub.domain.\*\/\*<==sub.domain.*/*<
#domain.\*\/\*<==domain.*/*<
a complete <==������������ <
\(slow\)==(����������������)
#was removed from blacklist==������ ������������ ���� �������������� ������������
#was added to the blacklist==������ ���������������� �� ������������ ������������
Activate this list for==������������������������ �������� ������������ ������
Show entries:==���������������� ������������:
Entries per page:==������������ ���� ����������������:
"set"=="��������������������"
Edit existing pattern\(s\):==���������������� ������������������������ ������������:
"Save URL pattern\(s\)"=="������������������ URL ��������������"
#-----------------------------

#File: BlacklistCleaner_p.html
#---------------------------
Blacklist Cleaner==�������������� �������������� ������������
Here you can remove or edit illegal or double blacklist-entries.==���������� ���� ������������ �������������� ������ ������������������������������ ������������������ ������ �������������� ������������.
Check list==���������������� ������������
"Check"=="������������������"
Allow regular expressions in host part of blacklist entries.==������������������ �������������������� ������������������ �� ������������ ������������.
The blacklist-cleaner only works for the following blacklist-engines up to now:==Der Blacklist-Cleaner arbeitet zur Zeit nur mit den folgenden Blacklist-Engines:
Illegal Entries in \#\[blList\]\# for==������������������������ �������� \#\[blList\]\# ������
Deleted \#\[delCount\]\# entries==�������������� \#\[delCount\]\# ����������������
Altered \#\[alterCount\]\# entries!==���������������� \#\[alterCount\]\# ��������������!
Two wildcards in host-part==������ ���������� �� ��������-����������
Either subdomain <u>or</u> wildcard==�������� ���������������� <u> ������ </u> ��������������
Path is invalid Regex==���������������� �������� ���������������������� ������������������
Wildcard not on begin or end==������������ ���� ���������� ������ ���� ����������������
Host contains illegal chars==�������� ���������������� ������������������������ ��������������
Double==��������������
"Change Selected"=="���������������� ������������������"
"Delete Selected"=="�������������� ������������������"
No Blacklist selected==���� ������������ ������������ ������������
#-----------------------------

#File: BlacklistImpExp_p.html
#---------------------------
Blacklist Import==������������ �������������� ������������
Used Blacklist engine:==������������������������ ������������ ������������:
Import blacklist items from...==�������������������������� ���������������� �������������� ������������ ����...
other YaCy peers:==������������ ���������� YaCy:
"Load new blacklist items"=="���������������� ���������� ���������������� �������������� ������������"
URL:==���� ������������:
plain text file:<==���������������� �������������������� ����������:<
XML file:==XML ����������:
Upload a regular text file which contains one blacklist entry per line.==������������������ �������������� ������������������ ��������, �������������� ���������������� ������������ ������������ ������������������.
Upload an XML file which contains one or more blacklists.==������������������ XML-��������, �������������� ���������������� �������� ������ ������������������ ������������ �������������� .
Export blacklist items to...==�������������� ���������������� �������������� ������������ �� ��������...
Here you can export a blacklist as an XML file. This file will contain additional==���������� ���� ������������ ���������������������������� ������������ ������������, ������ �������� XML. �������� �������� ���������� ������������������ ����������������������������
information about which cases a blacklist is activated for.==�������������������� �� ������, �� ���������� ������������ ������������ ������������ ���������� ��������������.
"Export list as XML"=="���������������������������� ������������ ������ XML"
Here you can export a blacklist as a regular text file with one blacklist entry per line.==���������� ���� ������������ ���������������������������� ������������ ������������, ������ �������������� ������������������ �������� �� ���������� ������������������ ���� ������������.
This file will not contain any additional information==�������� �������� ���� ���������� ������������������ ����������-�������� ���������������������������� ��������������������
"Export list as text"=="���������������������������� ������������ ������ ����������"
#-----------------------------

#File: BlacklistTest_p.html
#---------------------------
Blacklist Test==���������������� �������������� ������������
Used Blacklist engine:==������������������������ ������������ ������������:
Test list:==���������������� ������������:
"Test"=="������������������"
The tested URL was==���������������������� URL
It is blocked for the following cases:==���� ���������������������� �� ������������������ ��������������:
#Crawling==����������������������������
#DHT==DHT
#News==��������������
#Proxy==������������
Search==����������
Surftips==������������
#-----------------------------

#File: Blog.html
#---------------------------
by==����
Comments</a>==����������������������</a>
>edit==>����������������
>delete==>��������������
Edit<==����������������<
previous entries==�������������������� ������������
next entries==������������������ ������������
new entry==���������� ������������
import XML-File==������������ XML-����������
export as XML==�������������� �� XML
Comments</a>==����������������������</a>
Blog-Home==���������������� ���������������� ����������
Author:==����������:
Subject:==��������:
#Text:==����������:
You can use==���� ������������ ������������������������
Yacy-Wiki Code==YaCy-Wiki ������
here.==����������.
Comments:==����������������������:
deactivated==������������������
>activated==>������������������������
moderated==������������������
"Submit"=="������������������"
"Preview"=="������������������������������ ����������������"
"Discard"=="����������������"
>Preview==>������������������������������ ����������������
No changes have been submitted so far!==������������������ ���� �������� ����������������������!
Access denied==������������ ����������������
To edit or create blog-entries you need to be logged in as Admin or User who has Blog rights.==���������� ���������������� ������ �������������� ��������, ���� ������������ �������� �������������������������������� �� ���������������� ���������������������������� ������ ������������������������, �������������� ���������� ���������������������� ����������.
Are you sure==���� ��������������
that you want to delete==������ ���� ������������ ��������������:
Confirm deletion==���������������������� ����������������
Yes, delete it.==����, �������������� ������.
No, leave it.==������, ���������������� ������.
Import was successful!==������������ ���������������� ��������������!
Import failed, maybe the supplied file was no valid blog-backup?==���� �������������� ��������������������������, ���������� ��������, ������������������������ �������� ���� ������ ������������������ ������������?
Please select the XML-file you want to import:==��������������������, ���������������� XML-��������, �������������� ���� ������������������������:
#-----------------------------

#File: BlogComments.html
#---------------------------
by==����
Comments</a>==����������������������</a>
Login==����������
Blog-Home==���������������� ���������������� ����������
delete</a>==��������������</a>
allow</a>==������������������</a>
Author:==����������:
Subject:==��������:
#Text:==����������:
You can use==���� ������������ ������������������������
Yacy-Wiki Code==YaCy-Wiki ������
here.==����������.
"Submit"=="������������������"
"Preview"=="������������������������������ ����������������"
"Discard"=="����������������"
#-----------------------------

#File: Bookmarks.html
#---------------------------
YaCy \'\#\[clientname\]\#\': Bookmarks==YaCy '#[clientname]#': ����������������

The bookmarks list can also be retrieved as RSS feed. This can also be done when you select a specific tag.==������������ ���������������� ���������� ���������� ���������������� ������ RSS-����������. ������ ���������� �������� �������������� ������ ������������ ���������������������� �������� .
Click the API icon to load the RSS from the current selection.==�������������� ���� ������������ API ������ ���������������� RSS ���� ���������������� ������������������.
To see a list of all APIs, please visit the <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">API wiki page</a>.==������ ������������������ ������������ �������� API, ��������������������, ���������������� <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">wiki-���������������� API</a>.
<h3>Bookmarks==<h3>����������������
Bookmarks \(==���������������� \(
#Login==����������
List Bookmarks==������������ ����������������
Add Bookmark==���������������� ����������������
Import Bookmarks==������������ ����������������
Import XML Bookmarks==������������ XML ����������������
Import HTML Bookmarks==������������ HTML ����������������
"import"=="��������������������������"
Default Tags:==������ ����-������������������:
imported==��������������������������
#Edit Bookmark==���������������� ����������������
#URL:==URL:
Title:==������������������:
Description:==����������������:
Folder \(/folder/subfolder\):==�������������� \(/��������������/��������������������\):
Tags \(comma separated\):==�������� (���������������������� ��������������):
>Public:==>������������������������:
yes==����
no==������
Bookmark is a newsfeed==���������������� ������ ������������������ ����������
"create"=="��������������"
"edit"=="����������������"
File:==��������:
import as Public==�������������������������� ������ ������������������
"private bookmark"=="������������ ����������������"
"public bookmark"=="������������������ ����������������"
Tagged with==������ ��
'Confirm deletion'=='���������������������� ����������������'
Edit==����������������
Delete==��������������
Folders==����������
Bookmark Folder==�������������� ����������������
Tags==��������
Bookmark List==������������ ����������������
previous page==�������������������� ����������������
next page==������������������ ����������������
All==������
Show==����������������
Bookmarks per page.==���������������� ���� ����������������
#unsorted==������������������������������
#-----------------------------

#File: Collage.html
#---------------------------
Image Collage==������������ ����������������������
Private Queue==������������ ��������������
Public Queue==������������������ ��������������
#-----------------------------


#File: compare_yacy.html
#---------------------------
Websearch Comparison==������������������ ������-������������
Left Search Engine==����������
Right Search Engine==������������
"Compare"=="����������������"
Search Result==������������������ ������������
#-----------------------------

#File: ConfigAccounts_p.html
#---------------------------
User Accounts==�������������� ������������ ��������������������������
User Administration==�������������� ������������
User created:==������������������������ ������������:
User changed:==������������������������ ��������������:
Generic error.==���������� ������������.
Passwords do not match.==������������ ���� ������������������.
Username too short. Username must be &gt;= 4 Characters.==������ ������������������������ �������������� ����������������. ������ ������������������������ ������������ �������� ���� ������������ 4 ����������������.
No password is set for the administration account.==������������ ���� �������������������� ������ �������������� ������������ ����������������������������.
Please define a password for the admin account.==��������������������, �������������������� ������������ ������ �������������� ������������ ����������������������������.
Admin Account==�������������� ������������ ����������������������������
Access from localhost without account==������������ ���� ������������ �������������������� ���������������� ������ �������������� ������������.
Access to your peer from your own computer \(localhost access\) is granted. No need to configure an administration account.==������������ �� �������� ���� ������������ �������������������� ����������������. ������ �������������������������� ���������������������� �������������� ������������.
Access only with qualified account==������������ ������������ �� ���������������������������������� �������������� ������������
You need this only if you want a remote access to your peer.==��������������������, �������� ���� �������������� �������������� ������������������ ������������ �� ������������ ��������.
Peer User:==������������������������ ��������:
New Peer Password:==���������� ������������ ��������:
Repeat Peer Password:==������������������ ������������ ��������:
"Define Administrator"=="������������������ ������������������������������"
>Access Rules<==>�������������� ��������������<
Protection of all pages: if set to on, access to all pages need authorization; if off, only pages with "_p" extension are protected.==������������ �������� ��������������: �������� ����������������, ���� ������ �������������� ���� �������� ������������������ ������������������ ����������������������; �������� ������������������, ���� ���������������� ������������ ���������������� �� ������������������ "_p".
Set Access Rules==��������������������
Select user==�������������� ������������������������
New user==���������� ������������������������
Edit User==���������������� ������������������������
Delete User==�������������� ������������������������
Edit current user:==���������������� ���������������� ������������������������:
Username</label>==������ ������������������������</label>
Password</label>==������������</label>
Repeat password==������������������ ������������
First name==������
Last name==��������������
Address==����������
Rights==����������
Download right==����������������
Timelimit==���������� ��������������
Time used==���������� ��������������������������
Save User==������������������ ������������������������
#-----------------------------

#File: ConfigAppearance_p.html
#---------------------------
Appearance and Integration==�������������� ������
You can change the appearance of the YaCy interface with skins.==���� ������������ ���������������� �������������� ������ YaCy ������������������ ����������.
#You can change the appearance of YaCy with skins==���� ������������ ���������������� �������������� ������ YaCy ���� ��������������
The selected skin and language also affects the appearance of the search page.==������������������ �������� �� ��������, ���������� ������������ ���� �������������� ������ ���������������� ������������.
If you <a href="ConfigPortal.html">create a search portal with YaCy</a> then you can==�������� ���� <a href="ConfigPortal.html">������������������ ���������� �� Yacy, </a>
change the appearance of the search page here.==���� ���������������� �������������� ������ ���������������� ������������ ���� ������������ ����������.
#and the default icons and links on the search page can be replaced with you own.==�� ���������������������� ������������ �� ������������ ���� ���������������� ������������ ���������� ���������������� ���� ��������.
Skin Selection==���������� ����������
Select one of the default skins, download new skins, or create your own skin.==���������������� �������� ���� ���������������������� ������������, ������������������ ���������� ����������, ������ ���������������� �������� ���������������������� ��������.
Current skin==�������������� ��������
Available Skins==������������������ ����������
"Use"=="������������������������"
"Delete"=="��������������"
>Skin Color Definition<==>�������� ����������<
The generic skin \'generic_pd\' can be configured here with custom colors:==���������������� �������� \'generic_pd\' ���������� �������� �������������� ��������������������������::
>Background<==>������<
>Text<==>����������<
>Legend<==>��������������<
>Table&nbsp;Header<==>����������������&nbsp;��������������<
>Table&nbsp;Item<==>����������������&nbsp;��������������<
>Table&nbsp;Item&nbsp;2<==>����������������&nbsp;��������������&nbsp;2<
>Table&nbsp;Bottom<==>��������������&nbsp;����������<
>Border&nbsp;Line<==>��������������&nbsp;����������<
>Sign&nbsp;\'bad\'<==>��������&nbsp;\'����������\'<
>Sign&nbsp;\'good\'<==>��������&nbsp;\'������������\'<
>Sign&nbsp;\'other\'<==>��������&nbsp;\'������������\'<
>Search&nbsp;Headline<==>������������������&nbsp;������������<
>Search&nbsp;URL==>����������&nbsp;URL
"Set Colors"=="�������������������� ����������"
>Skin Download<==>������������������ ����������<
Skins can be installed from download locations==�������� ���������� �������� �������������������� ���� ������������������ ���� ������������������ ��������������������
Install new skin from URL==������������������ ������������ ���������� ���� ������������
Use this skin==������������������������ �������� ��������
"Install"=="��������������������"
Make sure that you only download data from trustworthy sources. The new Skin file==������������������, ������ ���� �������������������� ������������ ���� ������������������������ ������������������. ���������� �������� ����������
might overwrite existing data if a file of the same name exists already.==���������� ������������������������ ������������������������ ��������, �������� �������� �� ���������� ������������ ������ ��������������������.
>Unable to get URL:==>���� �������������� ���������������� ���� URL:
Error saving the skin.==������������ �������������������� ���������� ����������.
#-----------------------------

#File: ConfigBasic.html
#---------------------------
Access Configuration==���������������� ������������������
Basic Configuration==���������������� ������������������
Your port has changed. Please wait 10 seconds.==�������� ������������ �������� ������ ��������������. ��������������������, ������������������ 10 ������������.
Your browser will be redirected to the new <a href="http://\#\[host\]\#:\#\[port\]\#/ConfigBasic.html">location</a> in 5 seconds.==������ �������������� ���������������� ���� <a href="http://#[host]#:#[port]#/ConfigBasic.html">���������� ����������������</a> �� �������������� 10 ������������.
The peer port was changed successfully.==�������� �������� ������ �������������� ��������������.
Your YaCy Peer needs some basic information to operate properly==�������������� ���������������� �������������������� ������ ������������ ������������ ��������
Select a language for the interface==���������������� �������� ��������������������
Use Case: what do you want to do with YaCy:==���������������� �������� �������������������������� YaCy:
Community-based web search==������������������ ������-����������
Join and support the global network \'freeworld\', search the web with an uncensored user-owned search network==���������������������� �� ������������������ �������������������� �������� \'FreeWorld\', ���������� �� ������������������ ������ �������������� �������������������������������� ������������������ ��������.
Search portal for your own web pages==���������� ���� ���������� ���������������������� ������������
Your YaCy installation behaves independently from other peers and you define your own web index by starting your own web crawl. This can be used to search your own web pages or to define a topic-oriented search portal.==������ YaCy ���������� �������� �������������������� ���� ������������ �������������������� ��������, �� ���� ������������ �������� ���������������������� ������-������������, ���������� ���������������������������� �������������������������� ������. ������ ���������� �������� ������������������������ ������ ������������ ���� ���������������������� ���������� ������ ������ ���������������� �������������������������� �������������������� ��������������.
Files may also be shared with the YaCy server, assign a path here:==�������������� �������� �� ���������� ������������, ������������������ �������������� YaCy:
This path can be accessed at ==�������� �������� ���������� ���������������� ���� ������������ 
Use that path as crawl start point.==���������������������� �������� �������� �� ���������������� ������������������ ���������� ����������������������������.
Intranet Indexing==���������� �� �������� ����������������
Create a search portal for your intranet or web pages or your \(shared\) file system.==���������������� ������������������ ������������ ������ ���������� ����������������-�������� ������ ������-��������������, ������ ���������� \(����������������������������\) ���������������� ��������������.
URLs may be used with http/https/ftp and a local domain name or IP, or with an URL of the form==URL-������������ ���������� �������� ������������������������ �� HTTP/HTTPS/FTP �� ������������������ ������������ ������������ ������ IP-��������������, ������ ������������ 
or smb:==������ smb:
Your peer name has not been customized; please set your own peer name==���� ���� �������������� ������ ��������. ��������������������, ���������������� �������� ��������.
You may change your peer name==���������������� ������ ������������ ��������
Peer Name:==������ ��������:
Your peer cannot be reached from outside==������ �������� �������������������� ����������
which is not fatal, but would be good for the YaCy network==������ ���� ����������������, ���� �������������������� ������ �������������������� ������������ ��������
please open your firewall for this port and/or set a virtual server option in your router to allow connections on this port==��������������������, ������������������ ���������������������� ���� �������� �������� �� ���������� ���������������������� ������ �� �������������������� ��������������
Your peer can be reached by other peers==������ �������� ���������������� ������ ������������ ����������
Peer Port:==�������� ��������:
with SSL== ������������������������ SSL
https enabled==HTTPS ������������������
on port==���� ����������
Configure your router for YaCy using UPnP:==���������������� UPnP:
Configuration was not successful. This may take a moment.==������������������ ���� �������� ������������������. �������������������� ���������� ������������������ ����������.
Set Configuration==������������������
Your basic configuration is complete! You can now \(for example\)==���������������� ������������������ ������������������! ������������ ���� ������������
just <==������������ �������������� <
start an uncensored search==������������ ������������������������������������ ����������
start your own crawl</a> and contribute to the global index, or create your own private web index==������������ �������� ���������������������� ���������������������������� </> �� ������������ ���������� �� �������������������� ����������, ������ �������������� �������� ���������������������� ������-������������
set a personal peer profile</a> \(optional settings\)==�������������������� ������������������������ �������������� ��������</a>
monitor at the network page</a> what the other peers are doing==���������������� ���������������������� �������� </>
Your Peer name is a default name; please set an individual peer name.==�������� ������ �������� ���������������� ������������ ����-������������������, ��������������������, �������������������� ������������ ������ ��������.
What you should do next:==
You did not set a user name and/or a password.==���� ���� �������������������� ������ ������������������������ ��/������ ������������.
Some pages are protected by passwords.==������������������ ���������������� ���������������� ��������������.
You should set a password at the <a href="ConfigAccounts_p.html">Accounts Menu</a> to secure your YaCy peer.</p>::==���� ������������ �������������������� ������������ �� �������� <a href="ConfigAccounts_p.html">�������������� ������������</a>, ���������� ���������������� �������� 
YaCy.</p>::
You did not open a port in your firewall or your router does not forward the server port to your peer.==���� ���� �������������� �������� ���� ���������������� ������ ������ ������������ ���� ���������������������������� �������������� ���� �������� ��������������.
This is needed if you want to fully participate in the YaCy network.==������ ��������������������, �������� ���� ������������ �������������������� ���������������������� �� ��������.
You can also use your peer without opening it, but this is not recomended.==YaCy ���������� ���������������� �� ������ ���������������� ����������, ���� ������ ������������������������.
#-----------------------------

#File: ConfigHeuristics_p.html
#---------------------------
Heuristics Configuration==������������������������ ������������������
A <a href=\"http://en.wikipedia.org/wiki/Heuristic\" target="_blank">heuristic</a> is an \'experience-based technique that help in problem solving, learning and discovery\' \(wikipedia\).==<a href=\"http://ru.wikipedia.org/wiki/������������������\" target="_blank">������������������</a> ������ ���������������������� ����������, �������������� ���������������� �� �������������� �� ������������ �������������� ��������������������.
The search heuristics that can be switched on here are techniques that help the discovery of possible search results based on link guessing, in-search crawling and requests to other search engines.==�������������������������� ���������� �������������������� ������������, �������������� ���������������� ���������������� ������������������ ������������ ���� �������� ���������������������������� ������������ ��/������ ���������������� �� ������������ ������������������ ����������������. 
When a search heuristic is used, the resulting links are not used directly as search result but the loaded pages are indexed and stored like other content.==���������� ������������������������ �������������������������� ����������, �������������������� ������������ ���� ������������������������ �� ������������������ ������������ ����������������, �� ������������������������ ������ �������������������� ���������� ��������������.
This ensures that blacklists can be used and that the searched word actually appears on the page that was discovered by the heuristic.==������ �������� ���������������������� ������������������������ ������������ ������������ �� ����������������������, ������ �������������� ���������� �������������� �������� ���� ���������������� ������������������ ��������������������.
The success of heuristics are marked with an image==���������� ������������������ �������������� ������������������������
heuristic:&lt;name&gt;==������������������:&lt;����������������&gt;
#\(redundant\)==\(������������������\)
\(new link\)==\(���������� ������������\)
below the favicon left from the search result entry:==������ �������������� ���������� ���� �������������������� ������������:
The search result was discovered by a heuristic, but the link was already known by YaCy==������������������ ������������ ������ ������������������ ������ ������������ ������������������, ���� ������������ �������� ������ ���������������� YaCy.
The search result was discovered by a heuristic, not previously known by YaCy==������������������ ������������ ������ ������������������ ������ ������������ ������������������, ���� ���������� ���� ������ ���������������� YaCy.
\'site\'-operator: instant shallow crawl==���������������� 'site': �������������������� �������������������� ��������������������
When a search is made using a \'site\'-operator \(like: \'download site:yacy.net\'\) then the host of the site-operator is instantly crawled with a host-restricted depth-1 crawl.==�������� ������ ������������ ������������������������ ���������������� 'site' (����������������: 'download site:yacy.net'), ���� ������������������ �������� �������������������������� �� ���������������� ������������ 1.
That means: right after the search request the portal page of the host is loaded and every page that is linked on this page that points to a page on the same host.==������ ����������������, ������ ���������� ���������� �������������������� �������������� ���������������������� �������������� ���������������� ���������� �� ������ ���������������� ���������� ���� �������������� �������� ������������ �� ��������������.
Because this \'instant crawl\' must obey the robots.txt and a minimum access time for two consecutive pages, this heuristic is rather slow, but may discover all wanted search results using a second search \(after a small pause of some seconds\).==������ ������ ������ ������������������ ������������ ������������������ ������������������ �� robots.txt �� �� ������������������������ YaCy ����������������������, ���� ������ �������������������� ������������������. ���� ���������������� ���������� �������� ���������������� ������ ���������������� ������������ (���������� ������������������ ������������). 
search-result: shallow crawl on all displayed search results==������������������ ������������: �������������������� �������������������� �������� ������������������������ ���������������������� ������������
When a search is made then all displayed result links are crawled with a depth-1 crawl.==������ �������������������� ������������ ������ ������������������������ ������������ �������������������������� �� ���������������� 1.
This means: right after the search request every page is loaded and every page that is linked on this page.==������ ����������������, ������ ���������� ���������� ������������ ������������ ������������ ���������������� ���������������������� �� ������������ ���������������� ������������������ ���� ������ ����������������.
If you check \'add as global crawl job\' the pages to be crawled are added to the global crawl queue \(remote peers can pickup pages to be crawled\).==�������� ���� ������������������ '���������������� ������ ������������ ���������������������� ����������������������������', ���� ���������������� ������ ���������������������������� ���������� ������������������ �� �������������� ���������������������� ���������������������������� (������������������ �������� ���������� ������������������ ���������������� ������ ��������������������).
Default is to add the links to the local crawl queue \(your peer crawls the linked pages\).==����-������������������ ������������ ���������������������� �� �������������� �������������������� ���������������������������� (������ �������� ���������������������� ������������ ���� ����������������).
add as global crawl job==���������������� ������ ������������ ���������������������� ����������������������������

opensearch load external search result list from active systems below==���������������� ���������������������� ���������������� ������������ ���� ������������ ���������������� ������������ ��������
When using this heuristic, then every search request line is used for a call to listed opensearch systems until enough results to fill the current search page are available.==������ �������������������������� ������������������, ������������ ������������������ ������������ ������������������������ ������ ������������ ������������������ opensearch-������������.
20 results are taken from remote system and loaded simultanously, parsed and indexed immediately.==20 ���������������������� �������������� ���� ������������������ ��������������,  ���������������������� ������������������������, �������������������������� �� �������������������������� ����������.
To find out more about OpenSearch see==������ ������������ �������������������� ���� OpenSearch ����������������
#>OpenSearch.org<==>OpenSearch.org<
Available/Active Opensearch System==������������������/���������������� OpenSearch-��������������
>Active<==>����������������<
>Title<==>������������������<
>Comment<==>����������������������<
Url <small>\(format opensearch==URL <small>(������������ OpenSearch
Url template syntax==������������ �������������������� URL
>delete<==>��������������<
>new<==>����������<
"add"=="����������������"
"Save"=="������������������"
"reset to default list"=="������������������������ ������������ ����-������������������"
"discover from index" class=="�������������� ���� ��������������" ����������
start background task, depending on index size this may run a long time==������������������ �������������� ������������. �� ���������������������� ���� �������������� ��������������, ������ ���������� ������������ �������������������� ����������.
With the button "discover from index" you can search within the metadata of your local index \(Web Structure Index\) to find systems which support the Opensearch specification.==������ �������������� ������������ "�������������� ���� ��������������" ���� ������������ ���������������������� ���������� �� �������������������� ������������ �������������������� �������������� (������-��������������) �� �������������� ������������, �������������� ������������������������ ������������������������ Opensearch.
The task is started in the background. It may take some minutes before new entries appear \(after refreshing the page\).==������������ ���������� ���������������� �� ��������. ���������� ������������ ������������������ ����������, ������������ ������ ���������������� ������������ �������������������� (���������� �������������������� ����������������).
Alternatively you may==�� ���������������� ������������������������ ���� ������������ ���������������������� �� ����������������
>copy &amp; paste a example config file<==> ������������ ���������� ����������������<
located in <i>defaults/heuristicopensearch.conf</i> to the DATA/SETTINGS directory.==<i>heuristicopensearch.conf</i>, �������������������� ����-������������������ ��  ���������� DATA/SETTINGS.
For the discover function the <i>web graph</i> option of the web structure index and the fields <i>target_rel_s, target_protocol_s, target_urlstub_s</i> have to be switched on in the <a href="IndexSchema_p.html\?core=webgraph">webgraph Solr schema</a>.==���������������� ����������������, ������ �������������� <i>Webgraph</i>, ���������� ������-������������������ �������������� �� �������� <i>target_rel_s, target_protocol_s, target_urlstub_s</i> ������������ �������� ���������������� �� <a href="IndexSchema_p.html?core=webgraph">���������� Webgraph Solr</a>.
"switch Solr fields on"=="���������������� ���������������� Solr"
\(\'modify Solr Schema\'\)==('���������������� ���������� �������� Solr?')
#-----------------------------

#File: IndexFederated_p.html
#-----------------------------
Index Sources &amp; Targets==������������������ �������������� �� ��������
 YaCy supports multiple index storage locations.==YaCy ������������������������ ������������������ ���������� �� �������������������� ��������������.
As an internal indexing database a deep-embedded multi-core Solr is used and it is possible to attach also a remote Solr.==������������������������ �������������������� �������� ������������ �������������� �������������������� �� ������������-�������� Solr, ���� ���������� ���������� ���������������������������� �� ������������������ �������� Solr.
Solr Search Index==�������� ������������ Solr
Solr stores the main search index. It is the home of two cores, the default 'collection1' core for documents and the 'webgraph' core for a web structure graph. Detailed information about the used Solr fields can be edited in the <a href="IndexSchema_p.html">Schema Editor</a>.==Solr ���������������� �������������� ������������������ ������������. �������� ������������ �������������� ���� �������� ��������: ����-������������������ �������� 'collection1' ������ �������������������� �� �������� 'webgraph' ������ ������-����������������. �������� ������������ Solr ���������� �������� ���������������� ������������������ ���������� <a href="IndexSchema_p.html">���������������� ����������</a>.
Lazy Value Initialization&nbsp;=="��������������" ���������������� ��������������������������&nbsp;
If checked, only non-zero values and non-empty strings are written to Solr fields.==�������� ����������������, ���� ������������ ���� �������������� ���������������� �� ���� ������������ ������������, ���������� ���������������� �� �������� Solr.
Use deep-embedded local Solr&nbsp;==������������������������ �������������������� ������������������ �������� Solr&nbsp;
This will write the YaCy-embedded Solr index which stored within the YaCy DATA directory.==������ ������������ ������������ ���������� ���������������������������� �������������������� �������� Solr, �������������� ���������������� �� ���������� DATA.
The Solr native search interface is accessible at<br/>==������������������ ������������ Solr ���������������� ���� ������������
<a href="solr/select?q=*:*&start=0&rows=3&core=collection1">/solr/select?q=*:*&amp;start=0&amp;rows=3&amp;core=collection1</a>==<a href="solr/select?q=*:*&start=0&rows=3&core=collection1">/solr/select?q=*:*&amp;start=0&amp;rows=3&amp;core=collection1</a>
for the default search index \(core: collection1\) and at<br/>==������ �������������������� �������������� ����-������������������ (��������: collection1) �� <br/>
<a href="solr/select?q=*:*&start=0&rows=3&core=webgraph">/solr/select?q=*:*&amp;start=0&amp;rows=3&amp;core=webgraph</a>==<a href="solr/select?q=*:*&start=0&rows=3&core=webgraph">/solr/select?q=*:*&amp;start=0&amp;rows=3&amp;core=webgraph</a>
for the webgraph core.<br/>==������ �������� ������-����������������.<br/>
If you switch off this index, a remote Solr must be activated.==�������� ���� ������������������ �������������������������� �������������������� ��������, ���� ���������� ������������������������ ������������������ �������� Solr.
Use remote Solr server\(s\)==������������������������ ������������������ �������� Solr
Solr Hosts==���������� Solr
Solr Host Administration Interface==������������������ �������������������� Solr
Index Size==�������������������� �� ��������������
It's easy to <a href="http://www.yacy-websearch.net/wiki/index.php/Dev:Solr" target="_blank">attach an external Solr to YaCy</a>.==������������������������ �������������� �������� Solr <a href="http://www.yacy-websearch.net/wiki/index.php/Dev:Solr" target="_blank">������������</a>.
This external Solr can be used instead the internal Solr. It can also be used additionally to the internal Solr, then both Solr indexes are mirrored.==�������������� �������� ������������ Solr ���������� ���������������������������� ������������ ��������������������. ���� ���������� ������������ ������������������������ �������������������������� �������������������� ��������, ���� ���������� �������������� ���������� ���������������������� �� ������ ��������.
Solr URL\(s\)==������������ ���� �������� Solr
You can set one or more Solr targets here which are accessed as a shard. For several targets, list them using a ',' \(comma\) as separator.==���� ������������ �������������������� �������� ������ ���������� ������ Solr, �������������� ���������� ���������������� ��������������������������. ������������ �������������������� ������ �������������������� ���������� ��������������.
The set of remote targets are used as shard of a complete index. The host part of the url is used as key for a hash function which selects one of the shards \(one of your remote servers\).==�������������������������� ������������������ �������� ������������������������ ������ ������������ ����������. ���������� ������������ ���� ���������� ������������������������ ������ �������� ������ ������-��������������, �������������� �������������������� ���������� ���� ������������������ (�������� ���� ���������� ������������������ ����������������).
When a search request is made, all servers are accessed synchronously and the result is combined.==���������� �������������������� ������������������ ������������, ������������������ ����������������������, ������ ������  ������ �������������� ���������������� ������������������.
Sharding Method<br/>==���������� ������������������������������<br/>
write-enabled \(if unchecked, the remote server\(s\) will only be used as search peers\)==������������ ������������������. �������� ���� ����������������, ���� ������������������ ������������ ���������� ���������������������������� ������������ ������ ������������ ����������.
Web Structure Index==������������ ������-����������������
The web structure index is used for host browsing \(to discover the internal file/folder structure\), ranking \(counting the number of references\) and file search \(there are about fourty times more links from loaded pages as in documents of the main search index\).==������������ ������-���������������� ������������������������ ������ ������������������ ������������ (���������� ������������������ ������������ �� ����������), ������������������������ (�������������� ���������� ������������) �� ������������ ������������ (���������������� �� 40 ������ ������������ ������������ ���� ���������������������� �������������� �� �������������������� ���������������� �������������������� ��������������).
use citation reference index \(lightweight and fast\)==������������������������ ������������ �������������� ���������������������� (������������ �� ��������������)
use webgraph search index \(rich information in second Solr core\)==������������������������ ������������������ ������������ ������-�������������� (������������ �������������������� ���� ������������ �������� Solr)
"Set"=="������������������"
Peer-to-Peer Operation==P2P-����������������
The 'RWI' \(Reverse Word Index\) is necessary for index transmission in distributed mode. For portal or intranet mode this must be switched off.=='RWI' (���������������� ������������ ��������) ������������������ ������ ���������������� �������������� �� ���������������������������� ������������. ������ ������������ �� ������������������ ������ ���� ������������������ ���������� ���� ������������ �������� ����������������.
support peer-to-peer index transmission \(DHT RWI index\)==���������������� ������������������ P2P-���������������� �������������� (DHT RWI ������������)
"Set"=="������������������"
#-----------------------------


#File: IndexSchema_p.html
#---------------------------
Solr Schema Editor==���������������� ���������� Solr
If you use a custom Solr schema you may enter a different field name in the column 'Custom Solr Field Name' of the YaCy default attribute name==������ ��������������������������, ���� ������������ ������������������������ ������������������ ���������������� ���������� �� �������������� "�������������������������������� ������ �������� Solr" ������������ ����������������������.
Select a core:==���������������� ��������
the core can be searched at==�������������� ���������� �������� �������������� ���� ������������
Active==����������������
Attribute==����������������
Custom Solr Field Name==�������������������������������� ������ �������� Solr
Comment==����������������������
show active==���������������� ����������������
show all available==���������������� ������ ������������������
show disabled==���������������� ����������������������
"Set"=="������������������"
"reset selection to default"=="�������������� ���������������� ����-������������������"
>Reindex documents<==>���������������������������� ��������������������<
If you unselected some fields, old documents in the index still contain the unselected fields.==�������� ���� ���� ���������������� ������������������ ��������, ������������ ������������������ �� �������������� ���� ���������������� ���������� ������������������ ������������������������ ��������. 
To physically remove them from the index you need to reindex the documents.==������ ���������������������� ���������������� ���������� ���������� ���� ��������������, ������ �������������������� ���������������������������������� ������������������.
Here you can reindex all documents with inactive fields.==���������� ���� ������������ ������������������ ���������������������������� �������� �������������������� �� �������������������������� ������������.
"reindex Solr"=="������������ ����������������������������"
You may monitor progress \(or stop the job\) under <a href="IndexReIndexMonitor_p.html">IndexReIndexMonitor_p.html</a>==�������������������� ������ �������������������� ������ ������������ ���� ������������ ���� ���������������� <a href="IndexReIndexMonitor_p.html">����������������������������.</a>
#---------------------------

#File: ConfigHTCache_p.html
#---------------------------
Hypertext Cache Configuration==������������������ ��������
The HTCache stores content retrieved by the HTTP and FTP protocol. Documents from smb:// and file:// locations are not cached.==������ ���������������� ������������ �������������������� ���� HTTP �� FTP ������������������. ������������������ ���� smb:// �� file:// ���� ��������������������.
The cache is a rotating cache: if it is full, then the oldest entries are deleted and new one can fill the space.==�������� ������ ����������������, ���� ������������ ������������ ���������� �������������� �� ���������������� ���� ����������.
HTCache Configuration==������������������ ��������
The path where the cache is stored==���������� ���������������� ��������
The current size of the cache==�������������� ������������ ��������
\#\[actualCacheSize\]\# MB for \#\[actualCacheDocCount\]\# files, \#\[docSizeAverage\]\# KB / file in average==#[actualCacheSize]# MB ������ #[actualCacheDocCount]# ������������, �������������� ������������ ���������� #[docSizeAverage]# KB
The maximum size of the cache==������������������������ ������������ ��������
"Set"=="��������������������"
Cleanup==���������������� ��������
Cache Deletion==���������������� ������
Delete HTTP &amp; FTP Cache==���������������� HTTP &amp; FTP ������
Delete robots.txt Cache==���������������� ������ robots.txt
Delete cached snippet-fetching failures during search==�������������� ������������������������ ������������������, �������������������� ���������������� ���� ���������� ������������
"Delete"=="��������������"
#-----------------------------

#File: ConfigLanguage_p.html
#---------------------------
Language selection==���������� ����������
You can change the language of the YaCy-webinterface with translation files.==���������� ���� ������������ ���������������� �������� �������������������� YaCy.
Current language</label>==�������������� ��������</label>
#default\(english\)==��������������
Author\(s\) \(chronological\)</label>==����������</label>
Send additions to maintainer</em>==������������������ ������������������ ������������������������ ����������������</em>
Available Languages</label>==������������������ ����������</label>
Install new language from URL==�������������������� ���������� �������� ���� ������������
Use this language==������������������������ �������� ��������
"Use"=="������������������������"
"Delete"=="��������������"
"Install"=="��������������������"
Unable to get URL:==���� �������������� ���������������� URL:
Error saving the language file.==������������ �������������������� ������������������ ����������.
Make sure that you only download data from trustworthy sources. The new language file==������������������, ������ ���� �������������������� ���������� ���������������� �������� ���� ���������������������� ��������������������.
might overwrite existing data if a file of the same name exists already.==���������������� �������������������� ������������������������ ������������, �������� �������� �� ���������� ������������ ������ ��������������������.
#-----------------------------

#File: ConfigLiveSearch.html
#---------------------------
Integration of a Search Field for Live Search==�������������������� �������������������� ������������ ������ ������������ ������������
Integration of Live Search with YaCy Search Widget==�������������������� ������������ �� ���������������� YaCy
There are basically two methods for integrating the YaCy Search Widget with your web site.==�������������������� ������ ���������������� ������������ ������ �������������������� �������������� YaCy ���� ���������� ����������.
Static hosting of widget on own HTTP server==�������������������� �������������� ���� ���������������������� HTTP-��������������
Remote access through selected YaCy Peer==������������������ ������������ ���������� ������������������ �������� YaCy
Advantages:==������������������������:
faster connection speed==�������������� ���������������� ��������������������
possibility for local adaptions==���������������������� ������������������ ������������������
Disadvantages:==��������������������:
No automatic update to future releases of YaCy Search Widget==�������������������� �������������������� �������������� �������������� ��������������
Ajax/JSONP cross domain requests needed to query remote YaCy Peer==AJAX/JSON ����������-���������������� ��������������, ���������������������� ������ �������������������� �������������� ��������
Installing:==������������������:
download yacy-portalsearch.tar.gz from==�������������������� ������������������ �������� yacy-portalsearch.tar.gz ����
unpack within your HTTP servers path==���������������������� ���� ������ HTTP-������������ 
use ./yacy/portalsearch/yacy-portalsearch.html as reference for integration with your own portal page==������������������������ ./yacy/portalsearch/yacy-portalsearch.html ������ ������������ ������ �������������������� ���� ���������� ���������������� ������������
#Remote access through selected YaCy Peer==������������������ ������������ ���������� ������������������ �������� YaCy
#Advantages:==������������������������:
Always latest version of YaCy Search Widget==������������ ������������������ ������������ �������������� YaCy
No Ajax/JSONP cross domain requests, as Search Widget and YaCy Peer are hosted on the same domain.==������ AJAX/JSON ����������-���������������� ����������������, ������ ������ ������������ ������������ �� �������� YaCy ������������������ ���� �������������������� ��������������.
Under certain cirumstances slower than static hosting==�� ������������������������ �������������� ���������������� ������������������, ������ ������ �������������������� ���� �������������������� ����������������.
Just use the code snippet below and paste it any place in your own portal page==���������������� ���������������������� �������� ���������������� �������� �� ���������� ���������� ���� ���������� ���������������� ������������
Please check if '\#\[ip\]\#:\#\[port\]\#' is appropriate or replace it with address of the YaCy Peer holding your index==��������������������, ������������������ ������������������������ ������������ '#[ip]#:#[port]#'. �������� ��������������������, ���� ���� ������������ ���������������� ������ �������������� ������������ ��������.
A \'Live-Search\' input field that reacts as search-as-you-type in a pop-up window can easily be integrated in any web page==�������� "������������" ������������ ������������������ ���������� ���� ���������������� ������������ �� ���������� ������������ ������������������������������ �� �������� ������-����������������.
This is the same function as can be seen on all pages of the YaCy online-interface \(look at the window in the upper right corner\)==������ �������������� ���������� �������������� ���� �������� ������������������ �������������������� YaCy (����������������, �������� �� �������������� ������������ ��������)
#Just use the code snippet below to integrate that in your own web pages==���������������������� ������������������ �������� ���������������� ��������, ������ �������������������� ���� �������� ������-����������������
Just use the code snippet below and paste it any place in your own portal page==���������������� ������������������ �������� ���������������� �������� �� ���������� ���������� ���� ���������� ���������������� ������������ 
#Please check if the address, as given in the example \'\#\[ip\]\#\:\#\[port\]\#\' here is correct and replace it with more appropriate values if necessary==��������������������, ������������������ ������������������������ ������������ �������������������� �� �������������� '#[ip]#:#[port]#' ��, �������� ��������������������, ���������������� ���� ������������.
#Code Snippet:==���������������� ��������:
#YaCy Portal Search==������������������ ������������ YaCy
"Search"=="����������"
Configuration options and defaults for \'yconf\':==���������� ������������������������ �� ������������������ ����-������������������ ������ 'yconf':
Defaults<==����-������������������<
url<==URL<
#is a mandatory property - no default<==���������������� ������������������������ ������������������<
#YaCy P2P Web Search==YaCy P2P ������-����������
Size and position \(width \| height \| position\)==������������ �� ������������������ \(������������ \| ������������ \| ������������������ \)
Specifies where the dialog should be displayed. Possible values for position: \'center\', \'left\', \'right\', \'top\', \'bottom\', or an array containing a coordinate pair \(in pixel offset from top left of viewport\) or the possible string values \(e.g. \[\'right\',\'top\'\] for top right corner\)==������������������ ���������� ���������������������� ���������������������� ��������. ������������������ ���������������� ������ ��������������������������������: \'center\', \'left\', \'right\', \'top\', \'bottom\', ������ ������������ �������������������� ���������������������� �������� ������������������ \(�� ���������������� ���� ���������������� ������������ �������� �������������� ������������������\) ������ ������������������ ������������������ ���������������� \(��������. \[\'right\',\'top\'\] ������ ���������������� �������������� ������������������\)
Animation effects \(show | hide\)==������������������������ �������������� \(���������������� | ������������\)
The effect to be used. Possible values: \'blind\', \'clip\', \'drop\', \'explode\', \'fold\', \'puff\', \'slide\', \'scale\', \'size\', \'pulsate\'.==������������ ���������� ����������������������. ������������������ ����������������: 'blind', 'clip', 'drop', 'explode', 'fold', 'puff', 'slide', 'scale', 'size', 'pulsate'.
Interaction \(modal \| resizable\)==���������������������������� (������������������ | �������������������� ������������)
If modal is set to true, the dialog will have modal behavior; other items on the page will be disabled \(i.e. cannot be interacted with\).==�������� ������������������ ���������������� ���������������������� ������ "true", ���� �������� ���������� ���������� ������������������ ������������������; ������������ ���������������� ���� ���������������� ���������� ������������������.
Modal dialogs create an overlay below the dialog but above other page elements.==������������������ �������� �������������� ������������������ ������ �������������������� ����������, ���� ������ �������������� �������������������� ����������������.
If resizable is set to true, the dialog will be resizeable.==�������� ���������������� ������������������������ �������� ���������������������� ������ "true", ���� �������������������� �������� ���������� ��������������������.
Load JavaScript load_js==������������������ JavaScript load_js
Load Stylesheets load_css==������������������ �������������� ������������ load_css
This parameter is used for static hosting only.==�������� ���������������� ������������������������ ������������ ������ �������������������� ����������������.
>Themes<==>��������<
You can download standard jquery-ui themes or create your own custom themes on==���� ������������ ������������������ ���������������������� jQuery UI �������� ������ �������������� ���������������������� ����
Themes are installed in ./yacy/jquery/themes/ \(static hosting\) or in DATA/HTDOCS/jquery/themes/ on remote YaCy Peer.==�������� ���������������������� �� ./yacy/jquery/themes/ (�������������������� ��������������) ������ �� DATA/HTDOCS/jquery/themes/ ���� ������������������ ��������.
YaCy ships with 'start' and 'smoothness' themes pre-installed.==�� YaCy ������ ���������������������� ������������������ ��������.
#-----------------------------

#File: ConfigNetwork_p.html
#---------------------------
Network Configuration==������������������ ��������
No changes were made!==������������������ ���� ����������������������!
Accepted Changes==������������������ ��������������
Inapplicable Setting Combination==������������������������ ������������������ ����������������
#P2P operation can run without remote indexing, but runs better with remote indexing switched on. Please switch 'Accept Remote Crawl Requests' on==P2P-T��tigkeit l��uft ohne Remote-Indexierung, aber funktioniert besser, wenn diese eingeschaltet ist. Bitte aktivieren Sie 'Remote Crawling akzeptieren'
For P2P operation, at least DHT distribution or DHT receive \(or both\) must be set. You have thus defined a Robinson configuration==������ P2P-������������ ������������ �������� ������������������ ������ ���������������� ���������� DHT ������ ���������� \(������ �� ���� �� ������������\). ���� �������������� �������������������� (Robinson) ������������������������
Global Search in P2P configuration is only allowed, if index receive is switched on. You have a P2P configuration, but are not allowed to search other peers.==�������������������� P2P-���������� ���������������� ������������, �������� �� ������ �������������� ���������� �������������� ���������� DHT. �� ������ P2P-������������������������, ���� ������ ���� ���������������� �������������������� ����������.
For Robinson Mode, index distribution and receive is switched off==������ ���������������������� (Robinson) ������������, �������������� �� ���������� �������������� ������������������
#This Robinson Mode switches remote indexing on, but limits targets to peers within the same cluster. Remote indexing requests from peers within the same cluster are accepted==Dieser Robinson-Modus aktiviert Remote-Indexierung, aber beschr��nkt die Anfragen auf Peers des selben Clusters. Nur Remote-Indexierungsanfragen von Peers des selben Clusters werden akzeptiert
#This Robinson Mode does not allow any remote indexing \(neither requests remote indexing, nor accepts it\)==Dieser Robinson-Modus erlaubt keinerlei Remote-Indexierung (es wird weder Remote-Indexierung angefragt, noch akzeptiert)
Network and Domain Specification==������������������������ �������� �� ������������
# With this configuration it is not allowed to authentify automatically from localhost!==���������� ������������������������ ���� ������������������ �������������������������� ������������������������ ������������������ ������������������!
# Please open the <a href=\"ConfigAccounts_p.html\">Account Configuration</a> and set a new password.==��������������������, ���������������� <a href="ConfigAccounts_p.html">�������������� ������������</a> �� �������������������� ���������� ������������.
YaCy can operate a computing grid of YaCy peers or as a stand-alone node.==YaCy ���������� ���������������� �� ������������ ���������������� ���������� ������ ������ ������������������ ��������.
To control that all participants within a web indexing domain have access to the same domain,==������ ��������, ���������� ������ ������������������ ������������ �������������������� ���������� ������������ �� ���������� �� ������ ���� ������������,
this network definition must be equal to all members of the same YaCy network.==������������ ���������������� �������� ������������ �������� ������������������ �� �������� ������������ �������� ��������.
>Network Definition<==>��������<
Remote Network Definition URL==������������ ���� ������������������ ��������
Enter custom URL...==�������������� �������� ������������...
Network Nick==���������������� ��������
Long Description==������������������ ����������������
Indexing Domain==�������������������� ������������
#DHT==DHT
"Change Network"=="���������������� ��������"
Distributed Computing Network for Domain==�������� ���������������������������� �������������������� ������ ������������
You can configure if you want to participate at the global YaCy network or if you want to have your==������ ������������������ ������������������ ������������������ ���������� �� �������������������� �������� ������ ������������ ������������
own separate search cluster with or without connection to the global network. You may also define==����������������, �� ������������������������ ������ ������ ���������������������� �� �������������������� ��������. ���� ������������ ���������� ������������
a completely independent search engine instance, without any data exchange between your peer and other==�������������������� ���������������������� ������������������ ������������, ������ ������������ ������������ �������������� ���������� ���������� ���������� �� ��������������
peers, which we call a 'Robinson' peer.==������������. �������� ���������� ���� ���������������� 'Robinson'.
Peer-to-Peer Mode==���������� P2P
>Index Distribution==>�������������������������� ��������������
This enables automated, DHT-ruled Index Transmission to other peers==���������������������������� ���������������� �������������� ���������� DHT ���� ������������ ��������
>enabled==>����������������
disabled during crawling==������������������ ���� ���������� ������������������������
disabled during indexing==������������������ ���� ���������� ��������������������
>Index Receive==>���������� ��������������
Accept remote Index Transmissions==���������� ������������������ �������������� ��������������
This works only if you have a senior peer. The DHT-rules do not work without this function==���������������� ������������, �������� ������ �������� ���������������� ��������������. �������������� DHT ���� ���������������� ������ �������� ��������������.
>reject==>������������������
accept transmitted URLs that match your blacklist==������������������ ������������, ���������������������� �� ���������� ������������ ��������������
>allow==>������������������
deny remote search==������������������ ������������������ ����������
#>Accept Remote Crawl Requests==>���������� ���������������� �������������������� ����������������������
#Perform web indexing upon request of another peer==������������������ ������-���������������������������� ������ �������������� ���� �������������� ��������
#This works only if you are a senior peer==���������������� ������������, �������� ������ �������� ���������������� ��������������.
#Load with a maximum of==������������������ ����������������
#pages per minute==�������������� �� ������������ (PPM)
>Robinson Mode==>���������� Robinson
If your peer runs in 'Robinson Mode' you run YaCy as a search engine for your own search portal without data exchange to other peers==�������� �������� �������� ���������������� �� ������������ Robinson, ���� ���� ������������ ������������������ YaCy �� ���������������� ������������ ������ ������������������������ �������������������� ��������������, ������ ������������ �������������� �� �������������� ������������
There is no index receive and no index distribution between your peer and any other peer==�� ������������ ������������ Robinson-��������������������������, ���������� �� ���������������� �������������� ���������� ���������� �� �������������� ������������ ���������� ��������������������������
In case of Robinson-clustering there can be acceptance of remote crawl requests from peers of that cluster==
>Private Peer==>�������������� ��������
Your search engine will not contact any other peer, and will reject every request==������ �������� ���� ���������� ���������������������������� �� ������������ �������������� ������������, �� ���������� �������������������� ���������� ������������
#>Private Cluster==>�������������� ��������������
#Your peer is part of a private cluster without public visibility
#Index data is not distributed, but remote crawl requests are distributed and accepted from your cluster
#Search requests are spread over all peers of the cluster, and answered from all peers of the cluster
#List of ip:port - addresses of the cluster: \(comma-separated\)
>Public Cluster==>������������������ ��������������
Your peer is part of a public cluster within the YaCy network==������ �������� ���������������� ������������ �������������������� ���������������� ������������ �������� YaCy
Index data is not distributed, but remote crawl requests are distributed and accepted==������������������ ������������ ���� ��������������������������������, ���� ������������������ �������������� ���������������������������� �������������������������������� �� ����������������������
Search requests are spread over all peers of the cluster, and answered from all peers of the cluster==������������������ ��������������  �������������������������������� ���� ������ �������� ����������������, �������������������� ������������ ���������������������� ���� �������� ���������� ����������������
List of .yacy or .yacyh - domains of the cluster: \(comma-separated\)==������������ .yacy ������ .yacyh - ������������ ����������������: (���������� ��������������)
>Public Peer==>������������������ ��������
You are visible to other peers and contact them to distribute your presence==������ �������� ���������� ������������ �������������������� �� ���� ������������������������ �� �������� ������ ������������������������������ ������������ ����������������������
Your peer does not accept any outside index data, but responds on all remote search requests==������ �������� ���� ������������������ ���������� ������������������ ������������ ��������������, ���� ���������������� ���� ������ ������������������ ������������������ ��������������
>Peer Tags==>�������� ��������
When you allow access from the YaCy network, your data is recognized using keywords==���������� ���� �������������������� ������������ ���� �������� YaCy, �������� ������������ ������������������������ �� �������������� ���������������� ��������
Please describe your search portal with some keywords \(comma-separated\)==��������������������, �������������� ������ ������������������ ������������ ���������������������� �������������� (���������� ��������������)
If you leave the field empty, no peer asks your peer. If you fill in a \'\*\', your peer is always asked.==�������� ���� ���������������� �������� ������������, ���� ������������ �������� ���� ���������� �������������������� ������ ��������. �������� ���� �������������� �� �������� '*', ���� ������ �������� ������������ ���������� ������������������������.</br>
"Save"=="������������������"
#-----------------------------

#File: ConfigParser.html
#---------------------------
Parser Configuration==������������������������ ��������������
Content Parser Settings==������������������ �������������� ����������������
With this settings you can activate or deactivate parsing of additional content-types based on their MIME-types.==�� �������������� �������� ���������������� ���� ������������ ���������������� ������ ������������������ ������������ ���������������������������� ���������� ����������������.
For a detailed description of the various MIME-types take a look at==������������������ ���������������� ������������������ ���������� ������������ ���������������� ����
http://www.iana.org/assignments/media-types/</a>==http://www.iana.org/assignments/media-types/</a>
If you want to test a specific parser you can do so using the==�������� ���� �������������� ���������������������� ���������������������� ��������������, ���� ���������� ������������ ������������������������
>File Viewer<==>���������������� ������������<
> enable/disable<==> ���������������� / ������������������<
>Extension<==>��������������������<
>Mime-Type<==>������ ����������<
"Submit"=="��������������������"
#-----------------------------

#File: ConfigPortal.html
#---------------------------
Integration of a Search Portal==�������������������� ������������
If you like to integrate YaCy as portal for your web pages, you may want to change icons and messages on the search page.==�������� ���� ������������ �������������������������� YaCy ������ ���������� ������ ������-��������������, ���� ���� ������������ ������������ ������������ �� ������������������ ���� ���������������� ������������.
The search page may be customized.==���������������� ������������ ���������� �������� ������������������.
You can change the \'corporate identity\'-images, the greeting line==���� ������������ ���������������� ���������������� �������������������� ����������������, ������������ ����������������������
and a link to a home page that is reached when the \'corporate identity\'-images are clicked.==�� ������������ ���� ���������������� ����������������, �������������� ���������� ���������������� ������ �������������� ���� ���������������� �������������������� ����������������.
To change also colours and styles use the <a href=\"ConfigAppearance_p.html\">Appearance Servlet</a> for different skins and languages.==
���������������� ���������� �� ����������, ���������� �� ���������� ���������� ���� <a href="ConfigAppearance_p.html">��������</a> ����������������.
Greeting Line<==������������ ����������������������<
URL of Home Page<==���������� ���������������� ����������������<
URL of a Small Corporate Image<==���������� �������������������� ����������������<
URL of a Large Corporate Image<==���������� ���������������� ����������������<
Enable Search for Everyone?==������������������ ���������� ��������������
Search is available for everyone==���������� ���������������� ��������������
Only the administator is allowed to search==���������� ���������������� ������������ ����������������������������
Show additional interaction features in footer==���������������� ���������������������������� ������������ �� ������������ ����������������������
User-Logon==�������� ������������������������
Snippet Fetch Strategy &amp; Link Verification==�������������� ������������������ �������������������� �� ���������������� ������������
Speed up search results with this option! \(use CACHEONLY or FALSE to switch off verification\)==���������������� ������������ ���������������������� �� �������� ������������ ��������������������! (���������������������� CACHEONLY ������ FALSE ������ �������������������� ����������������)
NOCACHE: no use of web cache, load all snippets online==NOCACHE: ���� ������������������������ ������-������, ������������������ ������ ������������������ ���� ��������
IFFRESH: use the cache if the cache exists and is fresh otherwise load online==IFRESH: ������������������������ ������, �������� ���� ���������������� ���������� ������������ ������������. ���������� ������������������ ������������������ ���� ��������
IFEXIST: use the cache if the cache exist or load online==IFEXIST: ������������������������ ������ ������ ������������������ ���� ��������
If verification fails, delete index reference==�������� ������ ���������������� ������������������ ������������, ���� �������������� ������������ ������������
CACHEONLY: never go online, use all content from cache. If no cache entry exist, consider content nevertheless as available and show result without snippet==CACHEONLY: ���� ������������������ ������������������ ���� ��������, ������������������������ ������������ �������������������� ��������. �������� �������� ������, ���� ������������ �������������������� ������ ��������. ������������������ ������������������ ���������� ��������������������������
FALSE: no link verification and not snippet generation: all search results are valid without verification==FALSE: ���� ������������������ ������������ �� ���� ������������������ ������������������: ������ �������������������� ������������ ���� ����������������������
Greedy Learning Mode=="������������" ���������� ����������������
load documents linked in search results, will be deactivated automatically when index size==�������������������� �� ���������������������� ������������ ������������������ ������������������. ���������� �������� ���������������� �������������������������� ������ �������������������� �������������� ��������������
Show Navigation Bar on Search Page?==���������������� ������������ �������������������� ���� ���������������� ������������
Show Navigation Top-Menu&nbsp;==���������������� ������������ �������������������� �� �������������� ��������&nbsp;
no link to YaCy Menu \(admin must navigate to /Status.html manually\)==���� �������������������� ������������ ���� �������� YaCy \ (�������������������������� ������������ �������������� �� / Status.html �������������� \)
Show Advanced Search Options on Search Page?==�������������������� ���������������������� ���������� ���� ������������������ ����������������
Show Advanced Search Options on index.html&nbsp;==�������������������� ���������������������� ���������� ���� index.html ����������������
do not show Advanced Search==���� �������������������� ���������������������� ����������
Default Pop-Up Page<==������������������ ���������������� ����-������������������<
>Status Page==>������������ ����������������
>Search Front Page==>������������������ ���������������� ������������
>Search Page \(small header\)==>���������������� ������������ (������������������ ������������������)
>Interactive Search Page==>���������������� ���������������������������� ������������
Default maximum number of results per page==������������������������ �������������������� ���������������������� ���� ����������������
Default index.html Page \(by forwarder\)==���������������������� ���������������� index.html (������ ����������������)
Target for Click on Search Results==���������������� ������ �������������� ���� ������������������ ������������

\"_blank\" \(new window\)=="_blank" (���������� ��������)
\"_self\" \(same window\)=="_self" (�� ������ ���� ��������)
\"_parent\" \(the parent frame of a frameset\)=="_parent" (������������������������ ����������)
\"_top\" \(top of all frames\)=="_top" (������������ �������� ��������������)
\"searchresult\" \(a default custom page name for search results\)==\"searchresult\" (���� ������������������ �������������������������������� ������ ���������������� ������ ���������������������� ������������)

Special Target as Exception for an URL-Pattern==�������������������� ������ �������������� URL
Pattern:<==������������:<
>Exclude Hosts<==>������������������ ����������<
List of hosts that shall be excluded from search results by default but can be included using the site:&lt;host&gt; operator:==������������ ������������, �������������� ���������� ������������������ ���� ���������������������� ������������ ����-������������������, ���� ���������� �������� ���������������� �� �������������� ������������������ '��������: &lt;��������&gt; ����������������:'
\'About\' Column<br/>\(shown in a column alongside<br/>with the search result page\)==������������ '�� ������������������������ (����������������)'<br/>(������������������������ �� �������������� ����������<br/>���� ���������������� ������������)
\(Headline\)==(������������������)
\(Content\)==(��������������������)
"Change Search Page"=="���������������� ���������������� ������������"
"Set to Default Values"=="�������������������� ���������������� ����-������������������"
You have==������ ��������������������
set a remote user/password==�������������������� ������������ �� ������ �������������������� ������������������������
to change this options.==, ���������� ���������������� ������ ����������.
The search page can be integrated in your own web pages with an iframe. Simply use the following code:==���������������� ������������ ���������� �������� �������������������������� �� ������ ���������������������� �������� �� ���������������������������� ������������. ������������ ���������������������� ������������������ ������:
This would look like:==������ ���������� ������������������ ������:
For a search page with a small header, use this code:==������ ���������������� ������������ �� ������������������ �������������������� ���������������������� �������� ������:
A third option is the interactive search. Use this code:==�������������� ������������������ ���������������� �������������������������� ����������. ���������������������� �������� ������:
#-----------------------------

#File: ConfigProfile_p.html
#---------------------------
Your Personal Profile==������ ������������������������ ��������������
You can create a personal profile here, which can be seen by other YaCy-members==���� ������������ �������������� ������������������������ �������������� �� �������� ��������������, �������������� ���������� �������� ���������������� ������������ �������������������� Yacy
or <a href="ViewProfile.html\?hash=localhash">in the public</a> using a <a href="ViewProfile.rdf\?hash=localhash">FOAF RDF file</a>.==������ ���������� �������������������� <a href="ViewProfile.html?hash=localhash">�� ������������������ ��������������</a>, ������������������ <a href="ViewProfile.rdf?hash=localhash">�������� FOAF RDF</a>.
>Name<==>�������� ������<
Nick Name==�������� ����������������
Homepage \(appears on every <a href="Supporter.html">Supporter Page</a> as long as your peer is online\)==���������������� ���������������� (������������������������ ���� ������������ <a href="Supporter.html">���������������������������� ����������������,</a> ���� ������ ������, ������ �������� �� ��������������).
eMail==���������������������� ����������
#ICQ==ICQ
#Jabber==Jabber
#Yahoo!==Yahoo!
#MSN==MSN
#Skype==Skype
Comment==����������������������
"Save"=="������������������"
You can use <==���� ������������ ������������������������ <
> here.==> ������ ������������ ��������������.
#-----------------------------

#File: ConfigProperties_p.html
#---------------------------
Advanced Config==���������������������� ������������������������
Here are all configuration options from YaCy.==���������� ������������������ ������ �������������������������������� ���������� YaCy.
You can change anything, but some options need a restart, and some options can crash YaCy, if wrong values are used.==���� ������������ ���������������� ���������� ����������, ���� ������������������ ���� ������ �������������� ���������������������� YaCy, ������ �������� ����������, ������ �������������������������� ������������������������ ����������������, �������������� ��������������.
For explanation please look into defaults/yacy.init==���������������������������� ���������������� ���� ������������ ������������ �� ���������� defaults/yacy.init
"Save"=="������������������"
"Clear"=="����������������"
#-----------------------------

#File: ConfigRobotsTxt_p.html
#---------------------------
Exclude Web-Spiders==������������ �� ������-��������������������
Here you can set up a robots.txt for all webcrawlers that try to access the webinterface of your peer.==�� ���������� robots.txt ���� ������������ �������������� ������������������ ���������������������� �������������� �� ������-�������������������� ������������ ��������.
is a volunteer agreement most search-engines \(including YaCy\) follow.==
It disallows crawlers to access webpages or even entire domains.==���������� ��������������, ���� ���������������� ������������ ������������������������ �� ������-���������������� ������������ �������� ������ �������� ������������ ������������.
Deny access to==�������������� ������������ ��
Entire Peer==�������� ��������������
Status page==������������������ ����������������
Network pages==������������������ ��������
Surftips==��������������������
News pages==������������������ ����������������
Blog==����������
Wiki==Wiki
Public bookmarks==������������������ ������������������
Home Page==���������������� ����������������
File Share==���������� ������������
Impressum==��������������������
"Save restrictions"=="������������������ ������������������"
#-----------------------------

#File: ConfigSearchBox.html
#---------------------------
Integration of a Search Box==�������������������� ������������
We give information how to integrate a search box on any web page that==�������������������� ������ �������������������� ���� �������������������� ������������ YaCy ���� ���������� ������-����������������.
calls the normal YaCy search window.==
Simply use the following code:==������������ ���������������������� ������������������ ������:
  MySearch==  ������ ����������
"Search"=="����������"
This would look like:==������ ���������� ������������������ ������:
This does not use a style sheet file to make the integration into another web page with a different style sheet easier.==���������� �������������� �������������������� ������������ ���������� �������������� ������������ ���� ����������������������������.
You would need to change the following items:==������ ���������������������� ���������������� ������������������ ����������������:
Replace the given colors \#eeeeee \(box background\) and \#cccccc \(box border\)==���������������� ���������� #eeeeee (������ ������������) �� #cccccc (�������������� ������������)
Replace the word \"MySearch\" with your own message==���������������� ���������� "������ ����������" ���� �������� ������������������.
#-----------------------------

#File: ConfigSearchPage_p.html
#---------------------------
Search Page<==���������������� ������������<
>Search Result Page Layout Configuration<==>������������������������ ������������ ���������������� ���������������������� ������������<
Below is a generic template of the search result page. Mark the check boxes for features you would like to be displayed.==�������� ���������������� ���������� ���������� ���������������� ���������������������� ������������. ���������������� ��������������������, �������������� ������������ �������� ��������������������.
To change colors and styles use the ==���������������� ����������, ���������� �� ���������� ���� ������������ 
>Appearance<==>����������<
 menu for different skins.==.
Other portal settings can be adjusted in==������������ ������������������ �������������� ���������� �������� ���������������� ���� 
>Generic Search Portal<==>���������������� �������������������� ������������<
>Page Template<==>���������� ����������������<
>Administration<==>����������������������������������<
>Web Search<==>������-����������<
>File Search<==>���������� ������������<
>Tutorial<==>������������<
>Index Browser<==>���������������� ������������<
>About Us<==>�� ������������������������<
>Help / YaCy Wiki<==>YaCy Wiki<
"Search"=="����������"
>Text<==>����������<
>Images<==>����������������������<
>Audio<==>����������<
>Video<==>����������<
>Applications<==>��������������������<
>more options<==>���������������������� ����������<
>Tag<==>������<
>Topics<==>������������<
>Cloud<==>������������<
>Protocol<==>����������������<
>Filetype<==>������ ����������<
>Domain<==>����������<
>Wiki Name Space<==>������������ Wiki<
>Language<==>��������<
>Author<==>����������<
>Vocabulary<==>��������������<
>Provider<==>����������<
>Collection<==>������������������<
>Title of Result<==>������������������ ��������������������<
Description and text snippet of the search result==���������������� �� ���������������� ������������ �������������������� ������������
http://url-of-the-search-result.net==http://url-of-the-search-result.net
42 kbyte<==42 ����������<
>Metadata<==>��������������������<
>Parser<==>������������<
>Citation<==>������������<
>Pictures<==>����������������������<
>Cache<==>������<
>Augmented Browsing<==>���������������������� ����������������<
"Save Settings"=="������������������ ������������������"
"Set Default Values"=="�������������������� ���������������� ����-������������������"
#-----------------------------


#File: ConfigUpdate_p.html
#---------------------------
>System Update<==>�������������������� ��������������<
Manual System Update==������������ ��������������������
Current installed Release==�������������� �������������������������� ������������
Available Releases==������������������ ��������������������
>changelog<==>������������ ������������������<
> and <==> �� <
> RSS feed<==> RSS ����������<
\(unsigned\)==(���� ������������������)
\(signed\)==(������������������)
"Download Release"=="������������������ ��������������������"
"Check for new Release"=="������������������ ��������������������"
Downloaded Releases==���������������������� ��������������������
No downloaded releases available for deployment.==������ ������������������ �������������������� ������������������ ������ ������������������
no&nbsp;automated installation on development environments==������ ���������������������������� ������������������ ���� ������������ ��������������������
"Install Release"=="�������������������� ��������������������"
"Delete Release"=="�������������� ��������������������"
Automatic Update==���������������������������� ��������������������
check for new releases, download if available and restart with downloaded release==������������������ ��������������������, ������������������ �� �������������������������� �� ���������� ����������������������
"Check \+ Download \+ Install Release Now"=="������������������"
Download of release \#\[downloadedRelease\]\# finished. Restart Initiated.== ���������������� ������������ #[downloadedRelease]# ������������������. �������������������� ������������������������.
No more recent release found.==���������� ������������ �������������������� ���� ��������������������.
Release will be installed. Please wait.==�������� ������������������ ������������ ��������������������. ��������������������, ������������������.
You installed YaCy with a package manager.==
To update YaCy, use the package manager:==������ �������������������� YaCy ���������������������� ���������������� ��������������.
Omitting update because this is a development environment.==������������������ ��������������������, ������������ ������ ������ ������������ ������ ��������������������������.
Omitting update because download of release \#\[downloadedRelease\]\# failed.==������������������ ��������������������, ������������ ������ ���������������� ������������ #[downloadedRelease]# ���� �������� ����������������.
Automated System Update==���������������������������� ��������������������
manual update==������������ ��������������������
no automatic look-up, updates can be made manually using this interface \(see options above\)==�������������������� ���������� ������������������ �������������� ���� �������� ����������������.
automatic update==���������������������������� ��������������������
add the following line to==���������������� ������������ �� ��������
updates are made within fixed cycles:==�������������������� ���������������������� ���������� �������������������������� �������������������� ��������������:
Time between lookup==���������� ���������� ��������������������
hours==����������
Release blacklist==������������ ������������ ��������������
regex on release number strings==������������ �������������������� ������������������ �� ���������������� ����������������
Release type==������ ������������
only main releases==������������ ������������������ ������������
any release including developer releases==���������� ��������������������, �������������� ������������ ������ ��������������������������
Signed autoupdate:==���������������������� ��������������������
only accept signed files==������������������ ������������ ���������������������� ����������
"Submit"=="������������������"
Accepted Changes.==������������������ ��������������
System Update Statistics==�������������������� �������������������� ��������������
Last System Lookup==������������������ ���������������� ��������������������
never==��������������
Last Release Download==������������������ ���������������� ��������������������
Last Deploy==������������������ ��������������������
#-----------------------------

#File: Connections_p.html
#---------------------------
Server Connection Tracking==������������������������ �������������������� �� ����������������
Incoming Connections==���������������� ��������������������
Showing \#\[numActiveRunning\]\# active, \#\[numActivePending\]\# pending connections from a max. of \#\[numMax\]\# allowed incoming connections.==���������������� #[numActiveRunning]# ���������������� �� #[numActivePending]# ������������������ �������������������� ���� ���������������� #[numMax]# ���������������������� ���������������� ��������������������.
Showing \#\[numActiveRunning\]\# active connections from a max. of \#\[numMax\]\# allowed incoming connections.==���������������� #[numActiveRunning]# ����������������  �������������������� ���� ���������������� #[numMax]# ���������������������� ���������������� ��������������������.
Protocol</td>==����������������</td>
Duration==������������������������
Up-Bytes==������������
Source IP\[:Port\]==IP-���������� ������������������[:��������]
Dest. IP\[:Port\]==IP-���������� ��������������������[:��������]
Command</td>==��������������</td>
Used==������������������������
Close==������������������
Waiting for new request nr.==���������������� ������������ ��������������
Outgoing Connections==������������������ ��������������������
Showing \#\[clientActive\]\# pooled outgoing connections used as:==���������������� #[clientActive]# ������������������������ ������������������ ��������������������, ������������������������ ������:
Duration==������������������������
#ID==ID
#-----------------------------

#File: ContentControl_p.html
#---------------------------
Content Control<==�������������������� ������������������<
Peer Content Control URL Filter==�������������������� ������������������ ��������
With this settings you can activate or deactivate content control on this peer.==������ ������������������ ������������������ ���������������� ������ ������������������ �������������������� ������������������ ������ ������������ ��������.
Use content control filtering:==������������������������ ������������ �������������������� ������������������:
>Enabled<==>����������������<
Enables or disables content control.==������������������ ������ �������������������� �������������������� ������������������.
Use this table to create filter:==������������������������ ������ �������� ������ ���������������� ��������������:
Define a table. Default:==������������ ���������������� ��������. ����-������������������:
Content Control SMW Import Settings==������������ ���������������� �������������������� ������������������ SMW
With this settings you can define the content control import settings. You can define a==������ ������������������ ������������������ ������������ ������������������ �������������� ���������������� �������������������� ������������������ 
Semantic Media Wiki with the appropriate extensions.==Semantic Media Wiki �� �������������������������������� ������������������������.
SMW import to content control list:== ������������ SMW �� ������������ �������������������� ������������������:
Enable or disable constant background synchronization of content control list from SMW \(Semantic Mediawiki\). Requires restart!==������������������ ������ �������������������� �������������������� �������������� �������������������������� ������������ �������������������� ������������������ ���� SMW (Semantic Mediawiki). ���������������������� �������������������� ������������������!
SMW import base URL:==������������ ���� �������������������������� �������� SMW:
Define base URL for SMW special page "Ask". Example: ==�������������� ������������ ���� �������� SMW ���� ���������������������� ���������������� "Ask". ����������������: 
SMW import target table:==�������� �������������������� �������������� SMW:
Define import target table. Default: contentcontrol==�������������� �������� �������������������� ��������������.  ����-������������������: contentcontrol
Purge content control list on initial sync:==�������������� ������������ �������������������� ������������������ �� ������������ ��������������������������:
Purge content control list on initial synchronisation after startup.==�������������� ������������ �������������������� ������������������ �� ������������ �������������������������� ���������� �������������� ������������������.
"Submit"=="������������������"
#-----------------------------


#File: CookieMonitorIncoming_p.html
#---------------------------
Incoming Cookies Monitor==�������������� �������������������� ��������
Cookie Monitor: Incoming Cookies==�������������� ��������: �������������������� ��������
This is a list of Cookies that a web server has sent to clients of the YaCy Proxy:==������ ������������ ��������, �������������� ������-������������ ���������������� ���������������� ���������� ������������ YaCy:
Showing \#\[num\]\# entries from a total of \#\[total\]\# Cookies.==���������������� #[num]# �������������� �������� ���� #[total]#.
Sending Host==��������-����������������������
Date</td>==��������</td>
Receiving Client==������������-��������������������
>Cookie<==>��������<
"Enable Cookie Monitoring"=="�������������������� �������� ����������������"
"Disable Cookie Monitoring"=="�������������������� �������� ����������������"
#-----------------------------

#File: CookieMonitorOutgoing_p.html
#---------------------------
Outgoing Cookies Monitor==�������������� ������������������������ ��������
Cookie Monitor: Outgoing Cookies==�������������� ��������: ������������������������ ��������
This is a list of cookies that browsers using the YaCy proxy sent to webservers:==������ ������������ ��������, �������������� �������� �������������������� �������������������� ������-���������������� ���������� ������������ YaCy:
Showing \#\[num\]\# entries from a total of \#\[total\]\# Cookies.==���������������� #[num]# �������������� �������� ���� #[total]#.
Receiving Host==��������-��������������������
Date</td>==��������</td>
Sending Client==������������-����������������������
>Cookie<==>��������<
"Enable Cookie Monitoring"=="�������������������� �������� ����������������"
"Disable Cookie Monitoring"=="�������������������� �������� ����������������"
#-----------------------------

#File: CrawlCheck_p.html
#---------------------------
Crawl Check==���������������� ����������������������������
This pages gives you an analysis about the possible success for a web crawl on given addresses.==���������� ���� ������������ ������������������ ������������ ������ ������������ ���� ���������������������� �������������������� ����������������������������.
List of possible crawl start URLs==������������ ������������ ������ ����������������
"Check given urls"=="������������������"
>Analysis<==>������������<
#>URL<==>URL<
>Access<==>������������<
>Robots<==>������������<
>Crawl-Delay<==>���������������� ��������������������<
>Sitemap<==>���������� ����������<
#-----------------------------

#File: CrawlProfileEditor_p.html
#---------------------------
Crawl Profile Editor==������������������ �������������� ����������������������������
>Crawl Profile Editor<==>������������������ �������������� ����������������������������<
>Crawler Steering<==>�������������������� ������������������������<
>Crawl Scheduler<==>���������������������� ����������������������������<
>Scheduled Crawls can be modified in this table<==>������������������������������ ���������������������������� ���������� ���������������� �� �������� ��������������<
Crawl profiles hold information about a crawl process that is currently ongoing.==�������������� ���������������� �������������������� �� �������������� ����������������������������.

#Crawl profiles hold information about a specific URL which is internally used to perform the crawl it belongs to.==Crawl Profile enthalten Informationen ��ber eine spezifische URL, welche intern genutzt wird, um nachzuvollziehen, wozu der Crawl geh��rt.
#The profiles for remote crawls, <a href="ProxyIndexingMonitor_p.html">indexing via proxy</a> and snippet fetches==Die Profile f��r Remote Crawl, <a href="ProxyIndexingMonitor_p.html">Indexierung per Proxy</a> und Snippet Abrufe
#cannot be altered here as they are hard-coded.==k��nnen nicht ver��ndert werden, weil sie "hard-coded" sind.
Crawl Profile List==������������ ���������������� ����������������������������
Crawl Thread==���������� ����������������������������
Status==������������������
Start URL==������������������ URL-������������
>Depth</strong>==>�������������� ����������������������������</strong>
Must Match==������������ ������������������
Must Not Match==���� ������������ ������������������
MaxAge</strong>==��������. ��������������</strong>
#Auto Filter Depth</strong>==������������������ ��������������</strong>
#Auto Filter Content</strong>==������������������ ����������������</strong>
Domain Counter Content==�������������������� ���������������������� ������������
Max Page Per Domain</strong>==���������������� �������������� ���� ����������</strong>
Accept==��������������
Fill Proxy Cache==�������������������� �������� ������������
Local Text Indexing==���������������������������� ������������������ ������������������ ������������
Local Media Indexing==���������������������������� ������������������ ����������-������������
Remote Indexing==������������������ ����������������������������
#Status / Action==������������������ / ����������������
#terminated::active==����������������::��������������
no::yes==������::����
Running==����������������������
"Terminate"=="����������������"
Finished==������������������
"Delete"=="��������������"
"Delete finished crawls"=="�������������� ���������������������� ��������������"
Select the profile to edit==���������� �������������� ������ ������������������
"Edit profile"=="���������������� ��������������"
An error occurred during editing the crawl profile:==������������ ���� ���������� ������������������ ��������������:
Edit Profile==���������������� ��������������
"Submit changes"=="���������������������� ������������������"
Name==����������������
Collections \(comma-separated list\)==������������������ (������������ ���������� ��������������)
URL Must-Match Filter
URL Must-Not-Match Filter
IP Must-Match Filter
IP Must-Not-Match Filter
Country Must-Match Filter
URL No-Depth-Limit Must-Match Filter
Indexing URL Must-Match Filter
Indexing URL Must-Not-Match Filter
Indexing Content Must-Match Filter
Indexing Content Must-Not-Match Filter
Cache Strategy \(NOCACHE,IFFRESH,IFEXIST,CACHEONLY\)==�������������������������� �������� (������ ��������, �������� ����������, �������� ��������������������, ������������ ������)
Crawl Depth==�������������� ��������������������
Recrawl If Older==����������������������������������, �������� ������������
Domain Max. Pages==���������������� �������������� ������������
CrawlingQ / '?'-URLs==�������������������������� Q / '?'-������������
Index Text==�������������������������� ����������
Index Media==�������������������������� ��������������������
Store in HTCache==������������������ �� ��������
Remote Indexing==������������������ ����������������������������
Put all linked urls into index without parsing==������������������ ������ ������������������������ ������������ �� ������������ ������ ��������������
#-----------------------------


#File: CrawlResults.html
#---------------------------
Crawl Results<==�������������������� ����������������������������<
>Crawl Results Overview<==>���������� ���������������������� ����������������������������<
These are monitoring pages for the different indexing queues.==������ ���������������� ���������������������� ����������������x ���������������� ��������������������.
YaCy knows 5 different ways to acquire web indexes. The details of these processes \(1-5\) are described within the submenu's listed==YaCy ���������������� ������-������������ ���������� �������������������� ������������������. ������������ �������� ������������������ (1-5) ���� ������������ ��������������, ������������ ������������ �������� ������������.
above which also will show you a table with indexing results so far. The information in these tables is considered as private,==������ ������ ���������������������������� �������������������� ���������������� ������������ ����������������,
so you need to log-in with your administration password.==���� ���������������������� ������������ ������������ ����������������������������.
Case \(6\) is a monitor of the local receipt-generator, the opposed case of \(1\). It contains also an indexing result monitor but is not considered private==�������������� (6) �������������������� ������������������ ���������� ��������������, �� �������������� ���� ���������������� (1). ���������� ���������� ������������������������ �������������������� ���������������������������� ���� �������������������� ������������ ������������,
since it shows crawl requests from other peers.==�� ������������ �������������� ������������������������ ���� ������������ ����������.
Case \(7\) occurs if surrogate files are imported==�������������� (7) �������������������� �������������������� ������������ ������������
The image above illustrates the data flow initiated by web index acquisition.==���� ���������������������� �������� �������������� ���������� ������������, ���������������������������� ������-����������������.
Some processes occur double to document the complex index migration structure.==������������������ ���������������� ���������������������� ������������.
\(1\) Results of Remote Crawl Receipts==(1) ������������������ ���������������������� �������������������� ����������������������������
This is the list of web pages that this peer initiated to crawl,==���������� �������������� ������-����������������, ���������������������������� ���������� ���������� ������ ����������������������������,
but had been crawled by <em>other</em> peers.==���� ������������������������������������ �������������� ������������.
This is the 'mirror'-case of process \(6\).==������ ���������������� ���������������� ���������������������� ����������������������������. (6)
<em>Use Case:</em> You get entries here, if you start a local crawl on the 'Index Creation'-Page and check the==���� ������������ ���������������� ����������, �������������������� ������������������ ���������������������������� ���� ���������������� '����������������������������/������������ ��������' �� ��������������������
'Do Remote Indexing'-flag. Every page that a remote peer indexes upon this peer's request== �������� '������������������ ������������������ ����������������������������'. ������������ ����������������, ������������������������������������ ������������������ ����������
is reported back and can be monitored here.== ������������������������ ����������.
\(2\) Results for Result of Search Queries==(2) �������������������� ������������������ ����������������
This index transfer was initiated by your peer by doing a search query.==���������������� �������������� �������� ������������������������ ���������� ���������� ���� ���������� �������������������� ��������������.
The index was crawled and contributed by other peers.==�������������������� �������������������������� �������������� ������������.
<em>Use Case:</em> This list fills up if you do a search query on the 'Search Page'==���������� ������������������������ ������������ ����������������, �������������������������� �������� ���� ���������������� ������������.
\(3\) Results for Index Transfer==(3) �������������������� ���������������� ��������������
The url fetch was initiated and executed by other peers.==�������������������� ������������ �������� ���������������������� �� ������������������ �������������� ������������.
These links here have been transmitted to you because your peer is the most appropriate for storage according to==������ ������������ �������� ���������������� ������, ������������ ������ ������ �������� ���������� ���������������� ������ ���� ����������������,
the logic of the Global Distributed Hash Table.==�� ������������������������ �� �������������� �������������������� DHT.
<em>Use Case:</em> This list may fill if you check the 'Index Receive'-flag on the 'Index Control' page==�������� ������������ ���������� ����������������������, �������� ���� ���������������� "���������� ��������������" ���� ���������������� "������������������ ��������"
\(4\) Results for Proxy Indexing==(4) ��������������������  ���������������������������� ���������� ������������
These web pages had been indexed as result of your proxy usage.==������ ������-���������������� �������� �������������������������������� �� �������������������� �������������������������� �������� ������������.
No personal or protected page is indexed==������������ ������ �������������������� ���������������� ���� ��������������������������.
such pages are detected by Cookie-Use or POST-Parameters \(either in URL or as HTTP protocol\)==���������� ���������������� ������������������������ ���� ������������������ HTTP-������������������ (�������������������������� �������� ������ HTTP-����������������������) ������ ���� �������������������� POST (�� ������������ ������ ������������������������ ���������� HTTP-����������������)
and automatically excluded from indexing.==�� �������������������������� ���������������������� ���� ����������������������������.
<em>Use Case:</em> You must use YaCy as proxy to fill up this table.==�������������� ���������� ���������������������� ������ �������������������������� �������� YaCy �� ���������������� ������������-��������������.
Set the proxy settings of your browser to the same port as given==�������������� ������������������ �������� (����-������������������ 8090) �� �������������������� ������������ �� ���������� ����������������.
on the 'Settings'-page in the 'Proxy and Administration Port' field.==
\(5\) Results for Local Crawling==(5) �������������������� �������������������� ����������������������������
These web pages had been crawled by your own crawl task.==������ ������-���������������� �������� �������������������������������� ���������� ���������� ���� ������������ ����������������.
<em>Use Case:</em> start a crawl by setting a crawl start point on the 'Index Create' page.==������������������ ��������������������, ������������ ������������������ ���������� ���� ���������������� "����������������������������/������������ ��������"
\(6\) Results for Global Crawling==(6) �������������������� ���������������������� ����������������������������
These pages had been indexed by your peer, but the crawl was initiated by a remote peer.==������ ���������������� �������������������������������� ���������� ����������, ���� �������������������� ������ ���������������������� ������������������ ����������..
This is the 'mirror'-case of process \(1\).==������ ���������������������������������� ���������������� (1).
<em>Use Case:</em> This list may fill if you check the 'Accept remote crawling requests'-flag on the '<a href="RemoteCrawl_p.html">Index Create</a>' page==�������� ������������ ���������� ����������������������, �������� ���� ���������������� "������������������ ������������������ ����������������������������" ���� ���������������� '<a href="RemoteCrawl_p.html">������������������ ����������������������������</a>'.
The stack is empty.==������������ ��������.
Statistics about \#\[domains\]\# domains in this stack:==�� �������� �������������� ������������ �� #[domains]# ��������������:
\(7\) Results from surrogates import==\(7\) �������������������� ���������������������� ��������������
These records had been imported from surrogate files in DATA/SURROGATES/in==������ ������������ �������������������������� ���� �������������������� ������������ �� DATA/SURROGATES/in
<em>Use Case:</em> place files with dublin core metadata content into DATA/SURROGATES/in or use an index import method==������������������ ���������� �� ���������������������� ���������������� ������������������ ���������������������� �������� �� DATA/SURROGATES/in ������ ���������������������� ������������ ���������������������������� ��������������
\(i.e. <a href="IndexImportMediawiki_p.html">MediaWiki import</a>, <a href="IndexImportOAIPMH_p.html">OAI-PMH retrieval</a>\)==(����������������, <a href="IndexImportMediawiki_p.html">������������ MediaWiki ������������</a>, <a href="IndexImportOAIPMH_p.html">������������ OAI-PMH</a>\)
>Domain==>����������
#>URLs==>������������
"delete all"=="�������������� ������"
Showing all \#\[all\]\# entries in this stack.==���������������� ������ #[all]# ��������������.
Showing latest \#\[count\]\# lines from a stack of \#\[all\]\# entries.==���������������� ������������������ #[count]# �������������� ���� #[all]#.
"clear list"=="���������������� ������������"
#Initiator==������������������
>Executor==>����������������������
>Modified==>����������������
>Words==>����������
>Title==>������������������
#URL==������������
"delete"=="��������������"
>Collection==>������������������
Blacklist to use==������������������������ ������������ ������������
"del & blacklist"=="�������������� �� ����������������������"
#-----------------------------

#File: CrawlStartExpert.html
#---------------------------
Expert Crawl Start==���������������������� ����������������������������
Start Crawling Job:==������������������ ����������������������������:
You can define URLs as start points for Web page crawling and start crawling here.==���������� ������������ �������������� ������������������ ������������ �� ������������������ ����������������������������.
\"Crawling\" means that YaCy will download the given website, extract all links in it and then download the content behind these links.=="����������������������������" ����������������, ������ YaCy ���������������� ������������ ����������, ���������������� ������ ������������ �� ���������������� �������������������� ���� ���������������������� ��������������. 
This is repeated as long as specified under \"Crawling Depth\".==������������������������ ���������������������������� �������������� ���� ���������������� "�������������� ����������������������������".
A crawl can also be started using wget and the==���������������������������� ���������� ���������� ������������������, ������������������ wget ��
>post arguments<==>POST-������������������<
> for this web page.==> ���� �������� ������-����������������.
Click on this API button to see a documentation of the POST request parameter for crawl starts.==�������������� ������ ������������������ ������������������������ ���� �������������������� POST-���������������� ������ �������������� ����������������������������.
>Crawl Job<==>����������������������������<
A Crawl Job consist of one or more start point, crawl limitations and document freshness rules.==���������������������������� �������������� ���� ���������� ������ ���������� ������������������ ����������, ���������������������� �� ������������ ���������������������������� ��������������������.

>Start Point<==>������������������ ����������<
One Start URL or a list of URLs:<br/>\(must start with http:// https:// ftp:// smb:// file://\)==�������� ������ ������������������ ������������:<br/>(������������ �������������������� �� http:// https:// ftp:// smb:// file://)
Define the start-url\(s\) here. You can submit more than one URL, each line one URL please.==�������������� �������� ������ ������������������ ������������������ ������������ ����������. ������������������ ������������ �������������������� �������������������� ����������������.
Each of these URLs are the root for a crawl start, existing start URLs are always re-loaded.==������������ ���� �������� ������������ ���������������������� �� ������������ ����������������������������, ������������������������ ������������ ������������ ������������������������������.


>From Link-List of URL<==>���� ������������ ������������<
From Sitemap<==���� ���������� ����������<
From File \(enter a path<br/>within your local file system\)==���� ���������� (�������������� ��������<br/>�� ���������������� ���������� ������������������ ��������������)
Existing start URLs are always re-crawled.==������������������������ ������������������ ������������ ������������ ����������������������������������.
Other already visited URLs are sorted out as \"double\", if they are not allowed using the re-crawl option.==������ �������������������� ������������ ���������������������� ������ ������������������, �������� ���� ������������������ ���� ����������������������������.

A web crawl performs a double-check on all links found in the internet against the internal database. If the same url is found again,==������-�������������������� ������������ �������������� ������ ������������ �� ������������������ �� �������������������� ���������� ������������. �������� ������������������ ������������ �������� �������������� ����������,
then the url is treated as double when you check the \'no doubles\' option. A url may be loaded again when it has reached a specific age,== ���� ������������ ������������������ ������������������. �� ���������������������� ���� ����������������, ������������ ���������� �������� ������������������ ����������������.
#to use that check the \'re-load\' option. When you want that this web crawl is repeated automatically, then check the \'scheduled\' option.==������ ���������������������������� ���������������� ���� ������������ ������������������������ ����������������������.
#In this case the crawl is repeated after the given time and no url from the previous crawl is omitted as double.==�� �������� ������������ �������������������� ���������������������� ���������� �������������������� �������������� �� ������������������ ������������ ������������������������.
#Must-Match Filter==������������ ��������������������
Use filter==������������������������ ������������
Restrict to start domain\(s\)==������������������ ������������ ������������
Restrict to sub-path\(s\)==������������������ ���������� ��������
#The filter is an emacs-like regular expression that must match with the URLs which are used to be crawled;==������������ ������ emacs-���������������� �������������������� ������������������, �������������� ������������ ������������������ �� ���������������� ������ ��������������������;
#The filter is a <a href=\"http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html\">regular expression</a>==������������ ������ <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/util/regex/Pattern.html">�������������������� ������������������</a>
#that must match with the URLs which are used to be crawled; default is \'catch all\'.==�������������� ������������ ������������������ �� ���������������� ������ ��������������������; ����-������������������ '�������������� ������'.
Example: to allow only urls that contain the word 'science', set the must-match filter to '.*science.*'.==����������������, ������ �������������������� ������������ ������������, �������������������� ���������� 'science' , ���������� �������������������� ������������ '.*science.*'.
You can also use an automatic domain-restriction to fully crawl a single domain.==���� ������������ ���������� ������������������������ ���������������������������� ���������������������� ������������ ������ ������������ ���������������������������� ���������������� ������������.
Attention: you can test the functionality of your regular expressions using the <a href="/RegexTest.html">Regular Expression Tester</a> within YaCy</a>.==����������������! ���� ������������ ������������������ ������������������������ ���������� �������������������� ������������������ ������������������ <a href="/RegexTest.html">������������</a> �� YaCy</a>.
#Must-Not-Match Filter==������������ "���� ������������ ������������������"
#This filter must not match to allow that the page is accepted for crawling.==Dieser Filter muss nicht passen, um zu erlauben, dass die Seite zum crawlen akzeptiert wird.
#The empty string is a never-match filter which should do well for most cases.==������������ ������������ ���������������� ������������ "�������������� ���� ������������������", �������������� ������������ ���������������� �� ���������������������� ��������������.
If you don't know what this means, please leave this field empty.==�������� ���� ���� ������������, ������ ������ ����������������, ���� ���������������� ������ �������� ������������.
#Re-crawl known URLs:==���������������������������� ������������������ ������������:
#It depends on the age of the last crawl if this is done or not: if the last crawl is older than the given==������ �������������� ���� �������� �������������������� ����������������������������, �������� ���� ������ ������ ���� ������ ����������������: �������� ������������������ ���������������������������� ������������, ������ ������������������
#Auto-Dom-Filter:==������������ ��������-������������:
#This option will automatically create a domain-filter which limits the crawl on domains the crawler==������ ���������� ������������������ �������������������������� ������������������ ������������, �������������� ������������������������ �������������������� ��������������.
#will find on the given depth. You can use this option i.e. to crawl a page with bookmarks while==���������� ������������ ���� ���������������� ��������������. ���� ������������ ������������������������ ������ ����������, ����������������, ������ �������������������� ���������������� �� ��������������������, ���� ����������
#restricting the crawl on only those domains that appear on the bookmark-page. The adequate depth==���������������������� ���������������������������� ������������ ��������������, �������������� �������������� ���� ���������������� ����������������. �������������������� ��������������
#for this example  1.==������ ���������� �������������� ���������� 1.
#The default value 0 gives no restrictions.==����-������������������ ������������ ���������������� 0 - ������ ����������������������.
#Maximum Pages per Domain:==���������������� �������������� ���� ����������:
#Page-Count==���������� ��������������
You can limit the maximum number of pages that are fetched and indexed from a single domain with this option.==���� ������������ �������������������� ������������������������ ���������� ���������������������� �� ������������������������������������ �������������� ������������ ������������ �� �������������� �������� ����������.
You can combine this limitation with the 'Auto-Dom-Filter', so that the limit is applied to all the domains within==���� ������������ �������������������� ������ ���������������������� �� ���������������� '��������-����������' ������ ������ ������ ���������������������� ���������������������� ���� �������� �������������� ������
the given depth. Domains outside the given depth are then sorted-out anyway.== ���������������� ������������. ������������ ���� ������������������ �������������������� ������������ ���������������������� �� ���������� ������������.
#dynamic URLs==������������������������ URL-������������
Document Cache<==������ ������������������<
Store to Web Cache==�������������� �� ������-��������
This option is used by default for proxy prefetch, but is not needed for explicit crawling.==������ ���������� ������������������������ ����-������������������ ������ ������������, ���� ���� ������������������������ ������ ������������ ����������������������������.
A questionmark is usually a hint for a dynamic page. URLs pointing to dynamic content should usually not be crawled.==���������������������������� �������� ������������ ���������������� ������������������������ ����������������. ������������, ���������������������� ���� ������������������������ ��������������. ������������ ���� ��������������������������.
However, there are sometimes web pages with static content that== ������������, ������������ ���������������������� ������-���������������� ���� ���������������������� ��������������������, ��������������
is accessed with URLs containing question marks. If you are unsure, do not check this to avoid crawl loops.==���������������� ���� ��������������, �������������������� ���������������������������� ��������. �������� ���� ���� ��������������, ���� ���� ������������������ ������ ����������, ���������� ���������������� �������������������� ����������������������������.
Following frames is NOT done by Gxxg1e, but we do by default to have a richer content. \'nofollow\' in robots metadata can be overridden; this does not affect obeying of the robots.txt which is never ignored.==
Accept URLs with query-part \(\'\?\'\):==������������������ ������������ �� ('?') �� ���������� ��������������:
Obey html-robots-noindex:==������������������ html-robots-noindex:
Policy for usage of Web Cache==���������������� �������������������������� ������-��������
The caching policy states when to use the cache during crawling:==���������������� ������������������ ����������������������, ���������� ������ ������������������������ ���� ���������� ��������������������:
no&nbsp;cache==������&nbsp;��������
if&nbsp;fresh==��������&nbsp;������������&nbsp;������
if&nbsp;exist==��������&nbsp;������ ��������������������
cache&nbsp;only==������������&nbsp;������
never use the cache, all content from fresh internet source;==�������������� ���� ������������������������ ������, �������� �������������� ���� ������������ ����������������-������������������;
use the cache if the cache exists and is fresh using the proxy-fresh rules;==������������������������ ������, �������� ������ �������������������� �� ������ ���������� �������������������������� ������������ ������������
use the cache if the cache exist. Do no check freshness. Otherwise use online source;==������������������������ ������, �������� ������ ��������������������. ���� ������������������ ���� ��������������������. ���������� ������������������������ ����������������-����������������;
never go online, use all content from cache. If no cache exist, treat content as unavailable==������������ ��������������, ������������������������ �������� �������������� ���� ��������. �������� ������ ���� ��������������������, ���� �������������� ������ �������������� ��������������������.
>Crawler Filter<==>������������ ����������������������<
These are limitations on the crawl stacker. The filters will be applied before a web page is loaded.==���������������������� ������������ ����������������������. �������������� ���������������������� ���� ���������������� ����������������.
Crawling Depth<==�������������� ����������������������������<
This defines how often the Crawler will follow links \(of links..\) embedded in websites.==��������������������, ������ ���������� �������������������� ���������� �������� ���� �������������� (���� ������������ ...) ������-������������.
0 means that only the page you enter under \"Starting Point\" will be added==�������� ����������������, ������ ������������ ������������������ ���������������� ���������� ������������������
to the index. 2-4 is good for normal indexing. Values over 8 are not useful, since a depth-8 crawl will==������ ��������������������. 2-4 ������ �������������������� ����������������������������. ���������������� ���������� 8 ������������������������ ���� ��������������������������, ������������������ ���������� �������������� ���������������������������� ������������������������
index approximately 25.600.000.000 pages, maybe this is the whole WWW.==���������������� 25.600.000.000 �������������� �� ��������������, ���������������� ������ �������� WWW.
also all linked non-parsable documents==���������� ������ ������������������ ����-������������������������������������ ������������������
Unlimited crawl depth for URLs matching with==���������������������������� �������������� ���������������������������� ������ ������������ ���������������������� ��
Maximum Pages per Domain==������������������������ ���������� �������������� ������������
>Use<==>������������������������<
>Page-Count<==>��������������<
misc. Constraints==������������ ����������������������
>Load Filter on URLs<==>������������ ������������<
>Load Filter on IPs<==>������������ IP-��������������<
Must-Match List for Country Codes==������������ ����������
Crawls can be restricted to specific countries. This uses the country code that can be computed from==���������������������� ���������� �������� ������������������ ������ ������������������������ ����������. ������ �������� ������������������������ ������ ������������, �������������� ���������� �������� ���������������� ����
the IP of the server that hosts the page. The filter is not a regular expressions but a list of country codes, separated by comma.==IP-������������ ��������������, ���� �������������� ������������������ ����������������. ������������ ���� �������������������� �������������������� ������������������. ������������ ���������� ���������� �������������������������� ���������� ��������������.
no country code restriction==O�������������������� ���� �������������� ����������������������
Filter on URLs==������������ ������������
Document Filter==������������ ��������������������
These are limitations on index feeder. The filters will be applied after a web page was loaded.==���������������������� ���� ������������������ ��������������. �������������� ���������������������� ���������� ���������������� ������-����������������.
>Filter on URLs<==������������ ������������<
The filter is a==������������ ������
>regular expression<==>�������������������� ������������������<
that <b>must not match</b> with the URLs to allow that the content of the url is indexed.==�������������� <b>���� ������������ ������������������</b> �� ����������������, �������� �������������� ���� �������� ������������ ������������������������������.
> must-match<==> ������������ ������������������<
> must-not-match<==> ���� ������������ ������������������<
\(must not be empty\)==(���� ������������ �������� ������������)
Filter on Content of Document<br/>\(all visible text, including camel-case-tokenized url and title\)==������������ ���������������������� ������������������<br/>(�������� �������������� ����������, �������������� ������������ �������������������� ������������ �� ������������������)
Clean-Up before Crawl Start==�������������� ���������� �������������� ����������������������������
>No Deletion<==>������ ����������������<
>Re-load<==>��������������������������<
For each host in the start url list, delete all documents \(in the given subpath\) from that host.==������ �������������� ���������� �� ������������������ ������������ ������������, �������������� ������ ������������������ (�������� �� ������������������) ���� ����������.
Delete sub-path==�������������� ���������� ������������
Delete only old==�������������� ������������ ��������������������
Do not delete any document before the crawl is started.==���� �������������� ���������� ������������������ ���������� �������������� ����������������������������.
Treat documents that are loaded==�������������� ���������������������� ������������������
> ago as stale and delete them before the crawl is started.==> ����������������������, �� �������������� ���� ���������� �������������� ����������������������������.
After a crawl was done in the past, document may become stale and eventually they are also deleted on the target host.==�������� ���������������������������� �������� ������������������ ������������, ���� ���������������� ���������� ���������������� ������������������������ �� �������� �������� ������������ ���� ���������������������������� ����������.
To remove old files from the search index it is not sufficient to just consider them for re-load but it may be necessary==���������������������������� ������������������������ ���������� ���������������� ������������ ������������ ���� �������������������� ��������������, ���� ���������� �������� ��������������������,
to delete them because they simply do not exist any more. Use this in combination with re-crawl while this time should be longer.==������ ������ ������������ ���������� ������ ���� ��������������������. �������������������������� �������� �������������� ������������ �� ������������������������������ ���������� ������������ ���������� ��������������.

Double-Check Rules==�������������� ������������������ ����������������
No&nbsp;Doubles==������&nbsp;����������������
A web crawl performs a double-check on all links found in the internet against the internal database. If the same url is found again,==������-�������������������� ������������������ ������������������ ���������������� �������� ������������, ������������������ �� ������������������ �� �������������������� ���������� ������������. �������� ������������ �������������� ����������,
then the url is treated as double when you check the \'no doubles\' option. A url may be loaded again when it has reached a specific age,==���� ������ ������������������ ��������������������, �������� ���� ���������������� ���������� "������ ����������������". ������������ ���������� �������� ������������������ ����������, �������� ������ ���������������� ��������������������������  ����������������.
to use that check the \'re-load\' option.==������ ���������� ���������������� ���������� "������������������ ����������������".
>Re-load<==>������������������ ����������������<
Treat documents that are loaded==�������������� ���������������������� ������������������
> ago as stale and load them again. If they are younger, they are ignored.==> ���������������������� �� ������������������ ���� ����������. �������� ������ ������������, ���� ������ ������������������������.
Never load any page that is already known. Only the start-url may be loaded again.==�������������� ���� ������������������ ���������� ����������������, �������� ������ ������ ����������������. ������������ ������������������ ������������ ���������� �������� ������������������ ����������.

Robot Behaviour==������������������ ������������
Use Special User Agent and robot identification==������������������������ ���������������������� User Agent �� �������������������������� ������������
You are running YaCy in non-p2p mode and because YaCy can be used as replacement for commercial search appliances==���� ������������������ YaCy �� ����-p2p ������������, �������������� YaCy ���������� ���������������������� �� ���������������� ������������ ������������������������ ������������������ ����������������
\(like the GSA\) the user must be able to crawl all web pages that are granted to such commercial plattforms.==(����������������, GSA). ������������������������ ������������ ���������� ���������������������� �������������������������� ������ ������-����������������, ���������������������������� �������������������������� ����������������������.
Not having this option would be a strong handicap for professional usage of this software. Therefore you are able to select==�������������������� �������� ���������� ���������� ������������ ���������������������������� ���������������������������������� �������������������������� �������� ������������������. �������������� ���� ������������ ��������������
alternative user agents here which have different crawl timings and also identify itself with another user agent and obey the corresponding robots rule.==���������������������������� User-Agent'���� ����������. ������ ���������� ���������� ������������������ ���������������� ���������������������������� �� ���������� �������������������������������� �������� �� ������������ User-Agent'���� �� ������������������ ������������������������������ �������������� ��������������.
Index Administration==�������������������� ����������������
Do Local Indexing==������������������ ������������������ ����������������������������
index text==������������ ������������
index media==������������ ����������-������������
This enables indexing of the webpages the crawler will download. This should be switched on by default, unless you want to crawl only to fill the==������������������ ���������������������������� ������-��������������, �������� �������������������� �������������������� ����������������. ����-������������������ ����������������.
Document Cache without indexing.==������ �������������������� ������ ����������������������������.
Do Remote Indexing==������������������ ������������������ ����������������������������
Describe your intention to start this global crawl \(optional\)==���������������� ������������ ������������������ ������������ �������������������� ���������������������������� (��������������������������).
This message will appear in the 'Other Peer Crawl Start' table of other peers.==������ ������������������ ���������� ������������������������ �� �������������� ������������ ���������� �� �������� '������������ �������� ���������� ����������������������������'.  
If checked, the crawler will contact other peers and use them as remote indexers for your crawl.==�������� ����������������, ���� �������������������� ���������� ���������������������� �� �������������� ������������ �� ������������������������ ���� ������ �������������������� ����������������������������.
If you need your crawling results locally, you should switch this off.==������������������, �������� �������������� ���������������� �������������������� ���������������������������� ����������������.
Only senior and principal peers can initiate or receive remote crawls.==������������ �������������� �� �������������� �������� ���������� ������������������������ ������ ������������������ ������������������ ��������������������.
A YaCyNews message will be created to inform all peers about a global crawl==������������������ YaCy ���������� �������� �������������� ������ ���������������������������� �������� ���������� �� �������������������� ����������������������������
so they can omit starting a crawl with the same start point.==�������������� ������ ���������� �������������������� ������������ ���������������������������� �� ���������� �� ������ ���� ������������������ ����������.
#Exclude <em>static</em> Stop-Words==<em>������������������</em> ���������������������� ��������-����������
#This can be useful to circumvent that extremely common words are added to the database, i.e. \"the\", \"he\", \"she\", \"it\"... To exclude all words given in the file <tt>yacy.stopwords</tt> from indexing,==������ ���������� �������� ��������������, ���������� ���� ������������������ ���������� ����������, ���������������������� �� �������� ������������. ����������������, "����", "������", "������", "��", "������", "������" �� ������ ����������. ����������, ������������������ �� ���������� <tt>yacy.stopwords</tt> ���������������������� ���� ����������������������������,
check this box.==������������������ �������� ��������.

Add Crawl result to collection\(s\)==���������������� ������������������ ���������������������������� �� ������������������
A crawl result can be tagged with names which are candidates for a collection request.==������������������ ���������������������������� ���������� �������� �������������� �� �������������� �� ������������������ ������ �������������� �� ������������������.
These tags can be selected with the==������ �������� ���������� �������� ��������������
GSA interface==�������������������� GSA
using the \'site\' operator.==�� �������������� ������������������ 'site'.
To use this option, the 'collection_sxt'-field must be switched on in the==������ �������������������������� �������� ����������, �������� 'collection_sxt' �������������� �������� ����������������.
Solr Schema==���������� Solr
"Start New Crawl Job"=="������������ ���������� ����������������������������"
#-----------------------------

#File: CrawlStartIntranet_p.html
#---------------------------
#Intranet Crawl Start==������������������ ���������������������������� ������������������
When an index domain is configured to contain intranet links,==Wenn eine Index Domain konfiguriert wurde die Intranet Links enth��lt,
the intranet may be scanned for available servers.==kann dieses Intranet auf verf��gbare Server gescannt werden.
Please select below the servers in your intranet that you want to fetch into the search index.==Bitte in der folgenden Server Liste aus Ihrem Intranet ausw��hlen, welche Sie in den Suchindex aufnehmen wollen.
This network definition does not allow intranet links.==Diese Netzwerk Konfiguration erlaubt keine Intranet Links.
A list of intranet servers is only available if you confiugure YaCy to index intranet targets.==Eine Liste mit Servern aus dem Intranet ist nur verf��gbar, wenn Sie YaCy auch konfiguriert haben Intranetseiten zu indexieren.
To do so, open the <a href=\"ConfigBasic.html\">Basic Configuration</a> servlet and select the \'Intranet Indexing\' use case.==Um diese Einstellung vorzunehmen, bitte im Servlet <a href="ConfigBasic.html">Basis Konfiguration</a> den Anwendungsfall 'Intranet Indexierung' ausw��hlen.
Available Intranet Server==������������������ ����������������-������������
#>IP<==>IP-����������<
#>URL<==>URL-����������<
>Process<==>������������������<
>not in index<==>������ �� ��������������<
>indexed<==>��������������������������������<
"Add Selected Servers to Crawler"=="���������������� ������������������ �������������� �� ��������������������"
#-----------------------------

#File: CrawlStartScanner_p.html
#---------------------------
Network Scanner==������������ ��������
YaCy can scan a network segment for available http, ftp and smb server.==YaCy ���������� ���������������������� ���������� ���������������� �������� ������ http-, ftp- �� smb-�������������� .
You must first select a IP range and then, after this range is scanned,==�������������� ���� ������������ �������������� ���������������� IP-��������������, �� ���������� ���������������� ������������������������.
it is possible to select servers that had been found for a full-site crawl.==���������� ���������� ���������� �������������� �������������� ������ �������������� ���������������������������� ����������.
No servers had been detected in the given IP range \#\[iprange\]\#.==�������������� ���� �������������������� �� ���������������� ������������������ IP-��������������. 
Please enter a different IP range for another scan.==��������������������, �������������� ������������ ���������������� IP-��������������, ������ �������������������� ������������������������.
Please wait...==��������������������, ������������������...
>Scan the network<==>������������������������ ��������<
Scan Range==���������������� ������������������������
Scan sub-range with given host==������������������������ ������������������������ ������������������ ����������
Full Intranet Scan:==������������ ������������������������ ������������������:
Do not use intranet scan results, you are not in an intranet environment!==���� ���� ������������ ������������������������ �������������������� ������������������������ ������������������, ������ ������ ���� ���� �������������������� �� ������������������!
All known hosts in the search index \(/31 subnet recommended!\)==������ ������������������ ���������� �� �������������� ������������ (/31 �������������� ��������������������������!)
only the given host\(s\)==������������ ������������������ ����������(-����)
addresses\)==������������)
Subnet<==��������������<
Time-Out<==��������-������<
>Scan Cache<==>������������������������ ��������<
accumulate scan results with access type \"granted\" into scan cache \(do not delete old scan result\)==���������������������� �������������������� ������������������������ �� ���������� �������������� "������������������" �� �������� ������������������������ (������������ �������������������� ������������������������ ���� ������������������)
>Service Type<==>������ ������������������<
#>ftp==>FTP
#>smb==>SMB
#>http==>HTTP
#>https==>HTTPS
>Scheduler<==>����������������������<
run only a scan== ������������ ����������������������
scan and add all sites with granted access automatically. This disables the scan cache accumulation.==���������������������� �� ���������������� ������ ������������������ ���������� ��������������������������. ������ ���� ���������������� ������ �������������������� ���������������������� �� �������� ������������������������.
Look every==������������������ ������������
>minutes<==>����������<
>hours<==>����������<
>days<==>��������<
again and add new sites automatically to indexer.==�� ������������������ ���������� ���������� �� �������������������� ��������������������������.
Sites that do not appear during a scheduled scan period will be excluded from search results.==����������, �������������� ���������� �������������������� ���� ���������� �������������������������������� ������������������������, ���������� �������������� ���� ���������������������� ������������.
"Scan"=="����������������������"
#The following servers had been detected:==Die folgenden Server wurden entdeckt:
#Available server within the given IP range==Verf��gbare Server innerhalb des angegebenen IP Bereichs
#>Protocol<==>����������������<
#>IP<==>IP-����������<
#>URL<==>URL-����������<
#>Access<==>������������<
#>Process<==>������������������<
#>unknown<==>��������������������<
#>empty<==>����������<
#>granted<==>������������������<
#>denied<==>������������������<
#>not in index<==>������ �� ��������������<
#>indexed<==>��������������������������������<
#"Add Selected Servers to Crawler"=="���������������� ������������������ �������������� �� ��������������������"
#-----------------------------

#File: CrawlStartSite.html
#---------------------------
YaCy '#\[clientname\]#': Crawl Start==YaCy '#[clientname]#': ���������������������������� ����������
>Site Crawling<==>���������������������������� ����������<
Site Crawler:==���������������������������� ����������:
Download all web pages from a given domain or base URL.==������������������ ������ ������-���������������� ���� �������������������� ������������ ������ ���� ������������.
>Site Crawl Start<==>������������ ���������������������������� ����������<
>Site<==>��������<
Start URL&nbsp;\(must start with==������������������ ������������&nbsp;(������������ �������������������� ��	
Link-List of URL==������������ URL-��������������
Sitemap URL==������������ ���� ���������� ����������
#>Scheduler<==>����������������������<
#run this crawl once==������������������ ���������������������������� �������� ������
#scheduled, look every==���� ��������������������, ������������
#>minutes<==>����������<
#>hours<==>����������<
#>days<==>��������<
#for new documents automatically.==��������������������������, ���� �������������� ���������� ��������������������.
>Path<==>��������<
load all files in domain==������������������ ������ ���������� �� �������� ������������
load only files in a sub-path of given url==������������������ ���������� ������������ ���� �������������� ������������������ �� URL-������������
>Limitation<==>����������������������<
not more than <==���� ������������ ������ <
>documents<==>��������������������<
#>Dynamic URLs<==>������������������������ URL-������������<
#allow <==������������������ <
#urls with a \'\?\' in the path==URL-������������ �� '?' �� ������������
Collection<==������������������<
>Start<==>������������<
"Start New Crawl"=="������������������ ���������� ����������������������������"
Hints<==������������������<
>Crawl Speed Limitation<==>���������������������� ���������������� ����������������������������<
No more that two pages are loaded from the same host in one second \(not more that 120 document per minute\) to limit the load on the target server.==���� ���������� ������ ������ ���������������� �� ������������ ���������� �� �������������� (���� ���������� ������ 120 �������������������� �� ������������), ������ ���������������������� �������������������������� �������������������� ��������������.
>Target Balancer<==>�������� ������������������������<
A second crawl for a different host increases the throughput to a maximum of 240 documents per minute since the crawler balances the load over all hosts.==������������ ���������������������������� ���� �������������� ���������� ���������������������� �������������������� ���������������������� ���������������������������� ���� 240 �������������������� �� ������������ �� �������������������������� ���������������� ���� �������� ������������.
>High Speed Crawling<==>�������������� ���������������� ����������������������������<
A \'shallow crawl\' which is not limited to a single host \(or site\)=='������������������ ����������������������������' ���� �������������������� ���� ������������ ���������� (������ ����������)
can extend the pages per minute \(ppm\) rate to unlimited documents per minute when the number of target hosts is high.==���������������� ���������������������������� ���������������� ���������� �������� ������������������ ���� ����������������������������, ���������� ���������� ������������������ ������������ ������������.
This can be done using the <a href=\"CrawlStartExpert.html\">Expert Crawl Start</a> servlet.==������ ���������� �������������� �� �������������� <a href="CrawlStartExpert.html">�������������� ������������������������ ����������������������������</a>.
>Scheduler Steering<==>�������������������� ��������������������������<
The scheduler on crawls can be changed or removed using the <a href=\"Table_API_p.html\">API Steering</a>.==�������������������� ���������������������������� ���������� �������� ���������������� ������ ��������������, ������������������ <a href="Table_API_p.html">�������������������� API</a>.
#-----------------------------

#File: Help.html
#---------------------------
#YaCy: Help==YaCy: ������������
>Tutorial==>��������������������
You are using the administration interface of your own search engine==YaCy ���������� ������������������������ ������ ���������������������� ������������������������ ������������. �������� ����������-������������������������ ������������ YaCy (���� ���������������� ����������).
You can create your own search index with YaCy==�� YaCy ���� ������������ ������������������������ �������� ���������������������� ����������
To learn how to do that, watch one of the demonstration videos below==���������� ������������ ������ ������ ��������������, ���� ������������ ���������������������� ���������� ������������������������ �������� (���� ���������������� ����������)
twitter this video==������������������ ������ ���������� �� ��������������
Download from Vimeo==������������������ ���� Vimeo
More Tutorials==������������ ��������������������
Please see the tutorials on==��������������������, ���������������� ������������ �������������������� ����
#-----------------------------

#File: HostBrowser.html
#---------------------------
Index Browser==���������������� ������������
Browse the index of \#\[ucount\]\# documents.==�� �������������� ������������������ #[ucount]# ��������������������.
Enter a host or an URL for a file list or view a list of==�������������� �������� ������ ���������� ������ ������������������ ������������ ������������, ������ ���������������������� ������������ ����
>all hosts<==>�������� ������������<
>only hosts with urls pending in the crawler<==>������������ ����������, ���������������������� �� ���������������� ����������������������<
> or <==> ������ <
>only with load errors<==>������������ �� ���������������� ����������������<
Host/URL==��������/������������:
Browse Host==���������� ����������
"Browse Host"=="���������������� ������������"
"Delete Subpath"=="�������������� ��������"
Browser for==����������������
"Re-load load-failure docs \(404s etc\)"=="�������������������������� ������������������ �� ������������ ������������ 404"
Confirm Deletion==���������������������� ����������������
>Host List<==>������������ ������������<
Count Colors:==���������������������� ������������:
Documents without Errors==������������������������������������ ������������������ ������ ������������
Pending in Crawler==������������������ �� ����������������������
Crawler Excludes<==�������������������� ����������������������<
Load Errors<==������������ ����������������<

#Load Errors \(exclusion/failure\)==������������ ����������������
#Browser for \#\[path\]\#==���������������� #[path]#
documents stored for host: \#\[hostsize\]\#==������������������ ���������������������� ������������: #[hostsize]#
documents stored for subpath: \#\[subpathloadsize\]\#==������������������ ���������������������� �� ��������������������: #[subpathloadsize]#
unloaded documents detected in subpath: \#\[subpathdetectedsize\]\#==�������������������������� ������������������, ������������������������ �� ��������������������: #[subpathdetectedsize]#
>Path<==>��������<
>stored<==>��������������������<
>linked<==>����������������������<
>pending<==>������������������<
>excluded<==>����������������������<
>failed<==>������������������<
Show Metadata==���������������� ��������������������
link, detected from context==������������, �������������������� ���� ������������������
load &amp; index==������������������ &amp; ������������
>indexed<==>��������������������������������<
>loading<==>����������������������<
Outbound Links, outgoing from \#\[host\]\# - Host List==�������������� ������������, ������������������ ���� #[host]# - ������������ ������������
Inbound Links, incoming to \#\[host\]\# - Host List==�������������������� ������������, ���������������� �� #[host]# - ������������ ������������
#browse \#\[host\]\#==���������������� #[host]#
#\#\[count\]\# URLs==#[count]# ������������
#-----------------------------

#File: HostBrowserAdmin_p.html
#---------------------------
Administration Options==���������������������� ����������
Delete all==�������������� ������
>Load Errors<==>������������ ����������������<
from index==���� ��������������
"Delete Load Errors"=="��������������"
#-----------------------------

#File: index.html
#---------------------------
YaCy \'\#\[clientname\]\#\': Search Page==YaCy '#[clientname]#': ����������
#kiosk mode==���������� ������������
>Search<==>����������<
Text==����������
Images==����������������������
Audio==����������
Video==����������
Applications==��������������������
more options...==���������������������� ����������...
#advanced parameters==���������������������������� ������������������
#Max. number of results==������������������������ ���������� ����������������������
Results per page==���������������������� ���� ����������������
Resource==������������
global==��������������������
#>local==>������������������
#Global search is disabled because==�������������������� ���������� ���������������� ������������ ������
#DHT Distribution</a> is==���������� DHT-������������</a> ist
#Index Receive</a> is==���������� ��������������</a> ist 
#DHT Distribution and Index Receive</a> are==���������� DHT-������������ �� ��������������</a>
#����������������.\#\(==deaktiviert.#(
#URL mask==������������ URL-��������������
restrict on==����������������������
show all==���������������� ������
#��berarbeiten!!!
Prefer mask==������������
Constraints==����������������������
only index pages==������������ ������������������������������������ ����������������
#"authentication required"=="������������������ ����������������������"
#Disable search function for users without authorization==������������������ ������-���������� ������ �������������������������� ������ ����������������������
#Enable web search to everyone==������������������ ������-���������� ��������
the peer-to-peer network==P2P-��������
only the local index==������������ ������������������ ������������
Query Operators==������������������ ������������
restrictions==����������������������
only urls with the &lt;phrase&gt; in the url==������������ ������������ c &lt;phrase&gt; �� ������������
only urls with the &lt;phrase&gt; within outbound links of the document==������������ ������������ �� &lt;phrase&gt; ������ �������������� ������������ ���� ����������������
only urls with extension==������������ ������������ �� ����������������������
only urls from host==������������ ������������ ���� ����������
only pages with as-author-anotated==������������ ���������������� �� ��������������������
only pages from top-level-domains==������������ ���������������� �� TLD
only resources from http or https servers==������������ �������������� �� HTTP ������ HTTPS-����������������
only resources from ftp servers==������������ �������������� �� FTP ����������������
they are rare==������ ����������
crawl them yourself==������������������������������ ���� ����������������������������
only resources from smb servers==������������ �������������� �� SMB-����������������
Intranet Indexing</a> must be selected==�������������������� ����������������</a> ������������ �������� ��������������
only files from a local file system==������������ ���������� ������������������ ���������������� ��������������
>ranking modifier<==>��������������������<
sort by date==�������������������� ���� ��������
latest first==�������������� ������������������
multiple words shall appear near==���������� ������������ �������� ����������
doublequotes==�������������� ��������������
prefer given language==������������������������ ������������������ ��������
an ISO639 2-letter code==�������������������������� ���������������� ������ ISO639
heuristics==������������������
add search results from blekko==���������������� �������������������� ���� Blekko
Search Navigation==������������������ ���� ������������
keyboard shotcuts==�������������������� ������������
tab or page-up==Tab ������ PgUp
next result page==������������������ ���������������� ����������������������
page-down==PgDn
previous result page==�������������������� ���������������� ����������������������
automatic result retrieval==���������� ����������������������
browser integration==�������������������� �� ��������������
after searching, click-open on the default search engine in the upper right search field of your browser and select 'Add "YaCy Search.."'==���������� ������������, ���������������� ���� ������������ ���� ������������������ �� ������������ �������������� �������� ���������������� �� ���������������� '���������������� ���������� YaCy'
search as rss feed==���������������������� ������ RSS-����������
click on the red icon in the upper right after a search.==���������� ������������ �������������� ���� �������������� ������������ �� ������������ ���������������� ��������.
this works good in combination with the '/date' ranking modifier.==������ ������������ ���������������� ������������ �� �������������������������� ������������������������ /date.  
See an==����������������
<a href="yacysearch.rss?query=news+%2Fdate&amp;Enter=Search&amp;verify=cacheonly&amp;contentdom=text&amp;nav=hosts%2Cauthors%2Cnamespace%2Ctopics%2Cfiletype%2Cprotocol&amp;startRecord=0&amp;indexof=off&amp;meanCount=5&amp;maximumRecords=10&amp;resource=��������������������&amp;prefermaskfilter=">example</a>.==<a href="yacysearch.rss?query=news+%2Fdate&Enter=Search&verify=cacheonly&contentdom=text&nav=hosts%2Cauthors%2Cnamespace%2Ctopics%2Cfiletype%2Cprotocol&startRecord=0&indexof=off&meanCount=5&maximumRecords=10&resource=global&prefermaskfilter="></a>.
>example==>������������
json search results==�������������������� ������������ �� �������������� JSON
for ajax developers: get the search rss feed and replace the '.rss' extension in the search result url with '.json'==������ AJAX-��������������������������: ���������������� �������������������� rss-���������� �� .rss ���� .json
#-----------------------------

#File: IndexCleaner_p.html
#---------------------------
Index Cleaner==�������������� ��������������
>URL-DB-Cleaner==>�������������� �������� ������������ URL-��������������
#ThreadAlive:
#ThreadToString:
Total URLs searched:==���������� �������������� URL-��������������:
Blacklisted URLs found:==URL-������������, ������������������ �� ������������ ������������:
Percentage blacklisted:==�������������� ���������������������� �� ������������ ������������:
last searched URL:==������������������ ������������������ URL-������������: 
last blacklisted URL found:==������������������ ������������������ URL-������������ ���� �������������� ������������:
>RWI-DB-Cleaner==>�������������� �������� ������������ URL-��������������
RWIs at Start:==RWIs beim Start:
RWIs now:==RWIs jetzt: 
wordHash in Progress:==Wort-Hash in Benutzung:
last wordHash with deleted URLs:==letzter Wort-Hash mit gel��schten URLs:
Number of deleted URLs in on this Hash:==Anzahl an gel��schten URLs in diesem Hash:
URL-DB-Cleaner - Clean up the database by deletion of blacklisted urls:==URL-DB-Aufr��umer - R��umen Sie Ihre Datenbank auf, indem Sie URLs, die auf Ihrer Blacklist stehen, l��schen:
Start/Resume==������������/��������������������
Stop==��������������������
Pause==����������
RWI-DB-Cleaner - Clean up the database by deletion of words with reference to blacklisted urls:==RWI-DB-Aufr��umer - R��umen Sie Ihre Datenbank auf, indem Sie W��rter, die mit Ihrer Blacklist verbunden sind, l��schen:
#-----------------------------

#File: IndexControlRWIs_p.html
#---------------------------
Reverse Word Index Administration==�������������������� ���������������� ���������������� ��������
The local index currently contains \#\[wcount\]\# reverse word indexes==������������������ ������������ �� ������������������ ���������� ���������������� #[wcount]# �������� ������������������ ��������������
RWI Retrieval \(= search for a single word\)==���������� ��������
#Select Segment:==�������������� ��������������:
Retrieve by Word:<==���������� ���� ����������:<
"Show URL Entries for Word"=="���������������� ������������"
Retrieve by Word-Hash==���������� ���������� ���� ������ 
"Show URL Entries for Word-Hash"=="���������������� ������������"
"Generate List"=="�������������� ������������"
Limitations==����������������������
Index Reference Size==������������ �������������� ������������
No reference size limitation \(this may cause strong CPU load when words are searched that appear very often\)==������ ���������������������� (������ ���������� ������������ ������������������ ������������������, �������� �������������� ���������� ������������ �������������� ����������)
Limitation of number of references per word:==���������������������� ���������� ������������ ���� ����������:
\(this causes that old references are deleted if that limit is reached\)==(������������ ������������ ���������� ��������������, �������� ������������������ ��������������)
"Set References Limit"=="��������������������"
#Cleanup==��������������
#>Index Deletion<==>���������������� ��������������<
#>Delete Search Index<==>�������������� ������������������ ������������<
#Stop Crawler and delete Crawl Queues==�������������������� �������������������� �� �������������� �������������� ����������������
#Delete HTTP &amp; FTP Cache==�������������� HTTP &amp; FTP ������
#Delete robots.txt Cache==�������������� ������ robots.txt
#Delete cached snippet-fetching failures during search==�������������� ������������������������ ������������������, �������������������� ���������������� ���� ���������� ������������
#"Delete"=="��������������"
No entry for word \'\#\[word\]\#\'==���� �������������� ������ ���������� \'\#\[word\]\#\'
No entry for word hash==���� �������������� ������ ������ ����������
Search result==������������������ ������������
total URLs</td>==�������������������� URL-��������������</td>
appearance in</td>==�������������������� ��</td>
in link type</td>==�� �������� ������������</td>
document type</td>==������ ������������������</td>
<td>description</td>==<td>����������������</td>
<td>title</td>==<td>��������������������</td>
<td>creator</td>==<td>������������</td>
<td>subject</td>==<td>��������</td>
<td>url</td>==<td>������������</td>
<td>emphasized</td>==<td>����������������</td>
<td>image</td>==<td>����������������������</td>
<td>audio</td>==<td>����������</td>
<td>video</td>==<td>����������</td>
<td>app</td>==<td>��������������������</td>
index of</td>==������������</td>
>Selection</td>==>����������</td>
Display URL List==�������������������� ������������ URL-��������������
Number of lines==�������������������� ����������
all lines==������ ����������
"List Selected URLs"=="����������������"
Transfer RWI to other Peer==���������������� RWI �������������� ��������
Transfer by Word-Hash==���������������� ������ ����������
"Transfer to other peer"=="���������������� �������������� ��������"
to Peer==��������
<dd>select==<dd>��������������
or enter a hash==������ ������������ ������
or peer name:==������ ������ ��������:
Sequential List of Word-Hashes==������������ ���������� �������� ����-��������������
No URL entries related to this word hash==������ ������������, ������������������ �� �������� ���������� ����������.
\#\[count\]\# URL entries related to this word hash==#[count]# ������������, ������������������ �� �������� ���������� ����������.
Resource</td>==������������</td>
Negative Ranking Factors==Negative Ranking Faktoren
Positive Ranking Factors==Positive Ranking Faktoren
Reverse Normalized Weighted Ranking Sum==Inverse normalisierte gewichtete Ranking Summe
hash</td>==������</td>
dom length</td>==���������� ������������</td>
#ybr</td>==YBR</td>
#url comps</td>
url length</td>==���������� URL-������������</td>
pos in text</td>==Pos. im Text</td>
pos of phrase</td>==Pos. des Satzes</td>
pos in phrase</td>==Pos. im Satz</td>
word distance</td>==Wort Distanz</td>
<td>authority</td>==<td>Autorit��t</td>
<td>date</td>==<td>��������</td>
words in title</td>==�������� �� ������������������</td>
words in text</td>==�������� �� ������������</td>
local links</td>==������������������ ������������</td>
remote links</td>==������������������ ������������</td>
hitcount</td>==Trefferzahl</td>
#props</td>==</td>
unresolved URL Hash==���������������������� ������ URL-������������
Word Deletion==���������������� ����������
Deletion of selected URLs==���������������� ������������������ URL-������������
delete also the referenced URL \(recommended, may produce unresolved references==�������������� ������������������ URL-������������ (��������������������������. ���������� ���������������� �� ���������������������� �������������������������� ������������
at other word indexes but they do not harm\)==���� ������������ �������������� ��������, ���� ������ ���� �������������� ����������).
for every resolvable and deleted URL reference, delete the same reference at every other word where==������ ������������ ���������������������� �� ������������������ ������������, �������������� ���������� ������������ ���� ������ ������������ ����������, ������
the reference exists \(very extensive, but prevents further unresolved references\)==������������ �������������������� (������������������������ ������������������ �������������������������� ������������ �� ��������������������). 
"Delete reference to selected URLs"=="�������������� ������������"
"Delete Word"=="�������������� ����������"
Blacklist Extension==�������������������� �������������� ������������
"Add selected URLs to blacklist"=="���������������� ������������������ URL-������������ �� ������������ ������������"
"Add selected domains to blacklist"=="���������������� ������������������ ������������ �� ������������ ������������"
#-----------------------------

#File: IndexControlURLs_p.html
#---------------------------
These document details can be retrieved as <a href="http://www.w3.org/TR/xhtml-rdfa-primer/" target="_blank">XHTML+RDFa</a>==������������ ������������������ ���������� �������� ���������������� �� �������� <a href="http://www.w3.org/TR/xhtml-rdfa-primer/" target="_blank">XHTML+RDFa</a>.
document containg <a href="http://www.w3.org/RDF/" target="_blank">RDF</a> annotations in <a href="http://dublincore.org/" target="_blank">Dublin Core</a> vocabulary.==���������������� ���������������� <a href="http://www.w3.org/RDF/" target="_blank">RDF-������������������</a> �� �������������� <a href="http://dublincore.org/" target="_blank">���������������������� ��������</a>.
The XHTML+RDFa data format is both a XML content format and a HTML display format and is considered as an important <a href="http://www.w3.org/2001/sw/" target="_blank">Semantic Web</a> content format.==������������ ������������ XHTML+RDFa �� �������� XML-�������������������� �� HTML-����������������������, ������������������������������ �� ���������������� �������������� �������������� <a href="http://www.w3.org/2001/sw/" target="_blank">�������������������������� ��������</a>.
The same content can also be retrieved as pure <a href="api/yacydoc.xml?urlhash=#[urlhash]#">XML metadata</a> with DC tag name vocabulary.==������������������ �������������������� ���������� �������� ���������� ���������������� �� �������� <a href="api/yacydoc.xml?urlhash=">XML-��������������������</a> �� ���������������� ���������� �������� DC.
Click the API icon to see an example call to the search rss API.==�������������� ���� ������������ ������ ������������������ API �������������� ������������ ���� rss-����������.
To see a list of all APIs, please visit the <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">API wiki page</a>.==������ ������������������ ������������ �������� API, ��������������������, ���������������� <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">���������������� API wiki</a>.
URL Database Administration==�������������������� ���������� ������������ ������������
#URL References Administration==�������������������� URL-����������������
The local index currently contains \#\[ucount\]\# URL references==������������������ ������������ ���������������� ���� ������������ ������������ #[ucount]# ������������
URL Retrieval==���������� ������������
#Select Segment:==�������������� ��������������:
Retrieve by URL:<==���������� ������������:<
"Show Details for URL"=="���������������� ����������������"
Retrieve by URL-Hash==���������� �������� URL-������������
"Show Details for URL-Hash"=="���������������� ����������������"
#"Generate List"=="�������������� ������������"
Cleanup==��������������
Index Deletion==���������������� ��������������
Delete local search index \(embedded Solr and old Metadata\)==�������������� ������������������ ������������ ������������ (�������������� �������� ������������ Solr �� ������������ ��������������������)
Delete remote solr index==�������������� ������������������ ������������ �������� Solr
Delete RWI Index \(DHT transmission words\)==�������������� ������������ RWI (���������������� �������� �� �������� DHT)
Delete Citation Index \(linking between URLs\)==�������������� ������������ ���������� (������������������������ ������������)
Delete HTTP &amp; FTP Cache==�������������� HTTP &amp; FTP ������
Stop Crawler and delete Crawl Queues==�������������������� �������������������� �� �������������� �������������� ����������������
Delete robots.txt Cache==�������������� ������ robots.txt
Delete cached snippet-fetching failures during search==�������������� ������������������������ ������������������, �������������������� ���������������� ���� ���������� ������������
"Delete"=="��������������"
Confirm Deletion==���������������������� ����������������
Statistics about top-domains in URL Database==������������ ���������������� �������������������������������� �������������� �� �������� ������������ ������������
Show top==����������������
domains from all URLs.==���������������� ���������� �������������������������� �������������� ���������� �������� URL.
"Generate Statistics"=="����������������"
Statistics about the top-\#\[domains\]\# domains in the database:==�������������������� #[domains]# ���������������� �������������������������������� �������������� �� �������� ������������:
"delete all"=="�������������� ������"
>Domain<==>����������<
#URLs==������������
Dump and Restore of Solr Index==���������������� ���������� �� ���������������������������� �������������� �������� Solr
"Create Dump"=="�������������� ��������"
Dump File==�������� ����������
"Restore Dump"=="������������������������ ���� ����������"
>Optimize Solr<==>���������������������� �������� Solr<
merge to max. <==�������������������� ���������������� ��<
> segments==>������������������
"Optimize Solr"=="����������������������������"
Reboot Solr Core==�������������������������� �������� Solr
"Shut Down and Re-Start Solr"=="��������������������������"
#Sequential List of URL-Hashes==Sequentielle Liste der URL-Hashes
Loaded URL Export==�������������� ������������
Export File==���������������������������� ��������
URL Filter==������������ ������������
query==������������
Export Format==������������ ����������������
#Only Domain <i>\(superfast\)==������������ ���������� <i>(���������� ������������)
Only Domain:==������������ ����������:
Full URL List:==������������ ������������ ������������:
Plain Text List \(domains only\)==�������������� ������������������ ������������ (������������ ������������)
HTML \(domains as URLs, no title\)==HTML (������������ �� �������� ������������, ������ ��������������������)
#Full URL List <i>\(high IO\)==������������ ������������ ������������ <i>(�������������� IO)
Plain Text List \(URLs only\)==�������������� ������������������ ������������ (������������ URL-������������)
HTML \(URLs with title\)==HTML (������������ �� ����������������������)
#XML (RSS)==XML (RSS)
"Export URLs"=="����������������������������"
Export to file \#\[exportfile\]\# is running ..  \#\[urlcount\]\# URLs so far==�������������� �� �������� #[exportfile]# �������������� ..  #[urlcount]# ������������ ���� ������������ ������������
Finished export of \#\[urlcount\]\# URLs to file==���������������� �������������� #[urlcount]# URL-�������������� �� ��������
Export to file \#\[exportfile\]\# failed:==�������������� �� �������� #[exportfile]# ������������������ �� ��������������:
No entry found for URL-hash==���� �������������� ������ ������ URL-������������
#URL String</td>==URL-����������</td>
#Hash</td>==������</td>
#Description</td>==����������������</td>
#Modified-Date</td>==�������� ������������������</td>
#Loaded-Date</td>==�������� ����������������</td>
#Referrer</td>==Referrer</td>
#Doctype</td>==������ ������������������</td>
#Language</td>==��������</td>
#Size</td>==������������</td>
#Words</td>==����������</td>
"Show Content"=="���������������� ��������������"
"Delete URL"=="�������������� URL-����������"
this may produce unresolved references at other word indexes but they do not harm==������ ���������� ���������������� �� �������������������������� �������������� ���� ������������ ���������� ����������������, ���� ������ ���� �������������� ����������
"Delete URL and remove all references from words"=="�������������� ������������, �������������� ������������ ���� ��������"
delete the reference to this url at every other word where the reference exists \(very extensive, but prevents unresolved references\)==l��scht die Referenz zu dieser URL und jedem anderen Wort, wo die Referenz existiert (sehr umfassend, aber bewahrt vor ungel��sten Referenzen)
#-----------------------------

#File: IndexCreateLoaderQueue_p.html
#---------------------------
Loader Queue==�������������� ����������������
The loader set is empty==�������������� ����������.
There are \#\[num\]\# entries in the loader set:==���������� �������������� �� ���������������� #[num]# :
Initiator==������������������
Depth==��������������
Status==������������������
#URL==URL-����������
\'Local\' Crawl Queue==������������������ �������������� ����������������������������
#-----------------------------

#File: IndexCreateParserErrors_p.html
#---------------------------
Parser Errors==���������������������� ������������
Rejected URLs==���������������������� ������������
Rejected URL List:==
There are \#\[num\]\# entries in the rejected-urls list.==���������� �������������� �� ������������ #[num]#.
Showing latest \#\[num\]\# entries.==���������������� #[num]# ������������������ ��������������.
"show more"=="���������������� ������������"
"clear list"=="���������������� ������������"
There are \#\[num\]\# entries in the rejected-queue:==
#Initiator==������������������
#Executor==����������������������
Time==�������� �� ����������
#URL==URL-������������
Fail-Reason==�������������� ������������
#-----------------------------

#File: IndexCreateQueues_p.html
#-----------------------------
This crawler queue is empty==�������������� ���������� ����������c���������� ����������
\'Local\' Crawl Queue==������������������ �������������� ����������������������������
Click on this API button to see an XML with information about the crawler latency and other statistics.==�������������� ���� ������ ������������ ������ ������������������ �� �������� XML �������������������� �� ���������������� ���������������������� �� ������������ ��������������������.
Delete Entries:==�������������� ����������������:
Initiator==������������������
Profile==��������������
Depth==��������������
Modified Date==�������� ������������������
Anchor Name==���������������� ����������
#URL==URL
Count==��������������������
Delta/ms==������������ (����)
Host==��������
"Delete"=="��������������"

#-----------------------------


#File: ContentIntegrationPHPBB3_p.html
#---------------------------
Content Integration: Retrieval from phpBB3 Databases==�������������������� ����������������: ���������� ���� ������ ������������ phpBB3
It is possible to extract texts directly from mySQL and postgreSQL databases.==Es ist m��glich Texte direkt aus MySQL und PostgreSQL Datenbanken zu extrahieren.
Each extraction is specific to the data that is hosted in the database.==Jeder Vorgang extrahiert genau die Datens��tze die in der Datenbank gehostet werden.
This interface gives you access to the phpBB3 forums software content.==Dieses Interface erlaubt den Zugriff auf die Inhalte der phpBB3 Forum Software.
If you read from an imported database, here are some hints to get around problems when importing dumps in phpMyAdmin:==Wenn aus einer importierten Datenbank gelesen werden soll sind hier einige Hinweise, um Probleme zu vermeiden wenn Datenbankdumps in phpMyAdmin importiert werden.
before importing large database dumps, set==Bevor gro��e Datenbankdumps importiert werden die folgende Zeile
in phpmyadmin/config.inc.php and place your dump file in /tmp \(Otherwise it is not possible to upload files larger than 2MB\)==in die Datei phpmyadmin/config.inc.php schreiben und die Datenbank Datei in /tmp ablegen (Andernfalls ist es nicht m��glich Dateien gr����er als 2MB hochzuladen)
deselect the partial import flag==Den teilweisen Import Flag abschalten
When an export is started, surrogate files are generated into DATA/SURROGATE/in which are automatically fetched by an indexer thread.==Wenn ein Export gestartet wird werden Hilfsdateien in DATA/SURROGATE/in erzeugt, die automatisch von einem Indexer Thread geholt und verarbeitet werden.
All indexed surrogate files are then moved to DATA/SURROGATE/out and can be re-cycled when an index is deleted.==Alle indexierten Hilfsdateien werden dann nach DATA/SURROGATE/out verschoben und k��nnen recycelt werden wenn ein Index gel��scht wird.
The URL stub==Der Teil der URL
like http://forum.yacy-websuche.de==wie z.B. http://forum.yacy-websuche.de
this must be the path right in front of '\/viewtopic.php\?'==dies muss den kompletten Pfad vor '\/viewtopic.php\?' enthalten
Type==Typ
> of database<==> der Datenbank<
use either 'mysql' or 'pgsql'==Verwende entweder 'mysql' oder 'pgsql'
Host=Hostname
> of the database<==> der Datenbank<
of database service==des Datenbank Dienstes
usually 3306 for mySQL==normalerweise 3306 f��r MySQL
Name of the database==Name der Datenbank
on the host==auf dem Host
Table prefix string==Tabellen Pr��fix
for table names==f��r Tabellennamen
User==Benutzer
that can access the database==mit Zugriff auf die Datenbank
Password==Passwort
for the account of that user given above==f��r den Zugang des oben angegebenen Benutzers
Posts per file==Beitr��ge pro Datei
in exported surrogates==in der exportierten Hilfsdatei
Check database connection==Datenbankverbindung ��berpr��fen
Export Content to Surrogates==Exportiere Inhalt in Hilfsdateien
Import a database dump==Importieren eines Datenbankauszugs
Import Dump==Datenbankdump importieren
Posts in database==Beitr��ge in Datenbank
first entry==Erster Eintrag
last entry==Letzter Eintrag
Info failed:==Info Fehlgeschlagen:
Export successful! Wrote \#\[files\]\# files in DATA/SURROGATES/in==Export erfolgreich! #[files]# Dateien in DATA/SURROGATES/in geschrieben
Export failed:==Export fehlgeschlagen:
Import successful!==Import erfolgreich!
Import failed:==Import fehlgeschlagen:
#-----------------------------

#File: DictionaryLoader_p.html
#---------------------------
Knowledge Loader==���������������� ��������������
YaCy can use external libraries to enable or enhance some functions. These libraries are not==YaCy ���������� ������������������������ �������������� ��������������������, ���������� ���������������� ������ ���������������� ������������������ ��������������. ������ ��������������������
included in the main release of YaCy because they would increase the application file too much.==���� ���������������� �� �������������� ���������� YaCy, ������ ������ ������ ���������������������� ���������������������� ������������ ��������������������.
You can download additional files here.==���� ������������ ������������������ ���������������������������� ���������� ����������.
>Geolocalization<==>����������������������������<
Geolocalization will enable YaCy to present locations from OpenStreetMap according to given search words.==���������������������������� ���������������� YaCy ������������������������ �������������������� �� ���������������������������� ���� OpenStreetMap, ���������������� �������������������� ��������������.
>GeoNames<==>���������������������������� ����������������<
With this file it is possible to find cities all over the world.==�� �������������� �������� ������������������ ���������������� ���������� �������������� ���� ���������� ��������.
Content<==��������������������<
cities with a population &gt; 1000 all over the world==������������ �� �������������������� 1000 ��������������
cities with a population &gt; 5000 all over the world==������������ �� �������������������� 5000 ��������������
cities with a population &gt; 100000 all over the world \(the set is is reduced to cities &gt; 100000\)==������������ �� �������������������� 100000 �������������� (�������������������� ������ �������������������� �������������� �������������� ���� &gt; 100000)
>Download from<==>������������������ ����<
>Storage location<==>������������������ ������������������<
>Status<==>������������������<
>not loaded<==>���� ������������������<
>loaded<==>������������������<
:deactivated==:������������������
>Action<==>����������������<
>Result<==>������������������<
"Load"=="������������������"
"Deactivate"=="������������������"
"Remove"=="��������������"
"Activate"=="����������������"
>loaded and activated dictionary file<==>������������������ �� ���������������� �������� ��������������<
>loading of dictionary file failed: \#\[error\]\#<==>���������������� ���������� �������������� ����������������: #[error]#<
>deactivated and removed dictionary file<==>������������������ �� �������������� �������� ��������������<
>cannot remove dictionary file: \#\[error\]\#<==>�������������������� �������������� �������� ��������������: #[error]#<
>deactivated dictionary file<==���������������������� ���������� ��������������<
>cannot deactivate dictionary file: \#\[error\]\#<==>�������������������� ������������������ �������� ��������������: #[error]#<
>activated dictionary file<==>�������������������� �������� ��������������<
>cannot activate dictionary file: \#\[error\]\#<==>�������������������� ���������������� �������� ��������������: #[error]#<
#>OpenGeoDB<==>OpenGeoDB<
>With this file it is possible to find locations in Germany using the location \(city\) name, a zip code, a car sign or a telephone pre-dial number.<==>�� �������������� �������� ������������������ ���������������� ���������� ��������, ��������������, ���������������� ���������������� �� �������������������� ���������� �� ����������������.<
Suggestions<==��������������<
Suggestion dictionaries will help YaCy to provide better suggestions during the input of search words==������������������������ �������������� ������������ ���������� YaCy ����������.
This file provides 100000 most common german words for suggestions==�������� �������� ���������������� ���������� 100000 ���������������� �������������������������������� ���������������� ��������.
#-----------------------------

#File: IndexCreateWWWGlobalQueue_p.html
#---------------------------
Global Crawl Queue==�������������� ���������������������� ����������������������
This queue stores the urls that shall be sent to other peers to perform a remote crawl.==������ �������������� ���������������� ������������, ������������������������ ������������ ���������� ������ �������������������� �������������������� ����������������������������.
If there is no peer for remote crawling available, the links are crawled locally.==�������� ������ ���������� ������ �������������������� ����������������������������, ���� ������������ �������������������������� ����������������.
The global crawler queue is empty==�������������� ���������������������� ���������������������� ����������.
"clear global crawl queue"=="���������������� �������������� ���������������������� ����������������������"
There are <strong>\#\[num\]\#</strong> entries in the global crawler queue. Showing <strong>\#\[show-num\]\#</strong> most recent entries.==���������� �������������� �� �������������� ���������������������� ���������������������� <strong>#[num]#</strong>. ���������������� <strong>#[show-num]#</strong> ������������������ ��������������.
Show last==���������������� ������������������
</a> entries.==</a> ������������.
Initiator==������������������
Profile==��������������
Depth==��������������
Modified Date==�������� ������������������
Anchor Name==Anker Name
#URL==URL-����������
#-----------------------------

#File: IndexCreateWWWLocalQueue_p.html
#---------------------------
Local Crawl Queue==�������������� �������������������� ����������������������
This queue stores the urls that shall be crawled localy by this peer.==������ �������������� ���������������� ������������, ������������������������������������ ���������������� ���������� ����������.
It may also contain urls that are computed by the proxy-prefetch.==���������� ���������� ���������� ���������������������� ������������, �������������������� ������������������������������ ���������������� ���������� ������������.
The local crawler queue is empty==�������������� �������������������� ���������������������� ����������.
There are <strong>\#\[num\]\#</strong> entries in the local crawler queue. Showing <strong>\#\[show-num\]\#</strong> most recent entries.==���������� �������������� �� �������������� �������������������� ���������������������� <strong>#[num]#</strong>. ���������������� <strong>#[show-num]#</strong> ������������������ ��������������.
Show last==���������������� ������������������
</a> entries.==</a> ������������.
Initiator==������������������
Profile==��������������
Depth==��������������
Modified Date==�������� ������������������
Anchor Name==Anker Name
#URL==URL-����������
\[Delete\]==[��������������]
Delete Entries:==�������������� ������������:
"Delete"=="��������������"
This may take a quite long time.==������ ���������� ������������ ������������������ ����������.
#-----------------------------

#File: IndexCreateWWWRemoteQueue_p.html
#---------------------------
Remote Crawl Queue==�������������� �������������������� ����������������������
This queue stores the urls that other peers sent to you in order to perform a remote crawl for them.==������ �������������� ���������������� ������������, ������������������������ �������������� ������������ ������ �������������������� �������������������� ����������������������������.
The remote crawler queue is empty==�������������� �������������������� ���������������������� ����������
"clear remote crawl queue"=="���������������� �������������� �������������������� ����������������������"
There are <strong>\#\[num\]\#</strong> entries in the remote crawler queue.==���������� �������������� �� �������������� �������������������� ���������������������� <strong>#[num]#</strong>.
Showing <strong>\#\[show-num\]\#</strong> most recent entries.==���������������� <strong>#[show-num]#</strong> ������������������ ��������������.
Show last==���������������� ������������������
</a> entries.==</a> ������������.
Initiator==������������������
Profile==��������������
Depth==��������������
Modified Date==�������� ������������������
Anchor Name==Anker Name
#URL==URL-����������
Delete==��������������
#-----------------------------        

#File: IndexDeletion_p.html
#---------------------------
Index Deletion<==���������������� ��������������<
The search index contains \#\[doccount\]\# documents. You can delete them here.==������������������ ������������ ���������������� #[doccount]# ��������������������. ���� ������������ �������������� ���� ����������.
Deletions are made concurrently which can cause that recently deleted documents are not yet reflected in the document count.==���������������� ������������������������ ����������������������, �������������� �������������� ������������������ ������������������ ���������� ���� ���������������������� �� ���������������� ��������������������.
Delete by URL Matching<==���������������� ���������������������� ������������<
Delete all documents within a sub-path of the given urls. That means all documents must start with one of the url stubs as given here.==�������������� ������ ������������������, �������������� ���������������� ������������������ ������������. ���������������� ������������ ���� ������ ������������������ ������������ �������������������� ������������������.
One URL stub, a list of URL stubs<br/>or a regular expression==�������� ������������, ������������ ������������<br/>������ �������������������� ������������������
Matching Method<==������������ ������������ ��������������������<
sub-path of given URLs==�������������� ���������������� ������������������ ������������
matching with regular expression==�������������������� �� �������������������� ��������������������
"Simulate Deletion"=="������������������������"
"no actual deletion, generates only a deletion count"=="������������ ���� ������������������, ������������������������ ������������ ������������������ ���������� �������������������� ������ ����������������"
"Engage Deletion"=="���������������������� ����������������"
"simulate a deletion first to calculate the deletion count"=="�������������� �������������� ������������������������."
"engaged"=="����������������������"
selected \#\[count\]\# documents for deletion==���������� #[count]# �������������������� ������ ����������������
deleted \#\[count\]\# documents==�������������� #[count]# ��������������������
Delete by Age<==���������������� ���� ����������������<
Delete all documents which are older than a given time period.==�������������� ������ ������������������, �������������� ������������ �������������������� �������������� ��������������.
Time Period<==���� ��������������<
All documents older than==������ ������������������, ������������ ������
years<==������<
months<==��������������<
days<==��������<
hours<==����������<
Age Identification<==���� ��������<
>load date==>�������� ����������������
>last-modified==>�������� �������������������� ������������������ ������������������
Delete Collections<==���������������� ����������������<
Delete all documents which are inside specific collections.==�������������� ������ ������������������ ������������ ���������������������� ����������������.
Not Assigned<==���� ��������������������<
Delete all documents which are not assigned to any collection==�������������� ������ ������������������ ���������������������������� ���� ���� ���������� ��������������������
, separated by \',\' \(comma\) or \'\|\' \(vertical bar\); or==, ���������������������� �������������� ������ '|' (������������������������ ������������ (��������)); ������
>generate the collection list...==>���������������� ������������ ����������������...
Assigned<==��������������������<
Delete all documents which are assigned to the following collection\(s\)==�������������� ������ ������������������ ������������������������ ���� ������������������ �������� ��������������������
Delete by Solr Query<==���������������� ���������������� ���� �������� Solr<
This is the most generic option: select a set of documents using a solr query.==������ ���������������� �������������������������� ��������������: ���������������� ���������� �������������������� �� �������������� �������������� �� �������� Solr.
#-----------------------------


#File: IndexImport_p.html
#---------------------------
YaCy \'\#\[clientname\]\#\': Index Import==YaCy '#[clientname]#': Index Import
#Crawling Queue Import==Crawling Puffer Import
Index DB Import==Index Datenbank Import
The local index currently consists of \(at least\) \#\[wcount\]\# reverse word indexes and \#\[ucount\]\# URL references.==Der lokale Index besteht zur Zeit aus (mindestens) #[wcount]# W��rtern und #[ucount]# URLs.
Import Job with the same path already started.==Ein Import mit dem selben Pfad ist bereits gestartet.
Starting new Job==������������ ���������� ��������������
Import&nbsp;Type:==������������ ��������:
Cache Size==������������ ��������
Usage Examples==Benutzungs-<br />beispiele
"Path to the PLASMADB directory of the foreign peer"=="Pfad zum PLASMADB Verzeichnis des fremden Peer"
Import&nbsp;Path:==�������� ��������������:
"Start Import"=="������������ ����������"
Attention:==����������������:
Always do a backup of your source and destination database before starting to use this import function.==Machen Sie immer ein Backup von Ihrer Quell- und Zieldatenbank, bevor Sie die Import-Funktion nutzen.
Currently running jobs==�������������������������� ��������������
Job Type==������ ��������������
>Path==>��������
Status==������������������
Elapsed<br />Time==Verstrichene<br />Zeit
Time<br />Left==verbl.<br />Zeit
Abort Import==���������������� ������������
Pause Import==�������������������������� ������������
Finished::Running::Paused==������������������::����������������::����������������������������
"Abort"=="����������������"
#"Pause"=="����������"
"Continue"=="��������������������"
Finished jobs==���������������������� ��������������
"Clear List"=="���������������� ������������"
Last Refresh:==������������������ ��������������������:
Example Path:==������������ ��������:
Requirements:==��������������������:
You need to have at least the following directories and files in this path:==������ �������������������� �������������� �������� �� ������������ �� ������������::
>Type==>������
>Writeable==>������������ ����������������
>Description==>����������������
>File==>��������
>Directory==>��������������������
>Yes<==>����<
>No<==>������<
The LoadedURL Database containing all loaded and indexed URLs==Die 'geladene URLs'-Datenbank, enth��lt alle geladenen und indexierten URLs
The assortment directory containing parts of the word index.==Das Assortment-Verzeichnis, enth��lt Teile des Wort-Index.
The words directory containing parts of the word index.==Das Wort-Verzeichnis, enth��lt Teile des Wort-Index.
The assortment file that should be imported.==Die Assortment-Datei die importiert werden soll.
The assortment file must have the postfix==Die Assortment-Datei muss den Suffix
.db".==.db" haben.
If you would like to import an assortment file from the <tt>PLASMADB\\ACLUSTER\\ABKP</tt>== Wenn Sie eine Assortment-Datei aus <tt>PLASMADB\\ACLUSTER\\ABKP</tt> importieren wollen,
you have to rename it first.==m��ssen Sie sie zuerst umbenennen.
>Notes:==>Anmerkung:
Please note that the imported words are useless if the destination peer doesn't know==Bitte bedenken Sie, dass die importierten W��rter nutzlos sind, wenn der Ziel-Peer nicht wei��,
the URLs the imported words belongs to.==zu welchen URLs sie geh��ren.
Crawling Queue Import:==Crawler-Puffer-Import:
Contains data about the crawljob an URL belongs to==Enth��lt Daten ��ber den Crawljob, zu dem eine URL geh��rt
The crawling queue==Der Crawler-Puffer
Various stack files that belong to the crawling queue==Verschiedene Stack-Dateien, die zum Crawler-Puffer geh��ren
#-----------------------------

#File: IndexImportMediawiki_p.html
#---------------------------
#MediaWiki Dump Import==MediaWiki Dump Import
No import thread is running, you can start a new thread here==Sie k��nnen hier einen neuen Thread starten, da aktuell kein Import Thread l��uft
Bad input data:==Ung��ltige Eingabedaten:
MediaWiki Dump File Selection: select an XML file \(which may be bz2- or gz-encoded\)==MediaWiki Dump Datei Auswahl: W��hle eine XML Datei (die auch bz2 oder gzip komprimiert sein darf)
You can import MediaWiki dumps here. An example is the file==Hier k��nnen Sie MediaWiki Dumps importieren. Als Beispiel dient die Datei
Dumps must be in XML format and may be compressed in gz or bz2. Place the file in the YaCy folder or in one of its sub-folders.==Dumps m��ssen im XML Format vorliegen und bz2 komprimiert sein. Legen Sie die Datei im YaCy-Verzeichnis oder einem Unterordner ab.
"Import MediaWiki Dump"=="Importiere MediaWiki Dump"
When the import is started, the following happens:==Wenn der Import gestartet wird passiert Folgendes:
The dump is extracted on the fly and wiki entries are translated into Dublin Core data format. The output looks like this:==Der Dump wird zur Laufzeit extrahiert und die Wiki Eintr��ge werden in das Dublin Core Datenformat ��bersetzt. Die Ausgabe schaut wie folgt aus:
Each 10000 wiki records are combined in one output file which is written to /DATA/SURROGATES/in into a temporary file.==Je 10000 Wiki Eintr��ge werden zusammen in eine Ausgabedatei geschrieben und in /DATA/SURROGATES/in tempor��r gespeichert.
When each of the generated output file is finished, it is renamed to a .xml file==Wenn jede der generierten Ausgabedateien abgearbeitet wurde wird diese in eine .xml Datei umbenannt.
Each time a xml surrogate file appears in /DATA/SURROGATES/in, the YaCy indexer fetches the file and indexes the record entries.==Immer wenn eine xml Surrogat Datei in /DATA/SURROGATES/in erscheint, holt der YaCy Indexer diese Datei und indexiert die enthaltenen Datens��tze.
When a surrogate file is finished with indexing, it is moved to /DATA/SURROGATES/out==Wenn eine Surrogat Datei vollst��ndig indexiert wurde, wird sie nach /DATA/SURROGATES/out verschoben
You can recycle processed surrogate files by moving them from /DATA/SURROGATES/out to /DATA/SURROGATES/in==Sie k��nnen schon abgearbeitete Surrogat Dateien durch Verschieben von /DATA/SURROGATES/out nach /DATA/SURROGATES/in recyclen.
Import Process==Import Prozess
#Thread:==Thread:
#Dump:==Dump:
Processed:==Bearbeitet:
Wiki Entries==Wiki Eintr��ge
Speed:==Geschwindigkeit:
articles per second<==������������ �� ��������������<
Running Time:==������������ ��������������:
hours,==��������,
minutes<==������������<
Remaining Time:==���������������� ��������������:
#hours,==��������,
#minutes<==������������<
#-----------------------------

#File: IndexImportOAIPMH_p.html
#---------------------------
OAI-PMH Import==������������ OAI-PMH
Results from the import can be monitored in the <a href=\"CrawlResults.html\?process=7\">indexing results for surrogates==�������������������� �������������� ���������� �������������� ���� ���������������� <a href="CrawlResults.html?process=7">���������������������� �������������������� ���������������������� ��������������.
Single request import==�������� ������������ ��������������
This will submit only a single request as given here to a OAI-PMH server and imports records into the index==������ ���������������� ������������������ ������������ �������� ������������ ���� ������������ OAI-PMH �� �������������������������� ������������ �� ������������
"Import OAI-PMH source"=="�������������������������� ���������������� OAI-PMH"
Source:==����������������:
Processed:==��������������������:
records<==��������������<
ResumptionToken:==�������������� ��������������������������:
Import failed:==������������ ���� ������������:
Import all Records from a server==�������������������������� ������ ������������ �� ��������������
Import all records that follow according to resumption elements into index==�������������������������� ������ ������������, �������������� �������������� ���� ���������������������������� ������������������, �� ������������
"import this source"=="������������ ���������� ������������������"
::or&nbsp;==::������&nbsp;
"import from a list"=="������������ ���� ������������"
Import started!==���������������������������� ����������������!
Bad input data:==������������ ���������������� ������������:
#-----------------------------

#File: IndexImportOAIPMHList_p.html
#---------------------------
List of \#\[num\]\# OAI-PMH Servers==������������ ���� #[num]# ���������������� OAI-PMH
"Load Selected Sources"=="������������������ ������������������ ������������������"
OAI-PMH source import list==�������������������������� ������������ �������������������� OAI-PMH
#OAI Source List==OAI ������������ ��������������������
>Source<==>����������������<
Import List==�������������������������� ������������
>Thread<==>����������<
#>Source<==>����������������<
>Processed<br />Chunks<==>������������������<br />������������<
>Imported<br />Records<==>��������������������������<br />��������������<
>Speed<br />\(records/second\)==>����������������<br />(�������������� �� ��������������)
Complete at==���������� ��������������
Records==
#-----------------------------

#File: IndexReIndexMonitor_p.html
#---------------------------
Field Re-Indexing<==������������������������ ��������������<
In case that an index schema has changed, all documents with missing field entries can be indexed again with a reindex job.==�� ������������, �������� ���������� �������������� �������� ����������������, ������ ������������������ c ���������������������� �������������������� ���������� ���������� �������� �������������������������������� ���������� �� �������������� ����������������������������.
"refresh page"=="���������������� ����������������"
Documents in current queue<==������������������ �� �������������� ��������������:<
Documents processed<==������������������ ����������������������:<
current select query==���������� �������������� ��������������:
"start reindex job now"=="������������ ����������������������������"
"stop reindexing"=="��������������������"
Remaining field list==�������������������� �������� ������������
reindex documents containing these fields:==���������������������������������� ������������������, �������������������� ������ ��������:
# The following lines are hard-coded and would need to be translated in the .java bean
#"reindex job stopped"=="���������������������������� ����������������������"
#"reindex is running"=="���������������������������� ����������������������"
#"is empty"=="����������"
#"no reindex job running"=="������ �������������������������� ����������������������������"
#"! reindex works only with embedded Solr index !"=="! ���������������������������� �������� ������������ �� �������������������� ���������������� �������� Solr !"
#-----------------------------


#File: ContentAnalysis_p.html
#---------------------------
Content Analysis==������������ ����������������������
These are document analysis attributes.==������������������ �������������� ��������������������.
Double Content Detection==�������������� ���������������������� ����������������������
Double-Content detection is done using a ranking on a 'unique'-Field, named 'fuzzy_signature_unique_b'.==�������������� ���������������������� ���������������������� ���������������������� �� �������������� ������������������������ �������� 'fuzzy_signature_unique_b'. 
This field is set during parsing and is influenced by two attributes for the <a href="http://lucene.apache.org/solr/api-4_0_0-BETA/org/apache/solr/update/processor/TextProfileSignature.html">TextProfileSignature</a> class.==������ �������� ������������������������������ ���� ���������� �������������� �� ���������������������� ���������� ���������������������� ������������<a href="http://lucene.apache.org/solr/api-4_0_0-BETA/org/apache/solr/update/processor/TextProfileSignature.html">  TextProfileSignature</a>.
This is the minimum length of a word which shall be considered as element of the signature. Should be either 2 or 3.==���������������������� ���������� ����������, �������������� ������������ ������������������������������ �� ���������������� ���������������� ������������������. ���������� �������� 2 ������ 3
The quantRate is a measurement for the number of words that take part in a signature computation. The higher the number, the less=='quantRate' ������  �������������������� ��������, �������������� �������������������� ������ �������������������� ������������������. ������ �������� ������ ����������, ������ ������������
words are used for the signature.==�������� ������������������������ ������ ������������������.
For minTokenLen = 2 the quantRate value should not be below 0.24; for minTokenLen = 3 the quantRate value must be not below 0.5.==�������� 'minTokenLen' ���������� 2, ���� ���������������� 'quantRate' ������������ �������� ���� �������� 0.24; �������� 'minTokenLen' ���������� 3, ���� ���������������� 'quantRate' ������������ �������� ���� �������� 0.5. 
"Set"=="��������������������"
"Re-Set to default"=="�������������� ���������������� ����-������������������"
#---------------------------


#File: Load_MediawikiWiki.html
#---------------------------
YaCy \'\#\[clientname\]\#\': Configuration of a Wiki Search==YaCy '#[clientname]#': ������������������������ ������������ �� Wiki
Integration in MediaWiki==�������������������� �� MediaWiki
It is possible to insert wiki pages into the YaCy index using a web crawl on that pages.==���������������� ���������������� wiki-���������������� �� ������������ YaCy, ������������������ ���������������������������� �������� ������-��������������.
This guide helps you to crawl your wiki and to insert a search window in your wiki pages.==������ ���������������������� �������������� ������ �������������������������������� �������� wiki �� ���������������� �������� ������������ ���� �������� wiki-����������������.
Retrieval of Wiki Pages==�������������������� wiki-��������������
The following form is a simplified crawl start that uses the proper values for a wiki crawl.==������������������ ���������� ������������������������ ���������� �������������������� ������������ ����������������������������, �� ���������������������������� �������������������� ���������������� ������ �������������������� Wiki.
Just insert the front page URL of your wiki.==���������������� ������������ ���� �������������� ���������������� ���������� wiki. 
After you started the crawl you may want to get back==���������� ������������ ����������������������������, ���������������� ���� ���������������� ������������������ ����������
to this page to read the integration hints below.==���� ������ ����������������, ������ ������������ ������������������ ���� ��������������������, ������������������ ��������.
URL of the wiki main page==������������ ���� �������������� wiki-����������������
This is a crawl start point==(������������������ ���������� ����������������������������)
"Get content of Wiki: crawl wiki pages"=="�������������������������� Wiki-����������������"
Inserting a Search Window to MediaWiki==���������������� �������� ������������ �� MediaWiki
To integrate a search window into a MediaWiki, you must insert some code into the wiki template.==������ �������������������� �������� ������������ �� MediaWiki, ���� ������������ ���������������� ������������������������������ ������ �� wiki-������������.
There are several templates that can be used for MediaWiki, but in this guide we consider that==���������� ������������������������ ������������������ ��������������, �������������� ���� ������������ ������������������������ ������ MediaWiki, ���� ������ ���������������������� ���� ��������������������
you are using the default template, \'MonoBook.php\':==���� �������������� �������������������������� �������������� ����-������������������, 'MonoBook.php':
open skins/MonoBook.php==���������������� skins/MonoBook.php
find the line where the default search window is displayed, there are the following statements:==�������������� ������������, ������ ���������������� �������� ������������ ����-������������������. ���������� ������������ ������������������ ����������:
Remove that code or set it in comments using \'&lt;!--\' and \'--&gt;\'==�������������� �������� ������ ������ ������������������������������ ������, ������������������ '&lt;!--' �� '--&gt;'
Insert the following code:==���������������� ������������������ ������:
Search with YaCy in this Wiki:==���������� �� YaCy �� �������� Wiki:
value=\"Search\"==value="����������"
Check all appearances of static IPs given in the code snippet and replace it with your own IP, or your host name==������������������ ������ ���������������������� IP-������������ �� ������������������ �������� �� ���������������� ���� ������������ IP-���������������� ������ ������������ ������������ ����������.
You may want to change the default text elements in the code snippet==���� ������������ ���������������� ���������������������� ���������� �� ������������������ ��������
To see all options for the search widget, look at the more generic description of search widgets at==�������������������� ������ ���������� �� ���������������� �������������� ������������ ���� ������������ ���� ���������������� 
the <a href=\"ConfigLiveSearch.html\">configuration for live search</a>.==<a href=\"ConfigLiveSearch.html\">�������������������� ������������</a>.
#-----------------------------

#File: Load_PHPBB3.html
#---------------------------
Configuration of a phpBB3 Search==������������������������ ������������ �� phpBB3
Integration in phpBB3==�������������������� �� phpBB3
It is possible to insert forum pages into the YaCy index using a database import of forum postings.==���������������� ���������������� ���������������� ������������ �� ������������ YaCy, ������������������ ������������ �������� ������������ ������������ ������������.
This guide helps you to insert a search window in your phpBB3 pages.==������ ���������������������� �������������� ������ ���������������� �������� ������������ ���� �������� phpBB3-����������������.
Retrieval of phpBB3 Forum Pages using a database export==�������������������� phpBB3-�������������� ������������, ������������������ �������������� �������� ������������.
Forum posting contain rich information about the topic, the time, the subject and the author.==���������� ������������ ���������������� ���������� �������������������� �� ��������������, ��������������, �������� �� ������������.
This information is in an bad annotated form in web pages delivered by the forum software.==������ �������������������� ������������������ �� ���������� ���������������������������� ���������� ���� ������-������������������ ������������.
It is much better to retrieve the forum postings directly from the database.==�������������� �������������� �������������� �������������� ���������� ������������ ���������� ���� �������� ������������.
This will cause that YaCy is able to offer nice navigation features after searches.==���������� ������������ ������ �������������� �������������� ������������������.
YaCy has a phpBB3 extraction feature, please go to the <a href="ContentIntegrationPHPBB3_p.html">phpBB3 content integration</a> servlet for direct database imports.==������������������ �������������������� ���� �������������������� phpBB3 ���������������� ���� ���������������� <a href="ContentIntegrationPHPBB3_p.html">�������������������� ���������������������� phpBB3</a>.
Retrieval of phpBB3 Forum Pages using a web crawl==������ �������������������� phpBB3-�������������� ������������������������ ��������������������.
The following form is a simplified crawl start that uses the proper values for a phpbb3 forum crawl.==������������������ ���������� ������������������������ ���������� �������������������� ������������ ����������������������������, �� ���������������������������� �������������������� ���������������� ������ �������������������� phpbb3-������������.
Just insert the front page URL of your forum. After you started the crawl you may want to get back==���������������� ������������ ���� �������������� ���������������� ������������ ������������. ���������� ������������ ����������������������������, ���������������� ���� ���������������� ������������������ ����������
to this page to read the integration hints below.==���� ������ ����������������, ������ ������������ ������������������ ���� ��������������������, ������������������ ��������.
URL of the phpBB3 forum main page==������������ ���� �������������� ���������������� ������������
This is a crawl start point==(������������������ ���������� ����������������������������)
"Get content of phpBB3: crawl forum pages"=="�������������������������� ���������������� ������������"
Inserting a Search Window to phpBB3==���������������� �������� ������������ ���� phpBB3-����������
To integrate a search window into phpBB3, you must insert some code into a forum template.==������ �������������������� �������� ������������ �� phpBB3, ���� ������������ ���������������� ������������������������������ ������ �� ������������ ������������.
There are several templates that can be used for phpBB3, but in this guide we consider that==���������� ������������������������ ������������������ ��������������, �������������� ���� ������������ ������������������������ ������ phpBB3, ���� ������ ���������������������� ���� ��������������������
you are using the default template, \'prosilver\'==���� �������������� �������������������������� �������������� ����-������������������, 'prosilver'.
open styles/prosilver/template/overall_header.html==���������������� styles/prosilver/template/overall_header.html
find the line where the default search window is displayed, thats right behind the <pre>\&lt;div id=\"search-box\"\&gt;</pre> statement==�������������� ������������, ������ ���������������� �������� ������������ ����-������������������. ���������� ������������ ������������������ ����������: <pre>&lt;div id="search-box"&gt;</pre>
Insert the following code right behind the div tag==���������������� ������������������ ������ ���� ���������� "div"
YaCy Forum Search==���������� ���� ������������
;YaCy Search==;���������� YaCy
Check all appearances of static IPs given in the code snippet and replace it with your own IP, or your host name==������������������ ������ ���������������������� IP-������������ �� ������������������ �������� �� ���������������� ���� ������������ IP-���������������� ������ ������������ ������������ ����������.
You may want to change the default text elements in the code snippet==���� ������������ ���������������� ���������������������� ���������� �� ������������������ ��������
To see all options for the search widget, look at the more generic description of search widgets at==�������������������� ������ ���������� �� ���������������� �������������� ������������ ���� ������������ ���� ���������������� 
the <a href=\"ConfigLiveSearch.html\">configuration for live search</a>.==<a href=\"ConfigLiveSearch.html\">�������������������� ������������</a>.
#-----------------------------

#File: Load_RSS_p.html
#---------------------------
Configuration of a RSS Search==������������������������ ������������ ���� RSS-������������
Loading of RSS Feeds<==���������������� RSS-��������<
RSS feeds can be loaded into the YaCy search index.==RSS-���������� ���������� �������� ������������������ �� ������������������ ������������ YaCy.
This does not load the rss file as such into the index but all the messages inside the RSS feeds as individual documents.==�� ������������ ���������������������� ���� ������ RSS-��������, �� ������ ������������������ ������������ RSS-����������, ������ ������������������ ������������������.
URL of the RSS feed==������������ ���� RSS-����������
>Preview<==>������������������������������ ����������������:<
"Show RSS Items"=="���������������� �������������������� RSS"
Indexing==����������������������������:
Available after successful loading of rss feed in preview==������������ ���������������� ���������� ���������������� ���������������� RSS-���������� �� ������������������������.
"Add All Items to Index \(full content of url\)"=="���������������� ������ ���������������� �� ������������ (������������ �������������������� ������������)"
>once<==>�������� ������<
>load this feed once now<==>������������������ ������ ���������� ������������ �������� ������<
>scheduled<==>���� ��������������������<
>repeat the feed loading every<==>������������������ ���������������� ���������� ������������<
>minutes<==>����������<
>hours<==>����������<
>days<==>��������<
> automatically.==> ��������������������������.
#collection==������������������
>List of Scheduled RSS Feed Load Targets<==>������������ ������������������������������ ���������������� RSS-��������<
>Title<==>������������������<
>URL/Referrer<==>������������<
>Recording<==>����������������<
>Last Load<==>������������������ ����������������<
>Next Load<==>������������������ ����������������<
>Last Count<==>������������������ ����������<
>All Count<==>������ ����������<
>Avg. Update/Day<==>�������������� ���������� �������������������� �� ��������<
"Remove Selected Feeds from Scheduler"=="�������������� ������������������ ���������� ���� ������������������������"
"Remove All Feeds from Scheduler"=="�������������� ������ ���������� ���� ������������������������"
>Available RSS Feed List<==>������������������ ������������ RSS-��������<
"Remove Selected Feeds from Feed List"=="�������������� ������������������ ���������� ���� ������������ ��������"
"Remove All Feeds from Feed List"=="�������������� ������ ���������� ���� ������������ ��������"
"Add Selected Feeds to Scheduler"=="���������������� ������������������ ���������� �� ����������������������"
>new<==>����������<
>enqueued<==>�� ��������������<
>indexed<==>��������������������������������<
>RSS Feed of==>RSS-����������
>Author<==>����������<
>Description<==>����������������<
>Language<==>��������<
>Date<==>��������<
>Time-to-live<==>���������� ��������������������������<
>Docs<==>������������������<
>State<==>������������������<
#>URL<==>URL<
"Add Selected Items to Index \(full content of url\)"=="���������������� ������������������ ���������������� �� ������������ (������������ �������������������� ������������)"
#-----------------------------

#File: Messages_p.html
#---------------------------
>Messages==>Nachrichten
Date</td>==Datum</td>
From</td>==Von</td>
To</td>==An</td>
>Subject==>Betreff
Action==Aktion
From:==Von:
To:==An:
Date:==Datum:
#Subject:==Betreff:
>view==>anzeigen
reply==antworten
>delete==>l��schen
Compose Message==Nachrichtenerstellung
Send message to peer==Sende eine Nachricht an Peer
"Compose"=="Erstellen"
Message:==Nachricht:
inbox==Posteingang
#-----------------------------

#File: MessageSend_p.html
#---------------------------
Send message==���������������� ������������������
You cannot send a message to==���� ���� ������������ ������������������ ������������������
The peer does not respond. It was now removed from the peer-list.==�������� ���� ����������������. ���� ������������ ���� ������������ ����������. 
The peer <b>==�������� <b>
is alive and responded:==�� �������� �� ����������������:
You are allowed to send me a message==������ ������������������ ������������������ ������ ������������������
kb and an==KB �� 
attachment &le;==����������������  &le;
Your Message==�������� ������������������
Subject:==��������:
Text:==����������:
"Enter"=="������������������"
"Preview"=="������������������������"
You can use==���� ������������ ������������������������
Wiki Code</a> here.==Wiki-������ </a>.
Preview message==������������������������ ������������������
The message has not been sent yet!==������������������ ������ ���� ��������������������!
The peer is alive but cannot respond. Sorry.==�������� �� ��������, ���� ���� ����������������.
Your message has been sent. The target peer responded:==�������� ������������������ ��������������������. �������� �������������������� ��������������:
The target peer is alive but did not receive your message. Sorry.==�������� �������������������� �� ��������, ���� ���� �������� ���������������� �������� ������������������.
Here is a copy of your message, so you can copy it to save it for further attempts:==Hier ist eine Kopie Ihrer Nachricht. Sie k��nnen diese kopieren, speichern und es sp��ter nochmal versuchen:
You cannot call this page directly. Instead, use a link on the <a href="Network.html">Network</a> page.==Sie k��nnen diese Seite nicht direkt aufrufen. Benutzen Sie stattdessen einen Link auf der <a href="Network.html">Netzwerk</a> Seite.
#-----------------------------

#File: Network.html
#---------------------------
YaCy '#\[clientname]\#': YaCy Search Network==YaCy '#[clientname]#': �������������������� ��������
YaCy Search Network \'\#\[networkName\]\#\'==�������������������� �������� YaCy
YaCy Network<==�������� YaCy<
The information that is presented on this page can also be retrieved as XML==��������������������, ������������������ ���� �������� ����������������, ���������� ���������� �������� ���������������� ������ XML
Click the API icon to see the XML.==�������������� ���� ������������ API, ���������� �������������� XML.
To see a list of all APIs, please visit the <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">API wiki page</a>.==������ ������������������ ������������ �������� API, ��������������������, ���������������� <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">���������������� �� Wiki</a>.
Network Overview==���������� ��������
Active&nbsp;Principal&nbsp;and&nbsp;Senior&nbsp;Peers==���������������� �������������� �� �������������� ��������
Passive&nbsp;Senior&nbsp;Peers==������������������ �������������� ��������
Junior&nbsp;\(fragment\)&nbsp;Peers==�������������� ��������
Active Principal and Senior Peers in \'\#\[networkName\]\#\' Network==���������������� �������������� �� �������������� �������� �� ��������
Passive Senior Peers in \'\#\[networkName\]\#\' Network==������������������ �������������� �������� �� ��������
Junior Peers \(a fragment\) in \'\#\[networkName\]\#\' Network==�������������� �������� �� ��������
Manually contacting Peer==������������ ���������������������� ��������
no remote \#\[peertype\]\# peer for this list known==������ ������������������ ���������� #[peertype]# �� �������� ������������.
Showing \#\[num\]\# entries from a total of \#\[total\]\# peers.==���������������� #[num]# ���������� ���� #[total]#.
send&nbsp;<strong>M</strong>essage/<br/>show&nbsp;<strong>P</strong>rofile/<br/>edit&nbsp;<strong>W</strong>iki/<br/>browse&nbsp;<strong>B</strong>log==������������������ ������������������ (<strong>m</strong>)/<br/>���������������� �������������� (<strong>p</strong>)/<br/>������������ Wiki (<strong>w</strong>)/<br/>�������� (<strong>b</strong>)
Search for a peername \(RegExp allowed\)==���������� �������� ���� ���������� (������������������ �������������������� ������������������)
"Search"=="����������"
Name==������
Address==����������
Hash==������
Type==������
Release<==������������ YaCy<
#>PPM<==>�������������� �� ������������<
#>QPH<==>������������������ ���������������� �� ������<
Last<br/>Seen==������������������<br/>����������������
Location==������������������������
Offset==����������������
Send message to peer==������������������ ������������������ ��������
View profile of peer==���������������� �������������� ��������
Read and edit wiki on peer==������������ �� �������������������������� wiki ��������
Browse blog of peer==���������������� ���������� ��������
#"Ranking Receive: no"=="������������������ ����������������: ������"
#"no ranking receive"=="������ ������������������ ����������������"
#"Ranking Receive: yes"=="������������������ ����������������: ����"
#"Ranking receive enabled"=="������������������ ���������������� ����������������"
"DHT Receive: yes"=="DHT ����������: ����"
"DHT receive enabled"=="DHT ���������� ��������������"
"DHT Receive: no; \#\[peertags\]\#"=="DHT ����������: ������; \#\[peertags\]\#"
"DHT Receive: no"=="DHT ����������: ������"
#no tags given==�������� ���� ������������
"no DHT receive"=="������ ������������ DHT"
"Accept Crawl: no"=="������������ ����������������������������: ������"
"no crawl"=="������ ����������������������������"
"Accept Crawl: yes"=="������������ ����������������������������: ����"
"crawl possible"=="���������������������������� ����������������"
Contact: passive==��������������: ������������������
Contact: direct==��������������: ������������
Seed download: possible==���������������� ��������: ����������������
runtime:==���������� ������������:
#Peers==��������
#YaCy Cluster==YaCy ��������������

>Network<==>��������<
>Online Peers<==>�������� ������������<
>Number of<br/>Documents<==>��������������������<br/>������������������������������������ ��������������������<
Indexing Speed:==���������������� ��������������������:
Pages Per Minute \(PPM\)==�������������� �� ������������ (PPM)
Query Frequency:==�������������� ������������������ ����������������:
Queries Per Hour \(QPH\)==���������������� �� ������ (QPH)
>Today<==>��������������<
>Last&nbsp;Week<==>������������������&nbsp;������������<
>Last&nbsp;Month<==>������������������&nbsp;����������<
Last Hour==������������������ ������
>Now<==>������������<
>Active Senior<==>���������������� ��������������<
>Passive Senior<==>������������������ ��������������<
>Junior \(fragment\)<==>��������������<
>This Peer<==>������ ��������<
URLs for<br/>Remote Crawl==������������ ������ <br/>������������������ ������������������������
"The YaCy Network"=="YaCy ��������"

Indexing<br/>PPM==��������������������������������<br/>�������������� ���� ������������
\(public&nbsp;local\)==\(������������������<br/>������������������\)
\(remote\)==\(������������������\)
Your Peer:==������ ��������:
>Name<==>������<
>Info<==>��������<
>Version<==>������������<
>UTC<==>UTC<
>Uptime<==>���������� ������������<
>Links<==>������������<
#>RWIs<==>RWIs<
Sent<br/>URLs==��������������������<br/>������������
Sent<br/>DHT Word Chunks==��������������������<br/>���� DHT ������������ ��������
Received<br/>URLs==����������������<br/>������������
Received<br/>DHT Word Chunks==����������������<br/>���� DHT ������������ ��������
Known<br/>Seeds==������������������<br/>��������
Connects<br/>per hour==��������������������<br/>�� ������
#Version==������������
#Own/Other==��������/������������
>dark green font<==>���������� ����������-��������������<
senior/principal peers==��������������/�������������� ��������
>light green font<==>���������� ������������-��������������<
>passive peers<==>������������������ ��������<
>pink font<==>���������� ��������������<
junior peers==�������������� ��������
red point==�������������� ����������
this peer==������ ��������
>grey waves<==>���������� ����������<
>crawling activity<==>���������������������� ����������������������������<
>green radiation<==>�������������� ������������������<
>strong query activity<==>�������������� �������������������� ����������������<
>red lines<==>�������������� ����������<
>DHT-out<==>DHT-����������<
>green lines<==>�������������� ����������<
>DHT-in<==>DHT-��������<
#DHT-out==DHT-����������
#You are in online mode, but probably no internet resource is available.==���� �� ��������, ���� ���������������� ����������������-������������ ��������������������.
#Please check your internet connection.==��������������������, ������������������ �������� �������������������� �� ��������������������.
#You are not in online mode. To get online, press this button:==���� ���� �� ��������. ������ ���������� �� ��������, �������������� ������ ������������:
#"go online"=="���������� �� ��������"
#-----------------------------

#File: News.html
#---------------------------
Overview==����������
Incoming&nbsp;News==���������������� ������������������
Processed&nbsp;News==������������������������ ������������������
Outgoing&nbsp;News==������������������ ������������������
Published&nbsp;News==���������������������������� ������������������
This is the YaCyNews system \(currently under testing\).==������ �������������� ������������������ YaCy (����������������������).
The news service is controlled by several entry points:==������������������ ������������������ �� ������������������ ��������������:
A crawl start with activated remote indexing will automatically create a news entry.==������������ ���������������������������� �� �������������������� �������������������� ���������������������������� �������������������������� �������������� ������������������.
Other peers may use this information to prevent double-crawls from the same start point.==������������ �������� ���������� ������������������������ ������ ��������������������, ���������� ������������������ �������������� ���������������������������� ���� �������������������� ������������������ ����������.
A table with recently started crawls is presented on the Index Create - page==�������������� �� �������������� �������������������� ������������������������������ ������������������������ ���� ���������������� "�������������� ����������������������������".
A change in the personal profile will create a news entry. You can see recently made changes of==������������������ �������������������������� �������������� ���������� �������������� ������������������. ���� ������������ �������������� �������������� ������������������ ������������������ ��
profile entries on the Network page, where that profile change is visualized with a '\*' beside the 'P' \(profile\) - selector.==�������������� ���� ���������������� ��������. ������������������ �������������� ���������������� �������������������� '*' ���������� �� 'P' (��������������) ����������.
More news services will follow.==
Above you can see four menues:==���� �������������� ������������ ��������:
<strong>Incoming News \(\#\[insize\]\#\)</strong>: latest news that arrived your peer.==<strong>���������������� ������������������(#[insize]#)</strong>: ������������������ ������������������, �������������������� ���������� ����������.
Only these news will be used to display specific news services as explained above.==������������ ������ ������������������ ���������� ���������������������������� ������ ���������������������� ������������������������ ���������� ������������������.
You can process these news with a button on the page to remove their appearance from the IndexCreate and Network page==���� ������������ ������������������ ���������� ���������������������� ���������� ������������ ���� ����������������, ������ ���������������� ���� ���� ���������������� ���������������������������� �� ���������������� ��������.
<strong>Processed News \(\#\[prsize\]\#\)</strong>: this is simply an archive of incoming news that you removed by processing.==<strong>������������������������ ������������������ (#[prsize]#)</strong>: ������ �������������� ���������� ���������������� ������������������, ������������������ �������� ������ ������������������.
<strong>Outgoing News \(\#\[ousize\]\#\)</strong>: here your can see news entries that you have created. These news are currently broadcasted to other peers.==<strong>������������������ ������������������ (#[ousize]#)</strong>: ���������� ���� ������������ �������������� ������������������, ������������������ ��������. ������ ������������������ �������������������� ������������ ���������� �� ������������ ������������.
you can stop the broadcast if you want.==���� ������������ �������������������� ���������������� ������������������, �������� ������������������.
<strong>Published News \(\#\[pusize\]\#\)</strong>: your news that have been broadcasted sufficiently or that you have removed from the broadcast list.==<strong>���������������������������� ������������������ (#[pusize]#)</strong>: �������� ������������������, �������������������� ������������ ���������� ������ �������������������� �������� ���� ������������ ����������������������.
Originator==������������������
Created==��������������
Category==������������������
Received==����������������
Distributed==��������������������������
Attributes==������������������
"\#\(page\)\#::Process Selected News::Delete Selected News::Abort Publication of Selected News::Delete Selected News\#\(/page\)\#"=="#(page)#::������������������&nbsp;������������������&nbsp;������������������::��������������&nbsp;������������������&nbsp;������������������::����������������&nbsp;��������������������&nbsp;������������������&nbsp;������������������::��������������&nbsp;������������������&nbsp;������������������#(/page)#"
"\#\(page\)\#::Process All News::Delete All News::Abort Publication of All News::Delete All News\#\(/page\)\#"=="#(page)#::������������������&nbsp;������&nbsp;������������������::��������������&nbsp;������&nbsp;������������������::����������������&nbsp;��������������������&nbsp;��������&nbsp;������������������::��������������&nbsp;������&nbsp;������������������#(/page)#"
#-----------------------------

#File: Performance_p.html
#---------------------------
Performance Settings==������������������ ������������������������������������
Memory Settings==������������������ ���������������������� ������������
Memory reserved for JVM==���������������������������� ������������������������ ������������ ������ Java
"Set"=="������������������"
Resource Observer==���������� ����������������
DHT-Trigger==DHT-��������������
not triggered:==���� ����������������������:
>triggered==>ausgel��st
reset state==���������������� ������������������
HDD==�������������� ��������
disable crawls below==�������������������� ���������������������� ������ ��������������������
free space==�������������������� ����������
disable DHT-in below==�������������������� DHT-���������� ������ ��������������������
RAM==RAM
Accepted change. This will take effect after <strong>restart</strong> of YaCy==������������������ ���������� ������������������ ���������� <strong>����������������������</strong> YaCy
restart now</a>==�������������������������� ������������</a>
Confirm Restart==���������������������� ��������������������
refresh graph==������������������ ������������������
#show memory tables==���������������� �������������� ������������
Use Default Profile:==������������������������ �������������� ����-������������������:
and use==�� ������������������������
of the defined performance.==���� ���������������� ������������������������������������.
Save==������������������
Changes take effect immediately==������������������ ���������� ������������������ ��������������������
YaCy Priority Settings==������������������ �������������������� YaCy
YaCy Process Priority==������������������ ����������������
Normal==��������������������
Below normal==�������� ����������������������
Idle</option>==����������������</option>
"Set new Priority"=="�������������������� ���������� ������������������"
Changes take effect after <strong>restart</strong> of YaCy==������������������ ���������� ������������������ ���������� <strong>����������������������</strong> YaCy.
Online Caution Settings:==������������������ ������������ ����������������
This is the time that the crawler idles when the proxy is accessed, or a local or remote search is done.==������ ���������� ���������������� ���������������������� ������ ������������ ������������-��������������, �������������������� �������������������� ������ �������������������� ������������.
The delay is extended by this time each time the proxy is accessed afterwards.==���������������� ���������������������� ������������ ������ ������ ���������������������� ������������.
This shall improve performance of the affected process \(proxy or search\).==������ ������������ ���������������� ������������������������������������ ������������������������������ ������������������ (������������ ������ ����������).
\(current delta is==\(�������������� �������������� 
seconds since last proxy/local-search/remote-search access.\)==������������ ���������� �������������������� �������������� �� ������������/�������������������� ������������/�������������������� ������������.\)
Online Caution Case==��������������������
indexer delay \(milliseconds\) after case occurency==���������������� ���������������������� (����)
Proxy:==������������:
Local Search:==������������������ ����������:
Remote Search:==������������������ ����������:
"Enter New Parameters"=="������������������"
#-----------------------------

#File: PerformanceMemory_p.html
#---------------------------
Performance Settings for Memory==������������������ ������������������������������������ ������������
refresh graph==������������������ ������������������
simulate short memory status==���������������� ������������������ ������������ �������������� ������������ 
use Standard Memory Strategy</label> \(current: \#\[memoryStrategy\]\#\)==������������������������ ������������������ ������������������������ �������������� ������������</label> (��������������: #[memoryStrategy]#)
Memory Usage:==�������������������������� ������������:
After Startup==���������� ��������������
After Initializations==���������� ��������������������������
before GC==���� GC
after GC==���������� GC
>Now==>������������
before <==���� <
Description==����������������
maximum memory that the JVM will attempt to use==���������������� ���������������� ������������ ������ Java
>Available<==>����������������<
total available memory including free for the JVM within maximum==���������� ������������������ ������������, �������������� ������������������ ������ Java ������ ������������������������
>Max<==>����������������<
>Total<==>����������<
total memory taken from the OS==���������� ������������, �������������������� ������������������������ ����������������
>Free<==>����������������<
free memory in the JVM within total amount==������������������ ������������ �� Java ������ ���������� �������� ������������
>Used<==>������������������������<
used memory in the JVM within total amount==������������������������ ������������ �� Java ������ ���������� �������� ������������
Solr Resources:==�������������� �������� ������������ Solr:
>Class<==>����������<
>Type<==>������<
>Statistics<==>��������������������<
>Size<==>������������<
#EcoTable RAM Index:==EcoTabelle RAM Index:
Table RAM Index:==�������������� �������������� RAM:
>Key==>��������
>Value==>����������������
#FlexTable RAM Index:==FlexTabelle RAM Index:
Table</td>==��������������</td>
Chunk Size<==������������ ����������<
#Count</td>==��������</td>
Used Memory<==������������������������ ������������<
#Node Caches:==������ ��������:
Object Index Caches:==������ �������������� ����������������:
Needed Memory==�������������������� ������������

Object Read Caches==������������ ������������������������ ����������������
>Read Hit Cache<==>�������������� ������������ �� ������  <
>Read Miss Cache<==>�������������� ������������������ �� ������<
>Read Hit<==>�������������� ������������<
>Read Miss<==>�������������� ������������������<
Write Unique<==�������������������� ������������<
Write Double<==�������������� ������������<
Deletes<==����������������<
Flushes<==��������������<
Total Mem==���������� ������������
MB \(hit\)==MB (����������)
MB \(miss\)==MB (������������������)
Stop Grow when less than \#\[objectCacheStopGrow\]\# MB available left==�������������������� �������� ������ �������������������� ���� #[objectCacheStopGrow]# MB ���� ������������������
Start Shrink when less than \#\[objectCacheStartShrink\]\# MB availabe left==������������ ������������ ������ �������������������� ���� #[objectCacheStartShrink]# MB ���� ������������������

Other Caching Structures:==������������ ������������������ ��������:
>Hit<==>����������<
>Miss<==>������������������<
Insert<==������������������<
Delete<==��������������<
#DNSCache</td>==DNSCache</td>
#DNSNoCache</td>==DNSNoCache</td>
#HashBlacklistedCache==HashBlacklistedCache
Search Event Cache<==���������� �������������� ��������<
#-----------------------------

#File: PerformanceQueues_p.html
#---------------------------
Performance Settings of Queues and Processes==������������������ ������������������������������������ ���������������� �� ������������������
Scheduled tasks overview and waiting time settings:==���������� ������������������������������ ���������� �� ������������������ �������������� ����������������
>Thread<==>����������<
Queue Size==������������ ��������������
>Total==>����������
Cycles==������������
Block Time==���������� ��������������������
Sleep Time==���������� ������
Exec Time==���������� ��������������������
<td>Idle==<td>����������������,
>Busy==>����������������,
Short Mem<br />Cycles==����������<br />���������������� ������������
>per Cycle==>���� ��������
>per Busy-Cycle==>���� �������������������� ��������.
>Memory Use==>������������������������ ������������
>Delay between==>���������������� ����������
>idle loops==>�������������������� ��������������
>busy loops==>���������������������� ��������������
Minimum of<br />Required Memory==��������������������<br />���������������������� ������������
Maximum of<br />System-Load==��������.<br />���������������� ��������������
Full Description==������������ ����������������
Submit New Delay Values==������������������ ���������� ���������������� ����������������
Re-set to default==�������������������� ���������������� ����-������������������
Changes take effect immediately==������������������ ���������� ������������������ ��������������������
Cache Settings:==������������������ ��������:
RAM Cache==������ RAM
<td>Description==<td>����������������
Words in RAM cache:==�������� �� �������� ���������������������� ������������
(Size in KBytes)==������������ �� ��������������
This is the current size of the word caches.==�������������� ������������ �������� ��������.
The indexing cache speeds up the indexing process, the DHT cache holds indexes temporary for approval.==�������������������� �������� ���������������� ���������� �������������� ��������������������. ������ DHT ���������������� ���������������� ���������������������� ��������������.
The maximum of this caches can be set below.==������������������������ ���������������� ���������� ���������� �������� ���������������������� ��������.
Maximum URLs currently assigned<br />to one cached word:==������������������������ ���������� ������������ ���� �������� ������������������������ ���������� �� ������������ ������������:
This is the maximum size of URLs assigned to a single word cache entry.==������ ������������������������ ���������� ������������, ���������������������� �������� ������������������������ ����������.
If this is a big number, it shows that the caching works efficiently.==�������� ���������� ��������������, ���� ���������������������� ���������������������� ��������������������.
Maximum age of a word:==������������������������ �������������� ����������:
This is the maximum age of a word in an index in minutes.==������ ������������������������ �������������� ���������� �� �������������� �� ��������������.
Minimum age of a word:==���������������������� �������������� ����������:
This is the minimum age of a word in an index in minutes.==������ ���������������������� �������������� ���������� �� �������������� �� ��������������.
Maximum number of words in cache:==������������������������ ���������� �������� �� ��������:
This is is the number of word indexes that shall be held in the==������ ���������� �������� ��������������, ����������������������
ram cache during indexing. When YaCy is shut down, this cache must be==�� ���������������������� ������������ ���� ���������� ����������������������������. ���������� YaCy ����������������������, �������������������� �������� 
flushed to disc; this may last some minutes.==���������������������� ���� ��������; ������ ���������� ������������ ������������������ ����������.
#Initial space of words in cache:==���������������������������� ���������� �������� �� ��������:
#This is is the init size of space for words in cache.==������������������ ������������ �������� �� ��������.
Enter New Cache Size==�������������������� ���������� ������������ ��������
Thread Pool Settings:==������������������ ��������:
Thread Pool==������
Crawler Pool==�������������� ����������������������
httpd Session Pool==�������������������� ��������������������
maximum Active==���������������� ����������������
current Active==�� ������������ ������������
Enter new Threadpool Configuration==�������������������� ���������� ����������������
milliseconds<==����<
kbytes<==����������<
load<==����������������<
#-----------------------------

#File: PerformanceConcurrency_p.html
#---------------------------
Performance of Concurrent Processes==������������������������������������ ������������������������ ������������������
serverProcessor Objects==���������������� ��������������
#Thread==����������
Queue Size<br />Current==��������������<br />������������ ��������������
Queue Size<br />Maximum==��������.<br />������������ ��������������
Executors:<br />Current Number of Threads==����������������������:<br />�������������� ���������� ��������������
Concurrency:<br />Maximum Number of Threads==����������������������������:<br />��������. ���������� ��������������
Concurrency:<br />Number of Threads==����������������������������:<br />���������� ��������������
Childs==��������������
Average<br />Block Time<br />Reading==��������������<br />���������� ��������������������<br />������������
Average<br />Exec Time==�������������� ���������� ��������������������
Average<br />Block Time<br />Writing==��������������<br />���������� ��������������������<br />������������
Total<br />Cycles==���������� ������������
Full Description==������������ ����������������
#-----------------------------

#File: PerformanceSearch_p.html
#---------------------------
Performance Settings of Search Sequence==������������������ ������������������������������������ ���������������������������������� ������������
Search Sequence Timing==���������������� ���������������������������������� ������������
Timing results of latest search request:==���������������� �������������������� �������������������� �������������������� ��������������:
Query==������������
Event<==��������������<
Comment<==����������������������<
Time<==����������<
Duration \(ms\)==������������������������ (����)
Result-Count==���������� ����������������������
The network picture below shows how the latest search query was solved by asking corresponding peers in the DHT:==���������������������� �������� ��������������������, ���������� ������������������ ������������������ �������������� �������� ���������������� ���� ���������� ���� DHT �� ������������.
red -&gt; request list alive==�������������� -&gt; ���������������� ������������
green -&gt; request has terminated==�������������� -&gt; ���������������������� ������������
grey -&gt; the search target hash order position\(s\) \(more targets if a dht partition is used\)<==���������� -&gt; ������ �������� ������������ (������������ ����������, �������� ������������������������ DHT)<
"Search event picture"=="���������������������� ������������"
#-----------------------------

#File: ProxyIndexingMonitor_p.html
#---------------------------
Indexing with Proxy==�������������������� ���������� ������������-������������
YaCy can be used to 'scrape' content from pages that pass the integrated caching HTTP proxy.==YaCy ���������� �������������������������� ������������������������ ���������������� �� �������������� ������������.
When scraping proxy pages then <strong>no personal or protected page is indexed</strong>;==<strong>������������ �� �������������������� ���������������� ���� ��������������������������</strong>!
# This is the control page for web pages that your peer has indexed during the current application run-time==���������� ���������������� ������-���������������� ������������������������������������ ���������� ���������� ���� ���������� �� �������������� �������������� ��������������������, 
# as result of proxy fetch/prefetch.==�� �������������������� ������������ ������������-��������������.
# No personal or protected page is indexed==������������ ������ �������������������� ���������������� ���� ��������������������������.
those pages are detected by properties in the HTTP header \(like Cookie-Use, or HTTP Authorization\)==���������� ���������������� ������������������������ ���� ������������������ HTTP-������������������ (�������������������������� �������� ������ HTTP-����������������������)
or by POST-Parameters \(either in URL or as HTTP protocol\)==������ ���� �������������������� POST (�� ������������ ������ ������������������������ ���������� HTTP-����������������)
and automatically excluded from indexing.==�� �������������������������� ���������������������� ���� ����������������������������.

You have to==���������� ���������������������������� ������������, �������������� ���� ������������ ������
>setup the proxy<==>������������������<
before use.==.
Proxy Auto Config:==���������������������������� ������������������������ ������������:
this controls the proxy auto configuration script for browsers at http://localhost:8090/autoconfig.pac==���������������������� ������������ ���������������������������� ������������������������ ������������ ������ ������������������ http://localhost:8090/autoconfig.pac
.yacy-domains only==������������ ������������ .yacy
whether the proxy should only be used for .yacy-Domains==�������������������������� ������������-�������������� ������������ ������ �������������� .yacy
Proxy pre-fetch setting:==������������������ ���������������������� ������������:
this is an automated html page loading procedure that takes actual proxy-requested==������������������ �������������������� �������������������� �������������� ���������� ������������-������������
URLs as crawling start points for crawling.==
Prefetch Depth==�������������� ������������������������������ ��������������
A prefetch of 0 means no prefetch; a prefetch of 1 means to prefetch all==0 - �������������������� ������������������������������ ��������������, 1 - ������������������ ������������������������������ ��������������. 
embedded URLs, but since embedded image links are loaded by the browser==������������������������������ ��������������   
this means that only embedded href-anchors are prefetched additionally.==���������� ���������������������� ������������ �� ������������������ href-������������, ������ ������ �������������������� ������������ ���������������������� ������������������.
Store to Cache==������������������ �� ������
It is almost always recommended to set this on. The only exception is that you have another caching proxy running as secondary proxy and YaCy is configured to used that proxy in proxy-proxy - mode.==�������������������������� ������������������ ������������ �� ������ ������������, �������� ���� ���������������������� ������������ �������������������� ������������-������������ �� YaCy ���������������� ���� �������������������������� �� ������������ ������������-������������.
Do Local Text-Indexing==�������������������������� ������������������ ����������
If this is on, all pages \(except private content\) that passes the proxy is indexed.==�������� ����������������, ���� ������ ����������������, ���� ���������������������� ������������, ���������� ��������������������������������.
Do Local Media-Indexing==�������������������������� ������������������ ����������-����������
This is the same as for Local Text-Indexing, but switches only the indexing of media content on.==�������� ����������������, ���� ������ ����������-���������� ���������� ������������������������������.
Do Remote Indexing==���������������������� ������������������ ����������������������������
If checked, the crawler will contact other peers and use them as remote indexers for your crawl.==�������� ����������������, ���� ������ ���������������������������� ���������� ���������� ���������������������������� ������������������ ��������.
If you need your crawling results locally, you should switch this off.==�������� ������ �������������������� ������������ �� ������������������ ��������������������, ���� �������������� �������� ������������.
Only senior and principal peers can initiate or receive remote crawls.==������������ �������������� �� �������������� ��������, ���������� ���������������������� �� ������������������ ��������������������.
Please note that this setting only take effect for a prefetch depth greater than 0.==���������������� ����������������, ������ ������ ������������������ ������������ �������� ������������������ ������������������������������ ��������������.
Proxy generally==������ ������������
Path==��������
The path where the pages are stored \(max. length 300\)==���������� ���������������� ��������
Size</label>==������������</label>
The size in MB of the cache.==������������ �������� �� MB.
"Set proxy profile"=="������������������ ������������������"
The file DATA/PLASMADB/crawlProfiles0.db is missing or corrupted.==�������� DATA/PLASMADB/crawlProfiles0.db ���������������������� ������ ������������������.
Please delete that file and restart.==��������������������, �������������� �������� �������� �� �������������������������� YaCy.
Pre-fetch is now set to depth==�������������� ������������������������������ �������������� ��������������������
Caching is now \#\(caching\)\#off\:\:on\#\(/caching\)\#.==���������������������� #(caching)#��������::������#(/caching)#.
Local Text Indexing is now \#\(indexingLocalText\)\#off::on==�������������������� ������������������ ������������������ ������������ #(indexingLocalText)#��������::������
Local Media Indexing is now \#\(indexingLocalMedia\)\#off::on==�������������������� ������������������ ����������-������������ #(indexingLocalMedia)#��������::������
Remote Indexing is now \#\(indexingRemote\)\#off::on==������������������ �������������������� #(indexingRemote)#��������::������
Cachepath is now set to \'\#\[return\]\#\'.</strong> Please move the old data in the new directory.==�������� ���������������� �������� �������������������� ������ '#[return]#'.</strong>.
Cachesize is now set to \#\[return\]\#MB.==������������ �������� �������������������� �� #[return]#MB .
Changes will take effect after restart only.==������������������ ���������� ������������������ ������������ ���������� ����������������������.
An error has occurred:==������������������ ������������:
You can see a snapshot of recently indexed pages==���� ������������ �������������� �������������� ������������������������������������ ������������
on the==���� ����������������
Page.==


#-----------------------------

#File: QuickCrawlLink_p.html
#---------------------------
Quick Crawl Link==Schnell Crawl Link
Quickly adding Bookmarks:==�������������� �������������������� ����������������:
Simply drag and drop the link shown below to your Browsers Toolbar/Link-Bar.==Ziehen Sie einfach den unten stehenden Link auf Ihre Browser Toolbar/Linkbar.
If you click on it while browsing, the currently viewed website will be inserted into the YaCy crawling queue for indexing.==Wenn Sie, w��hrend Sie surfen, auf dieses Lesezeichen klicken, wird die gerade betrachtete Seite zum YaCy Crawler-Puffer hinzugef��gt, um indexiert zu werden.
Crawl with YaCy==�������������������������� �� YaCy
Title:==������������������:
Link:==������������:
Status:==������������������:
URL successfully added to Crawler Queue==������������ �������������� ������������������ �� �������������� ����������������������.
Malformed URL==������������������������ ������������
Unable to create new crawling profile for URL:==�������������������� �������������� ���������� �������������� ���������������������������� ������ ������������:
Unable to add URL to crawler queue:==�������������������� ���������������� ������������ �� �������������� ����������������������:
#-----------------------------

#File: Ranking_p.html
#---------------------------
Ranking Configuration==Ranking Einstellungen
The document ranking influences the order of the search result entities.==Das Dokument Ranking beeinflusst die Reihenfolge der Suchergebnis Datens��tze.
A ranking is computed using a number of attributes from the documents that match with the search word.==Ein Ranking wird berechnet mit einer Anzahl von Attributen aus den Dokumenten die das gesuchte Wort enthalten.
The attributes are first normalized over all search results and then the normalized attribut is multiplied with the ranking coefficient computed from this list.==Die Attribute werden zuerst ��ber alle Suchergebnisse normalisiert und dann wird das normalisierte Attribut multpliziert mit dem Ranking Koeffizienten der aus dieser Liste errechnet wird.
The ranking coefficient grows exponentially with the ranking levels given in the following table.==Der Ranking Koeffizient w��chst exponential mit den Ranking Werten die in der folgenden Tabelle festgelegt werden.
If you increase a single value by one, then the strength of the parameter doubles.==Wenn Sie einen einzelnen Wert um eins erh��hen wird die St��rke des Parameters verdoppelt.
Pre-Ranking==Vor-Ranking

# Aktuell sind die Werte und Hover over Information in der Ranking_p.java hartcodiert und k��nnen nicht ��bersetzt werden
#
#Date==Datum
#a higher ranking level prefers younger documents.==Ein h��herer Ranking Level bevorzugt j��ngere Dokumente
#The age of a document is measured using the date submitted by the remote server as document date==Das Alter eines Dokuments wird gemessen anhand des Dokument Datums das der Remote Server ��bermittelt

There are two ranking stages:==Es gibt zwei Phasen beim Ranking.
first all results are ranked using the pre-ranking and from the resulting list the documents are ranked again with a post-ranking.==Zuerst werden alle Resultate nach dem Vor-Ranking geranked und aus der resultierenden Liste werden die Dokumente erneut im Nach-Ranking sortiert.
The two stages are separated because they need statistical information from the result of the pre-ranking.==Die zwei Phasen sind getrennt weil statistische Informationen aus dem Ergebnis des Vor-Rankings ben��tigt werden.

Post-Ranking==Nach-Ranking

#Application Of Prefer Pattern==Anwendung eines bevorzugten Musters
#a higher ranking level prefers documents where the url matches the prefer pattern given in a search request.==Ein h��herer Ranking Level bevorzugt Dokumente deren URL auf das bevorzugte Muster einer Suchanfrage passt.

"Set as Default Ranking"=="Als Standard Ranking speichern"
"Re-Set to Built-In Ranking"=="Auf urspr��ngliche Werte zur��cksetzen"
#-----------------------------

#File: RankingRWI_p.html
#---------------------------
RWI Ranking Configuration<==������������������������ ������������������������ RWI<
The document ranking influences the order of the search result entities.==������������������������ �������������������� ������������ ���� ������������������ ������������. 
A ranking is computed using a number of attributes from the documents that match with the search word.==������������������������ ���������������������������� �� ���������������������������� ������������ �������� �������������������� �������������������� �� ������������������������ �� �������������� ������������.  
The attributes are first normalized over all search results and then the normalized attribute is multiplied with the ranking coefficient computed from this list.==������������������ �������������� �������������������� ������ �������������������� ������������, �� ���������� ������������������������ ���������������� �������������������� ���� ���������������������� ������������������������, ���������������������� ���� ���������� ������������.
The ranking coefficient grows exponentially with the ranking levels given in the following table. If you increase a single value by one, then the strength of the parameter doubles.==���������������������� ������������������������ ������������ ������������������������������ �� �������������������������� ��������������, ������������������ �� �������������� ��������. �������� ���� ������������������������ �������� ���������������� ���� ������������, ���� ���������������� ����������������������.
There are two ranking stages: first all results are ranked using the pre-ranking and from the resulting list the documents are ranked again with a post-ranking.==�������� ������ ������������ ������������������������. �������������� ������ �������������������� ���������������������� �� ���������������������������� �������������������������������� ������������������������, �� ���������� ���� ������������ ���������������������� ������������������ ���������������������� ���������� �� ��������-��������������������������.
The two stages are separated because they need statistical information from the result of the pre-ranking.==������ ������������ ������������������, ������ ������ ������ ������������������ �� ���������������������������� �������������������� ���� �������������������� �������������������������������� ������������������������.
Pre-Ranking==������������������������������ ������������������������
>Post-Ranking<==>��������-������������������������<
"Set as Default Ranking"=="�������������������� ������������������������ ����-������������������"
"Re-Set to Built-In Ranking"=="���������������� �� ���������������� ������������������"
#-----------------------------

#File: RankingSolr_p.html
#---------------------------
Solr Ranking Configuration<==������������������������ ������������������������ Solr<
These are ranking attributes for Solr. This ranking applies for internal and remote \(P2P or shard\) Solr access.==������ ������������������ ������������������������ ������ Solr. ������ ������������������������ ���������������������� ������ ���������������������� �� �������������������� (P2P ������ ����������������������) �������������� �� Solr.
Select a profile:==���������������� ��������������:
>Boost Function<==>�������������� Boost<
A Boost Function can combine numeric values from the result document to produce a number which is multiplied with the score value from the query result.==Eine Boost Funktion kann numerische Werte von Ergebnis-Dokumenten kombinieren, um eine Nummer zu erzeugen die mit den Scoring Werten der Suchergebnisse multipliziert wird.
To see all available fields, see the==������ ������������������ �������� ����������������
>YaCy Solr Schema<==>���������� Solr<
and look for numeric values \(these are names with suffix '_i'\).==�� ���������� ���������������� ���������������� (���������������� �� ������������������ '_i').
To find out which kind of operations are possible, see the==���������� ������������ ������������������ ����������������, ����������������
>Solr Function Query<==>������������ �������������� Solr<
documentation.==.
Example: to order by date, use==����������������: ������ �������������������� ���� ��������, ����������������������
, to order by clickdepth, use==, ������ �������������������� ���� �������������� ��������������������, ����������������������
>boost<==>Boost<
"Set Boost Function"=="�������������������� �������������� Boost"
"Re-Set to default"=="������������������������ ���������������� ����-������������������"
>Boost Query<==>������������ Boost<
The Boost Query is attached to every query. Use this to statically boost specific content in the index.==Die Boost Abfrage wird an jede Abfrage angeh��ngt. Verwenden sie diese Einstellung, um spezifischen Inhalt im Index zu boosten.
Example: "fuzzy==����������������: "fuzzy
 means that documents, identified as 'double' are ranked very bad and appended to the end of all results \(because the unique are ranked high\).== bedeutet dass Dokumente die als 'double' identifiziert werden sehr schlecht geranked werden und an das Ende der Suchergebnisliste angeh��ngt werden (weil die eindeutigen hoch geranked werden).
To find appropriate fields for this query, see the ==���������� ���������� ������������������������������ �������� ����������������, ���������������� 
>YaCy Solr Schema<==>���������� Solr<
 and look for boolean values \(with suffix '_b'\) or tags inside string fields \(with suffix '_s' or '_sxt'\).== �� ���������� �������������������� ���������������� (�� ������������������ '_b') ������ �������� ������������ ���������� (�� ������������������ '_s' ������ '_sxt')

#>bq<==>bq<
"Set Boost Query"=="�������������������� ������������ Boost"
#"Re-Set to default"=="������������������������ ���������������� ����-������������������"
#>Solr Boosts<==>Solr Boosts<
This is the set of searchable fields. Entries without a boost value are not searched. Boost values make hits inside the corresponding field more important.==Das ist das Set der suchbaren Felder. Eintr��ge ohne Boost Werte werden nicht durchsucht. Boost Werte erh��hen die Wichtigkeit der Treffer im passenden Feld.
field not in local index \(boost has no effect\)==�������� ������ �� ������������������ �������������� (������������ Boost ���� ����������������������)
"Set Field Boosts"=="�������������������� �������� Boosts"
#"Re-Set to default"=="������������������������ ���������������� ����-������������������"
#-----------------------------

#File: RegexTest.html
#---------------------------
RegexTest==�������� ���������������������� ������������������
Regex Test==�������� ���������������������� ������������������
Test String==�������� ������������
Regular Expression==�������������������� ������������������
This is a ==������ 
Java Pattern==������������ Java
Result<==������������������<
no match<==������ ��������������������<
> match<==> ��������������������<
error in expression:==������������ �� ������������������:
#-----------------------------

#File: RemoteCrawl_p.html
#---------------------------
Remote Crawl Configuration==������������������������ �������������������� ����������������������������
>Remote Crawler<==>������������������ ����������������������������<
The remote crawler is a process that requests urls from other peers.==������������������ ���������������������������� ���������������������� ������ ������������������ ������������ ������ ���������������������������� ���� ������������ ����������.
Peers offer remote-crawl urls if the flag \'Do Remote Indexing\'==�������� �������������������� �������������������� ���������������������� ������������ �� ������������ \'�������������������� ������������������ ����������������������������\' 
is switched on when a crawl is started.==�� ���������� ���������� �������������������� ��������������������.
Remote Crawler Configuration==������������������������ �������������������� ����������������������������
Your peer cannot accept remote crawls because you need senior or principal peer status for that!==������ �������������������� ���������������������������� ������ �������� ������������ �������� �������������� ������ ��������������!
>Accept Remote Crawl Requests<==>������������������ ����������������������������<
Perform web indexing upon request of another peer.==������������������ ������������������ ����������������������������.
Load with a maximum of==������������������ ����������������
pages per minute==�������������� �� ������������
"Save"=="������������������"
Crawl results will appear in the==�������������������� ���������������������������� ���������������� ����������
>Crawl Result Monitor<==>�������������� ���������������������� ����������������������������<
Peers offering remote crawl URLs==�������� ������������������������ ������������ ������ �������������������� ����������������������������
If the remote crawl option is switched on, then this peer will load URLs from the following remote peers:==�������� ������������������ ���������������������������� ������������������, ���� ������ �������� ���������� ������������������ ������������ ���� ������������������ ����������:
>Name<==>������<
URLs for<br/>Remote<br/>Crawl==������������ ������ <br/>������������������ <br/>������������������������
#>Remote<br/>Crawl<==>������������������<br/>��������������������<
>Release<==>������������<
>PPM<==>�������������� �� ������������ (PPM)<
>QPH<==>���������������� �� ������ (QPH)<
>Last<br/>Seen<==>������������������<br/>����������������<
>UTC</strong><br/>Offset<==>UTC</strong><br/><
>Uptime<==>���������� ������������<
>Links<==>������������<
#>RWIs<==>RWIs<
>Age<==>��������������<
#-----------------------------

#File: Settings_p.html
#---------------------------
Advanced Settings==������������������ ��������������
If you want to restore all settings to the default values,==�������� ���� ������������ ������������������������ ������ ���������������� ���������������� ����-������������������,
but <strong>forgot your administration password</strong>, you must stop the proxy,==���� <strong>������������ �������� ������������ ����������������������������</strong>, ���� ���� ������������ �������������������� YaCy,
delete the file 'DATA/SETTINGS/yacy.conf' in the YaCy application root folder and start YaCy again.==�������������� �������� 'DATA/SETTINGS/yacy.conf' �� ���������������� ���������� ������������������ �� �������������������������� YaCy.
Performance Settings of Busy Queues==������������������ ������������������������������������ ���������������� �� ������������������
Viewer and administration for database tables==���������������� �� �������������������� ������������������ �������� ������������
Viewer for Cookies in Proxy==���������������� ���������������� �� �������� (������ �������������������������� ������������-��������������)
Server Access Settings==������������������ �������������� �� ��������������
Proxy Access Settings==������������������ �������������� �� ������������-��������������
Crawler Settings==������������������ ����������������������
HTTP Networking==HTTP ��������
Remote Proxy \(optional\)==������������������ ������������
Seed Upload Settings==������������������ ���������������� ��������
Message Forwarding \(optional\)==���������������� ����������������������
#-----------------------------

#File: Settings_Crawler.inc
#---------------------------
>Crawler Settings<==>������������������ ����������������������<
Generic Crawler Settings==���������� ������������������ ����������������������
Connection timeout in ms==�������������������� �� ��������������������������
means unlimited==���������������� ����������������������������
HTTP Crawler Settings:==������������������ �������������������� ���� HTTP:
Maximum Filesize==������������������������ ������������ ����������
FTP Crawler Settings==������������������ �������������������� ���� FTP
SMB Crawler Settings==������������������ �������������������� ���� SMB
Local File Crawler Settings==������������������ �������������������� ������������������ ������������
Maximum allowed file size in bytes that should be downloaded==���������������������� ���������������������� ������������ ������������������������ ����������
Larger files will be skipped==���������� ���������������� �������������� ���������� ������������������
Please note that if the crawler uses content compression, this limit is used to check the compressed content size==���������������� ����������������, ������ �������� �������������������� �������������������� ������������ ��������������, ���� ������ ���������������������� ������������������ ������������ �������������� ����������������
Submit==������������������
Changes will take effect immediately==������������������ ���������� ������������������ ��������������������
Timeout:==����������������:
#-----------------------------

#File: Settings_Http.inc
#---------------------------

#-----------------------------

#File: Settings_Proxy.inc
#---------------------------
Remote Proxy \(optional\)==������������������ ������������
YaCy can use another proxy to connect to the internet. You can enter the address for the remote proxy here:==YaCy ���������� ������������������������ ������������ ������������ ������ �������������������� �� ��������������������. ���� ������������ �������������� ���������� �������������������� ������������ ����������.
Use remote proxy</label>==������������������������ ������������������ ������������</label>
Enables the usage of the remote proxy by yacy==������������������ �������������������������� �������������������� ������������
Use remote proxy for yacy &lt;-&gt; yacy communication==������������������������ ������������������ ������������ ������ ���������� ���������� ������������
Specifies if the remote proxy should be used for the communication of this peer to other yacy peers.==������������������ �������������������������� �������������������� ������������ ������ ���������� ������������ �������� �� �������������� ������������.
<em>Hint:</em> Enabling this option could cause this peer to remain in junior status.==<em>����������:</em> ������������������ �������� ���������� ���������� �������������� ������ �������� ��������������.
Use remote proxy for HTTPS==������������������������ ������������������ ������������ ������ HTTPS-������������������
Specifies if YaCy should forward ssl connections to the remote proxy.==������������������ ������������������������ SSL-�������������������� ������ �������������������� ������������.
Remote proxy host==�������� �������������������� ������������
The ip address or domain name of the remote proxy==IP-���������� ������ ���������� �������������������� ������������
Remote proxy port==�������� �������������������� ������������
the port of the remote proxy==
Remote proxy user==������������������������ �������������������� ������������
Remote proxy password==������������ �������������������� ������������
No-proxy adresses==���� ������������������������ ������ ������������ ������������
IP addresses for which the remote proxy should not be used==IP-������������, ������ �������������� ������������������ ������������ ���� ������������������������
"Submit"=="������������������"
Changes will take effect immediately.==������������������ ���������� ������������������ ��������������������.
#-----------------------------

#File: Settings_ProxyAccess.inc
#---------------------------
Proxy Settings==������������������ ������������
Transparent Proxy==�������������������� ������������
With this you can specify if YaCy can be used as transparent proxy.==���������������� ������ ����������, �������� ������ ���������� ������������������������ YaCy �� ���������������� ���������������������� ������������.
Hint: On linux you can configure your firewall to transparently redirect all http traffic through yacy using this iptables rule==����������: �� ������������-���������������� ���� ������������ ������������������ �������������� ���� �������������������� ������������������������������ ���������� �������������� ���������� YaCy �� ���������� ������������������ iptables
With this you can specify if YaCy should support the HTTP connection keep-alive feature.==���������������� ������ ����������, �������� ������ �������������������� �������������������� �������������������� �� YaCy.
Send "Via" Header==�������������������� ������������������ "Via"
Specifies if the proxy should send the <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.45" target="_blank">Via</a>==����������������, �������� ������������ ������������ �������������������� ������������������ <a href="http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.45" target="_blank">Via-HTTP-Header</a>
http header according to RFC 2616 Sect 14.45.==, ������������������ �� RFC 2616 ������������ 14.45.
Send "X-Forwarded-For" Header==�������������������� ������������������ "X-Forward-For"
Specifies if the proxy should send the X-Forwarded-For http header.==����������������, �������� ������������ ������������ �������������������� ������������������ "X-Forward-For"
"Submit"=="������������������"
Changes will take effect immediately.==������������������ ���������� ������������������ ��������������������.
HTTP Server Port==�������� HTTP
HTTPS Server Port==�������� HTTPS
"change"=="����������������"
Version==������������
Proxy Access Settings==������������������ �������������� �� ������������
These settings configure the access method to your own http proxy and server.==���������� ���� ������������ ������������������ ������������ �� ������������ http-������������ �� ��������������.
All traffic is routed throug one single port, for both proxy and server.==�������� ������������ ������������������������ ���� �������� �������� ������ ������������ �� ��������������.
Server/Proxy Port Configuration==������������������ ���������� ��������������/������������
The socket addresses where YaCy should listen for incoming connections from other YaCy peers or http clients.==������������ ��������������, �������������� ���������������������������� ���� ���������������� �������������������� ���� ������������ ���������� ������ http-����������������.
You have four possibilities to specify the address:==���� ������������ �������������� ������������ ������������:
defining a port only==������������ ������������ ��������
<em>e.g. 8090</em>==<em>����������������, 8090</em>
defining IP address and port==������������ IP-���������� �� ��������
<em>e.g. 192.168.0.1:8090</em>==<em>����������������, 192.168.0.1:8090</em>
defining host name and port==������������ ������ ���������� �� ��������
<em>e.g. home:8090</em>==<em>����������������, home:8090</em>
defining interface name and port==������������ ������ �������������������� �� ��������
<em>e.g. #eth0:8090</em>==<em>����������������, #eth0:8090</em>
Hint: Dont forget to change your firewall configuration after you have changed the port.==����������: ���� ���������������� ���������������� ������������������ ���������������� ���������� ������������������ ����������.
Proxy and http-Server Administration Port==�������� ������������ �� http-��������������
Changes will take effect in 5-10 seconds==������������������ ���������� ������������������ ���������� 5-10 ������������
Server Access Restrictions==���������������������� �������������� �� ��������������
You can restrict the access to this proxy/server using a two-stage security barrier:==���� ������������ �������������������� ������������ �� ������������ ������������/�������������� ������������������ �������������������������� ������������:
define an <em>access domain</em> with a list of granted client IP-numbers or with wildcards==�������������������� <em>������������ �� ������������</em> �������������� ������������������������������ �������������� IP-������������ ������ ����������������
define an <em>user account</em> with an user:password - pair==�������������������� <em>�������������� ������������ ������������������������</em> �� �������������� �� ��������������
This is the account that restricts access to the proxy function.==���������� �������������� ������������ ���������� ���������� ������������������������ ������������ �� ���������������� ������������.
You probably don't want to share the proxy to the internet, so you should set the==�������� ���� ���� �������������� ������������������������ ���������� ������������ ������ ������������������, ���� ������������ ��������������
IP-Number Access Domain to a pattern that corresponds to you local intranet.==IP-���������� ���������� ������������������ �������� �� �������������� ��������.
The default setting should be right in most cases. If you want, you can also set a proxy account==������������������ ����-������������������ ���������������� �� ���������������������� ��������������. ���� ���������� ������������ �������������������� �������������� ������������ ������������
so that every proxy user must authenticate first, but this is rather unusual.==, ���������� �������������� ������������������������������ ������������ ������������������������ ������������. ������������ ������ ���� ������������������������.
IP-Number filter==������������ IP-��������������
Use <a==������������������������ <a
"Submit"=="������������������"
#-----------------------------

#File: Settings_Seed.inc
#---------------------------
Seed Upload Settings==������������������ ���������������� ��������
With these settings you can configure if you have an account on a public accessible==���������� ���� ������������ �������������� ������������ ���������� �������������� ������������ ���� ����������
server where you can host a seed-list file.==��������������, ������ ���� �������������� ������-������������.
General Settings:==���������� ������������������:
If you enable one of the available uploading methods, you will become a principal peer.==�� ������������ ������������������, ������ �������� ������������ ��������������. 
Your peer will then upload the seed-bootstrap information periodically,==������ �������� ���������������� ������������������ �������������������� �� ��������,
but only if there have been changes to the seed-list.==������������ �������� ������-������������ ���������� ��������������.
Upload Method==������������ ����������������
"Submit"=="������������������"
>URL<==>������������<
Retry Uploading==������������������ ����������������
Here you can specify which upload method should be used.==���������� ���� ������������ �������������� ���������������� ������������ ����������������.
Select 'none' to deactivate uploading.==���������������� 'none' ������ �������������������� ����������������.
The URL that can be used to retrieve the uploaded seed file, like==������������ ������ ���������������� ���������� ��������, ������������������
#-----------------------------

#File: Settings_Seed_UploadFile.inc
#---------------------------
Store into filesystem:==���������������� ���� ������������������ ����������:
You must configure this if you want to store the seed-list file onto the file system.==������������������ �������� �� ������-������������.
File Location==�������� �� ����������
Here you can specify the path within the filesystem where the seed-list file should be stored.==���������� ���� ������������ �������������� �������� �� ������-������������.
"Submit"=="������������������"
#-----------------------------

#File: Settings_Seed_UploadFtp.inc
#---------------------------
Uploading via FTP:==���������������� ���� FTP:
This is the account for a FTP server where you can host a seed-list file.==������ ������������ FTP-��������������, ������ ���� �������������������� �������� ������-������������.
If you set this, you will become a principal peer.==�� ������������ ������������������, ������ �������� ������������ ��������������.
Your peer will then upload the seed-bootstrap information periodically,==������ �������� ���������������� ������������������ �������������������� �� ��������,
but only if there had been changes to the seed-list.==������������ �������� ������-������������ ���������� ��������������.
The host where you have a FTP account, like==������������ ������������ FTP-��������������, ������������������
Path</label>==��������</label>
The remote path on the FTP server, like==������������������ �������� FTP-��������������, ������������������
Missing sub-directories are NOT created automatically.==�������������������������� ���������������� ���� ������������������ ��������������������������.
Username==������ ������������������������
>Server<==>������������<
Your log-in at the FTP server==������ ���������� ���� FTP-��������������
Password</label>==������������</label>
The password==������ ������������
"Submit"=="������������������"
#-----------------------------

#File: Settings_Seed_UploadScp.inc
#---------------------------

Uploading via SCP:==���������������� ���� SCP:
This is the account for a server where you are able to login via ssh.==������ �������������� ������������ ������ ��������������, ���� �������������� ���� �������������� ���������� ���������� ssh.
>Server<==>������������<
The host where you have an account, like 'my.host.net'==��������, ���� �������������� ���� ������������ �������������� ������������, ������������������ 'mein.host.net' 
Server&nbsp;Port==��������&nbsp;��������������
The sshd port of the host, like '22'==Sshd-�������� ����������, ������������������ '22'
Path</label>==��������</label>
The remote path on the server, like '~/yacy/seed.txt'. Missing sub-directories are NOT created automatically.==������������������ �������� ���� ��������������, ������������������ '~/yacy/seed.txt'. �������������������������� ���������������� ���� ������������������ ��������������������������.
Username==������ ������������������������
Your log-in at the server==������ ���������� ���� ��������������
Password</label>==������������</label>
The password==������ ������������
"Submit"=="������������������"
#-----------------------------

#File: Settings_ServerAccess.inc
#---------------------------
Server Access Settings==������������������ �������������� �� ��������������
IP-Number filter:==������������ IP-��������������:
requires restart==���������������������� ��������������������
Here you can restrict access to the server.==���������� ���� ������������ ������������������ ������������ �� ��������������.
By default, the access is not limited,==����-������������������ ������������ ����������������������,
because this function is needed to spawn the p2p index-sharing function.==������������ ������ ������ �������������������� ������ ������������ ���������������� �������������� ���������������������� ��������������.
If you block access to your server \(setting anything else than \'\*\'\), then you will also be blocked==�������� ���� ������������������������ ������������ �� ������������ ��������������, ���� ���� ���������� ������������������������
from using other peers' indexes for search service.==�������������������������� ������������ ���������������� �������������� ������������.
However, blocking access may be correct in enterprise environments where you only want to index your==���������������������� �������������� ���������� �������� ���������������� �� �������������������������� ��������, ������ ������������������ ������������ ���������������������������� 
company's own web pages.==������-�������������� ����������������.
Filter have to be entered as IP, IP range or first part of allowed IP's separated by comma \(e.g. 10.100.0-100.0-100, 127. \)== ������������ ���������������� ���� ip-������������, ���� ������������������ ip-�������������� ������ ���� ������������ ������������ ip-������������ ���������� ��������������, (����������������  10.100.0-100.0-100, 127.)
further details on format see Jetty ==������������������ �������������������� ���� IPAccessHandler ����������������
<a href="http://download.eclipse.org/jetty/8.1.14.v20131031/apidocs/org/eclipse/jetty/server/handler/IPAccessHandler.html" target="_blank">IPAccessHandler</a> docu.==<a href="http://download.eclipse.org/jetty/8.1.14.v20131031/apidocs/org/eclipse/jetty/server/handler/IPAccessHandler.html" target="_blank">����������</a>.
staticIP \(optional\):==�������������������� IP-���������� (��������������������������):
<strong>The staticIP can help that your peer can be reached by other peers in case that your==<strong>�������������������������� ���������������������� IP-������������ ���������� ������������ ������������ �������� ���������������������� �� �������������� ������������
peer is behind a firewall or proxy.</strong> You can create a tunnel through the firewall/proxy==�� ������������, �������� ���� ���������������������� �������������� ������ ������������.</strong> ���� ������������ �������������� �������������� ���������� �������������� ������ ������������
\(look out for 'tunneling through https proxy with connect command'\) and create==(�������������� "���������������������������� ���������� HTTPS-������������ �� ������������������������") �� ����������������
an access point for incoming connections.==���������� �������������� ������ ���������������� ��������������������.
This access address can be set here \(either as IP number or domain name\).==���������� �������������� ���������� �������� �������������������� ���������� (������ IP-���������� ������ ������ ����������).
If the address of outgoing connections is equal to the address of incoming connections,==�������� ������������ ������������������ �� ���������������� �������������������� ������������������,
you don't need to set anything here, please leave it blank.==���� ���������������� �������� ������������.
ATTENTION: Your current IP is recognized as "#\[clientIP\]#".==����������������: ������ �������������� IP-���������� ������������������ ������ "#[clientIP]#".
If the value you enter here does not match with this IP,==�������� IP-���������� ������������������ ��������, ���� ���������� ������������������ �� �������� IP-��������������,
you will not be able to access the server pages anymore.==���� ���� ������������ ���� �������������� ���������������� ������������ �� ������������������ ��������������.
value="Submit"==value="������������������"
#-----------------------------

#File: SettingsAck_p.html
#---------------------------
YaCy \'\#\[clientname\]\#\': Settings Acknowledge==YaCy '#[clientname]#': �������������������� ��������������������
Settings Receipt:==������������������ ������������������ �������� ����������������:
No information has been submitted==������������������ ���� ��������������������������.
Error with submitted information.==������������ ������ �������������������� ������������������.
Nothing changed.</p>==������������������ ���� ��������������������������.</p>
The user name must be given.==�������������� ������ ������������������������
Your request cannot be processed.==������ ������������ ���� ���������� �������� ����������������.
The password redundancy check failed. You have probably misstyped your password.==������������ ������������ ��������������. �������������� ������������ ������ ������.
Shutting down.</strong><br />Application will terminate after working off all crawling tasks.==��������������������.</strong><br />�������������������� ���������� �������������� ���������� �������������������� ����������������������������.
Your administration account setting has been made.==�������� �������������� ������������ ������������������ ��������������.
Your new administration account name is \#\[user\]\#. The password has been accepted.<br />If you go back to the Settings page, you must log-in again.==�������� ���������� ������ ������������������������ #[user]#. ������������ ������������.<br />������ ���������������� ���� ���������������� ����������������, �������������� ������ ������������������������ �� ������������ ����������.
Your proxy access setting has been changed.==������������������ ������������ ����������������.
Your proxy account check has been disabled.==�������������� ������������ ������������ ������������������.
The new proxy IP filter is set to==IP-������������ ������������: 
The proxy port is:==�������� ������������:
Port rebinding will be done in a few seconds.==�������� ���������� �������������� ���������� ������������������ ������������.
You can reach your YaCy server under the new location==���� ������������ ������������������ ������ ������������ YaCy ���� ������������ ����������:
Your proxy access setting has been changed.==������������������ �������������� �� ������������ ����������������.
Your server access filter is now set to==������������ �������������� �� �������������� �������������������� - 
Auto pop-up of the Status page is now <strong>disabled</strong>==������������������������ ���������������� ������������������ <strong>������������������.</strong>
Auto pop-up of the Status page is now <strong>enabled</strong>==������������������������ ���������������� ������������������ <strong>����������������.</strong>
You are now permanently <strong>online</strong>.==������������ ���� ������������������ <strong>�� ��������</strong>.
After a short while you should see the effect on the====���������� ������������������ ���������� ���� �������������� ������������������ ����
status</a> page.==����������������</a> ������������������.
The Peer Name is:==������ ������������ ��������:
Your static Ip\(or DynDns\) is:==������ �������������������� IP-���������� (������ DynDns):
Seed Settings changed.\#\(success\)\#::You are now a principal peer.==������������������ ������-�������������� ����������������.#(success)#::������ �������� ������������ ���������������� ��������������.
Seed Settings changed, but something is wrong.==������������������ ������-�������������� ����������������, ���� ������������������ ������������.
Seed Uploading was deactivated automatically.==���������������� ������-������������ �������� ������������������ ��������������������������.
Please return to the settings page and modify the data.==��������������������, ������������������ ���� ���������������� ���������������� �� ���������������� ������������.
The remote-proxy setting has been changed==������������������ �������������������� ������������ ����������������.
If you open any public web page through the proxy, you must log-in.==������ ������������������ ���������� �������������� ������-���������������� ���������� ������������, �������������������� ������������ ������ ������������������������ �� ������������.
The new setting is effective immediately, you don't need to re-start.==���������� ������������������ ���������� ������������������ ��������������������.
The submitted peer name is already used by another peer. Please choose a different name.</strong> The Peer name has not been changed.==������������������ ������ �������� ������ ������������������������. ��������������������, ���������������� ������������ ������ ������ ������������ ��������.</strong> ������ �������� ���� ����������������.
Your Peer Language is:==�������� ������������ ��������:
The submitted peer name is not well-formed. Please choose a different name.</strong> The Peer name has not been changed.
Peer names must not contain characters other than (a-z, A-Z, 0-9, '-', '_') and must not be longer than 80 characters.
#The new parser settings where changed successfully.==���������� ������������������ �������������� �������� ���������������� ��������������.
Parsing of the following mime-types was enabled:==������������ ������������������ ���������� ������������ ����������������:
Seed Upload method was changed successfully.==������������ ���������������� ������-������������ ������ �������������� ��������������.
You are now a principal peer.==������ �������� ������������ ���������������� ��������������.
Seed Upload Method:==������������ ���������������� ������-������������:
Seed File URL:==������������ ���� ������-������������:
Your proxy networking settings have been changed.==������������������ ������������������ HTTP ����������������.
Transparent Proxy Support is:==�������������������� ������������:
Connection Keep-Alive Support is:==�������������������� ��������������������:
Your message forwarding settings have been changed.==������������������ ���������������� ������������������ �������� ����������������.
Message Forwarding Support is:==���������������� ������������������:
Message Forwarding Command:==�������������� ������ ���������������� ������������������:
Recipient Address:==���������� ��������������������:
Please return to the settings page and modify the data.==��������������������, ������������������ ���� ���������������� ���������������� �� ���������������� ������������.
You are now <strong>event-based online</strong>.==���� <strong>������������</strong>.
After a short while you should see the effect on the==���������� ������������������ ���������� ���� �������������� ������������������ ����
You are now in <strong>Cache Mode</strong>.==���� <strong>���������������������� ������������ ������</strong>.
Only Proxy-cache ist available in this mode.==������������ ������-������������ ���������������� �� �������� ������������.
After a short while you should see the effect on the==���������� ������������������ ���������� ���� �������������� ������������������ ����
You can now go back to the==������ ���������������� ���� ���������������� ���������������� ��������������, ��������������
Settings</a> page if you want to make more changes.==����������</a>.
You can reach your YaCy server under the new location==���� ������������ ������������������ ������ ������������ YaCy ���� ������������ ����������::
Send via header is:==�������������������� ������������������ "Via":
Send X-Forwarded-For header is:==�������������������� ������������������ "X-Forward-For":
Your crawler settings have been changed.==������������������ ���������������������� �������� ����������������.
Generic Settings:==���������� ������������������:
Crawler timeout:==���������������� ����������������������
http Crawler Settings:==������������������ �������������������� ���� HTTP:
Maximum HTTP Filesize:==������������������������ ������������ ����������:
ftp Crawler Settings:==������������������ �������������������� ���� FTP:
Maximum SMB Filesize:==������������������������ ������������ ����������:
Maximum file Filesize:==������������������������ ������������ ����������:
Maximum FTP Filesize:==������������������������ ������������ ����������:
smb Crawler Settings:==������������������ �������������������� ���� SMB:
#-----------------------------

#File: Settings_MessageForwarding.inc
#---------------------------
Message Forwarding==���������������� ������������������
With this settings you can activate or deactivate forwarding of yacy-messages via email.==���� ������������ ���������������� �� ������������������ ���������������� ������������������ YaCy ���� ���������������������� ����������.
Enable message forwarding==���������������� ���������������� ������������������
Enabling/Disabling message forwarding via email.==������������������/�������������������� ���������������� ������������������ ���� ���������������������� ����������
Forwarding Command==�������������� ������ ����������������
The command-line program that should be used to forward the message.<br />==�������� �� ������������������, �������������� ���������� ���������������������������� ������ ���������������� ������������������.<br />
Forwarding To==������������������ ����
The recipient email-address.<br />==���������� ���������������������� ���������� ��������������������<br />
e.g.:==����������������:
"Submit"=="������������������"
Changes will take effect immediately.==������������������ ���������� ������������������ ��������������������.
#-----------------------------

#File: sharedBlacklist_p.html
#---------------------------
Shared Blacklist==���������� ������������ ������������
Add Items to Blacklist==���������������� ���������������� �� ������������ ������������
Unable to store the items into the blacklist file:==�������������������� ������������������ ���������������� �� ���������� �������������� ������������:
#File Error! Wrong Path?==������������! ���������������� ��������?
YaCy-Peer &quot;<span class="settingsValue">\#\[name\]\#</span>&quot; not found.==�������� YaCy &quot;<span class="settingsValue">#[name]#</span>&quot; ���� ������������.
not found or empty list.==���� ������������ ������ ������������ ������������.
Wrong Invocation! Please invoke with==������������������������ ����������! ��������������������, ���������������� ��
Blacklist source:==Blacklist Quelle:
Blacklist target:==Blacklist Ziel:
Blacklist item==Blacklist Eintrag
"select all"=="�������������� ������"
"deselect all"=="���������������� ����������"
value="add"==����������������="����������������"
#-----------------------------

#File: Status.html
#---------------------------
Console Status==�������������� �������������������� ����������
Log-in as administrator to see full status==����������, ������ ��������������������������
Welcome to YaCy!==���������� �������������������� �� YaCy!
Your settings are _not_ protected!</strong>==�������� ������������������ ���� ���������������� ��������������!</strong>
Please open the <a href="ConfigAccounts_p.html">accounts configuration</a> page <strong>immediately</strong>==�������������������� ������������������ ���� ������������ <a href="ConfigAccounts_p.html">������������������ ����������������</a> <strong>��������������������</strong>
and set an administration password.==�� �������������������� ������������ ����������������������������.
You have not published your peer seed yet. This happens automatically, just wait.==������ �������� ������ ���� ��������������. ���������������������� �������������� ��������������, ��������������������, ������������������.
The peer must go online to get a peer address.==������ �������� ������������ �������� ������������ ������ ������������������ �������������� ������������ ����������.
You cannot be reached from outside.==������ �������� �������������������� ����������.
A possible reason is that you are behind a firewall, NAT or Router.==����������������, ���� �������������������� ���� ������������������������, NAT ������ ����������������.
But you can <a href="index.html">search the internet</a> using the other peers'==���� ���� ������������ <a href="index.html">������������������ ����������</a>, �� �������������� ������������ ����������
global index on your own search page.==���� �������������� ���������������� ������������.
"bad"=="������������"
"idea"="��������"
"good"="��������������"
"Follow YaCy on Twitter"=="������������ ���� YaCy ���� Twitter"
We encourage you to open your firewall for the port you configured \(usually: 8090\),==�������������������������� �������������� ������������ �� �������������������������� ���������� (������������, 8090) ���� ���������� ����������������������,
or to set up a 'virtual server' in your router settings \(often called DMZ\).==������ ������������������ "���������������������� ������������" ���� ���������� �������������� (������������������ ������������ �������������������� DMZ).
Please be fair, contribute your own index to the global index.==��������������������, �������������� �������������� �� ���������������� ���������������������� �������������������� ��������������.
Free disk space is lower than \#\[minSpace\]\#. Crawling has been disabled. Please fix==������������������ ���������� ���� ���������� ������������, ������ #[minSpace]#. ���������������������������� ������������ ����������������������������. ��������������������, �������������������� ���������� ���� ����������.
it as soon as possible and restart YaCy.==���������������������� �������������������� YaCy.
Free memory is lower than \#\[minSpace\]\#. DHT has been disabled. Please fix==������������������ ������������ ������������, ������ \#\[minSpace\]\#. DHT ����������������. ��������������������, ������������������. 
Crawling is paused! If the crawling was paused automatically, please check your disk space.==���������������������������� ����������������������! �������� ���������������������������� ���������������������� ���� ��������, ���� ������������������ ������������������ ���������� ���� ����������.
Latest public version is==������������������ ������������������ ������������
You can download a more recent version of YaCy. Click here to install this update and restart YaCy:==���� ������������ ������������������ ���������� ������������������ ������������ ������������������. �������������� ���������� ������ ������������������ ���������� �������������������� �� ���������������������� YaCy:
#"Update YaCy"=="���������������� YaCy"
Install YaCy==������������������ YaCy
You can download the latest releases here:=���� ������������ ������������������ ������������������ ������������ ������������������ ����������:
You are running a server in senior mode and you support the global internet index,==������ �������� ���������������� �������������� �� ���� �������������������� �� ���������������� ���������������������� �������������� ������������������,
which you can also <a href="index.html">search yourself</a>.==�������������� ���� ���������� ������������ <a href="index.html">������������������������ ������ ������������ ������������</a>.
You have a principal peer because you publish your seed-list to a public accessible server==������ �������� ���������������� �������������� �� ���� ������������ ���������������������� �������� ������-�������� ���� ����������������-������������������ ��������������,
where it can be retrieved using the URL==������ ���� ���������� �������� �������������� �� �������������� ������������:
Your Web Page Indexer is idle. You can start your own web crawl <a href="CrawlStartSite.html">here</a>==������ �������������������� ������-������������ ��������������������. ���� ������������ ������������ ���������������������������� ���������� <a href="CrawlStartSite.html">���� ������������</a>
Your Web Page Indexer is busy. You can <a href="Crawler_p.html">monitor your web crawl</a> here.==������ �������������������� ������-������������ ����������������. ���� ������������ �������������������� ������ ������������ <a href="Crawler_p.html">���� �������� ������������</a>
If you need professional support, please write to==�������� ������ ���������� �������������������������������� ������������������, ��������������������, ����������������
For community support, please visit our==������ ������������������ ������������������ ��������������������, ��������������������, ���������������� ������
>forum<==>����������<
#-----------------------------

#File: Status_p.inc
#---------------------------
System Status==������������ ��������������
System==��������������
YaCy version==������������ YaCy
Unknown==����������������������
Uptime==���������� ������������
Processors:==��������������������:
Load:==���������������� ��������������������:
Protection==������������
Password is missing==������������ ���� ������������������������
password-protected==������������ ������������������������
Unrestricted access from localhost==���������������������������� ������������ �� �������������������� ����������
Address</dt>==����������</dt>
peer address not assigned==���������� �������� ���� ����������������
Host:==������ ��������:
Public Address:==�������������� IP-����������:
YaCy Address:==YaCy-����������:
Peer Host==�������� ����������
#Port Forwarding Host==�������� �������������������������� ��������
Proxy</dt>==������������</dt>
Transparent ==������������������������ 
not used==���� ������������������������
broken::connected==����������������::��������������������
broken==����������������
connected==��������������������
not used==���� ������������������������
Used for YaCy -> YaCy communication:==������������������������ ������ YaCy -> YaCy ������������������������:
WARNING:==����������������������������:
You do this on your own risk.==���� �������������� ������ ���� �������� ��������.
If you do this without YaCy running on a desktop-pc, this will possibly break startup.==���������������������� ������ ����������, ������������ �������� YaCy ��������������.
In this case, you will have to edit the configuration manually in DATA/SETTINGS/yacy.conf==������ �� ������������ ���������� ���� ������������ ���������������� �������������� ���������� �������� DATA/SETTINGS/yacy.conf
Remote:==������������������ ������������
Tray-Icon==������������ �� ��������
Experimental<==����������������<
Yes==����
No==������
Auto-popup on start-up==������������������ ������ ������������
Disabled==������������������
Enable\]==����������������]
Enabled==����������������
Disable\]==������������������]
Memory Usage==�������������������������� ������������
RAM used:==RAM ������������������������:
RAM max:==RAM ����������������:
DISK used:==���� ���������� ������������������������:
\(approx.\)==(����������������)
DISK free:==���� ���������� ����������������:
on::off==������::��������

Configure==������������������
max:==����������������������:
Configure==������������������
Traffic ==�������������� 
>Reset==>����������
Proxy:==������������:
Crawler:==��������������������:
Incoming Connections==���������������� ��������������������
Active:==��������������:
Max:==����������������������:
Indexing Queue==�������������� ��������������������
Loader Queue==������������������ ����������������
paused==����������
>Queues<==>��������������<
Local Crawl==������������������ ��������������������
Remote triggered Crawl==������������������ ��������������������
Pre-Queueing==������������������������������ ��������������
Seed server==������-������������
Configure==������������������
Enabled: Updating to server==����������������: �������������������� ���� ������������:
Last upload: #\[lastUpload\]# ago.==������������������ ����������������: #\[lastUpload\]#
Enabled: Updating to file==����������������: �������������������� ���� ����������
#-----------------------------

#File: Steering.html
#---------------------------
Steering</title>==��������������������</title>
Checking peer status...==���������������� ������������������ ��������...
Peer is online again, forwarding to status page...==�������� ���������� ������������. ������������������������������ ���� ���������������� �������������������� ���������� ...
Peer is not online yet, will check again in a few seconds...==�������� �������� ���� ������������. �������������� ���������� ������������������ ������������...
No action submitted==������ ���������������������� ����������������
Go back to the <a href="Settings_p.html">Settings</a> page==������������������ ���������� ���� ���������������� <a href="Settings_p.html">����������������</a>
Your system is not protected by a password==������ �������� ���� �������������� ��������������
Please go to the <a href="ConfigAccounts_p.html">User Administration</a> page and set an administration password.==��������������������, ������������������ ���� ���������������� <a href="ConfigAccounts_p.html">�������������������� ����������</a> �� �������������������� ������������ ����������������������������.
You don't have the correct access right to perform this task.==���� ���� ������������ �������������������� �������� ������ �������������������� ���������� ����������������.
Please log in.==��������������������, ��������������������������.
You can now go back to the <a href="Settings_p.html">Settings</a> page if you want to make more changes.==���� ������������ ������������������ ���� ���������������� <a href="Settings_p.html">����������������</a>, �������� �������������� �������������������� ������������������ �������������������� ��������.
See you soon!==���� ��������������!
Just a moment, please!==��������������������, ������������������!
Application will terminate after working off all scheduled tasks.==�������������������� ������������������ �������� ������������.
Please send us feed-back!==��������������������, ���������������������� ������ ������������!
We don't track YaCy users, YaCy does not send \'home-pings\', we do not even know how many people use YaCy as their private search engine.==���� ���� ������������ ���� ���������������������������� YaCy. ���� �������� ���� ���������� ������ ���������� ���������� �������������������� �������������� YaCy ������ ������������ ����������.
Therefore we like to ask you: do you like YaCy\? Will you use it again... if not, why\? Is is possible that we change a bit to suit your needs\?==���������������� ��������: ���� ������ ������ ���������������� YaCy? ���� ������������ ������������������������ ������ ����������... ������ ������... ������������?
Please send us feed-back about your experience with an==��������������������, ������������������ ������ ���������� �� ���������� ���������� ��������������������������
>anonymous message<==>����������������<
or a<==������<
posting to our==���� ����������
web forums==������������
>bug report<==>������������������ ������ ���������� �� ������������������ ��������������.<
>Professional Support<==>�������������������������������� ������������������<
If you are a professional user and you would like to use YaCy in your company in combination with consulting services by YaCy specialists, please see==�������� ���� �������������� ������������������������ YaCy ������ �������� ���������� ����������������, ����, ��������������������, ����������������
Then YaCy will restart.==�� ���������� ����������������������������.
If you can't reach YaCy's interface after 5 minutes restart failed.==�������� ������������������ YaCy ���� ���������������� �� �������������� �������� ����������, ���� ������������ ����������������.
Installing release==������������������������������ ����������
YaCy will be restarted after installation==YaCy ���������� ���������������������� ���������� ������������������.
#-----------------------------

#File: Supporter.html
#---------------------------
Supporter<==��������������<
"Please enter a comment to your link recommendation. (Your Vote is also considered without a comment.)"
Supporter are switched off for users without authorization==���������������� ������������������ ������ ��������������������������, ���� ������������������ ����������������������
"bookmark"=="����������������"
"Add to bookmarks"=="���������������� �� ����������������"
"positive vote"=="����������������������"
"Give positive vote"=="������������ ����������������������"
"negative vote"=="���� ����������������������"
"Give negative vote"=="������������ ���� ����������������������"
provided by YaCy peers with an URL in their profile. This shows only URLs from peers that are currently online.==bereitgestellt durch YaCy Peers mit einer URL in ihrem Profil. Es werden nur URLs von Peers angezeigt, die online sind.
#-----------------------------

#File: Surftips.html
#---------------------------
Surftips</title>==������������</title>
Surftips</h2>==Surftipps</h2>
Surftips are switched off==Surftipps sind ausgeschaltet
title="bookmark"==title="����������������"
alt="Add to bookmarks"==alt="���������������� �� ����������������"
title="positive vote"==title="����������������������"
alt="Give positive vote"==alt="������������ ����������������������"
title="negative vote"==title="���� ����������������������"
alt="Give negative vote"==alt="������������ ���� ����������������������"
YaCy Supporters<==�������������������� YaCy<
>a list of home pages of yacy users<==>������������ ���������������� �������������� �������������������������� YaCy<
provided by YaCy peers using public bookmarks, link votes and crawl start points==automatisch erzeugt durch ��ffentliche Lesezeichen, Link-Bewertungen und Crawl-Startpunkte anderer YaCy-Peers
"Please enter a comment to your link recommendation. \(Your Vote is also considered without a comment.\)"=="Bitte geben Sie zu Ihrer Linkempfehlung einen Kommentar ein. (Ihre Stimme wird auch ohne Kommentar angenommen.)"
#"authentication required"=="Autorisierung erforderlich"
Hide surftips for users without autorization==Verberge Surftipps f��r Benutzer ohne Autorisierung
Show surftips to everyone==Zeige Surftipps allen Benutzern
#-----------------------------

#File: Table_API_p.html
#---------------------------
: Peer Steering==: �������������������� ����������
The information that is presented on this page can also be retrieved as XML==�������������������� ���������������������������� ���� �������� ����������������, ���������� ���������� �������� ���������������� �� XML-��������������.
Click the API icon to see the XML.==�������������� ���� ������������ API ������ ������������������ XML.
To see a list of all APIs, please visit the ==������ ������������������ ������������ �������� API, ��������������������, ���������������� 
API wiki page==���������������� API �� Wiki
>Process Scheduler<==>����������������������<
This table shows actions that had been issued on the YaCy interface==������ �������������� ��������������������, ���������� ���������������� �������� ������������������ �� ���������� ������������������ ����������������
to change the configuration or to request crawl actions.== ������ ������������ �������������� ���� �������������������� ������������������������.
These recorded actions can be used to repeat specific actions and to send them==������ ���������������������� ���������������� ���������� �������� ������������������������, ���������� ������������������ ������������������ �� ���������������� ����
to a scheduler for a periodic execution.==�� ���������������������� ������ ���������������������������� ��������������������.
>Recorded Actions<==>������������������������������ ����������������<
"next page"=="������������������ ����������������"
"previous page"=="�������������������� ����������������"
"next page"=="������������������ ����������������"
"previous page"=="�������������������� ����������������"
 of \#\[of\]\#== ���� #[of]#
>Date==>��������
>Type==>������
>Comment==>����������������������
Call<br/>Count<==��������������������<br/>��������������<
Recording<==������������<
Last&nbsp;Exec==��������&nbsp;�������������������� ��������������
Next&nbsp;Exec==��������&nbsp;�������������������� ��������������
#>URL<==>URL-����������<
>Event Trigger<==>�������������� ��������������<
"clone"=="����������������������"
>Scheduler<==>����������������������<
>no event<==>������ ��������������<
>activate event<==>������������������������ ��������������<
>Scheduler<==>����������������������<
>no repetition<==>���� ������������������<
>activate scheduler<==>������������������������ ����������������������<
>off<==>������������������<
>run once<==>������������������ �������� ������<
>run regular<==>������������������ ������������������<
>after start-up<==>���������� ��������������<
at 00:00h==�� 00:00 ��.
at 01:00h==�� 01:00 ��.
at 02:00h==�� 02:00 ��.
at 03:00h==�� 03:00 ��.
at 04:00h==�� 04:00 ��.
at 05:00h==�� 05:00 ��.
at 06:00h==�� 06:00 ��.
at 07:00h==�� 07:00 ��.
at 08:00h==�� 08:00 ��.
at 09:00h==�� 09:00 ��.
at 10:00h==�� 10:00 ��.
at 11:00h==�� 11:00 ��.
at 12:00h==�� 12:00 ��.
at 13:00h==�� 13:00 ��.
at 14:00h==�� 14:00 ��.
at 15:00h==�� 15:00 ��.
at 16:00h==�� 16:00 ��.
at 17:00h==�� 17:00 ��.
at 18:00h==�� 18:00 ��.
at 19:00h==�� 19:00 ��.
at 20:00h==�� 20:00 ��.
at 21:00h==�� 21:00 ��.
at 22:00h==�� 22:00 ��.
at 23:00h==�� 23:00 ��.
"Execute Selected Actions"=="������������������ ����������������"
"Delete Selected Actions"=="�������������� ����������������"
"Delete all Actions which had been created before "=="�������������� ������ ���������������� ������������, ������"
day<==��������<
days<==��������<
week<==������������<
weeks<==������������<
month<==����������<
months<==��������������<
year<==������<
years<==��������<
>Result of API execution==>������������������ �������������������� API
#>Status<==>������������������>
#>URL<==>URL-����������<
>minutes<==>������������<
>hours<==>��������<
#>days<==>������<
Scheduled actions are executed after the next execution date has arrived within a time frame of \#\[tfminutes\]\# minutes.==���� �������������������� ������������������������������ ���������������� ���������������� #[tfminutes]# ����������.
#-----------------------------

#File: Table_RobotsTxt_p.html
#---------------------------
Table Viewer==���������������� ��������������
The information that is presented on this page can also be retrieved as XML==�������������������� ���������������������������� ���� �������� ����������������, ���������� ���������� �������� ���������������� �� XML-��������������.
Click the API icon to see the XML.==�������������� ���� ������������ API ������ ������������������ XML.
To see a list of all APIs, please visit the==������ ������������������ ������������ �������� API, ��������������������, ���������������� 
API wiki page==���������������� API �� Wiki
>robots.txt table<==>���������������� robots.txt<
#-----------------------------

### This Tables section is removed in current SVN Versions
#File: Tables_p.html
#---------------------------
Table Viewer==���������������� ������������
Table Administration==�������������������� ������������������ �������� ������������
Table Selection==��������������
Select Table:==�������������� ��������������:
#"Show Table"=="���������������� ��������������"
show max.==���������������� ����������������
>all<==>������<
entries==��������������
search rows for==���������� ������������
"Search"=="������������"
Table Editor: showing table==���������������� ��������������: ���������������� ��������������
#PK==������������������ ��������
"Edit Selected Row"=="���������������� ������������������ ������������"
"Add a new Row"=="���������������� ���������� ������������"
"Delete Selected Rows"=="�������������� ������������������ ������������"
"Delete Table"=="�������������� ��������������"
Row Editor==���������������� ����������
Primary Key==������������������ ��������
"Commit"=="������������������"
#-----------------------------

#File: YMarks.html
#-----------------------------
Login==����������
TreeView==������ ������������
Import Bookmarks==������������ ����������������
Bookmarks \(XBEL\)==���������������� (XBEL)
YaCy Bookmarks==���������������� YaCy
The information that is presented on this page can also be retrieved as XML==�������������������� ���������������������������� ���� �������� ����������������, ���������� ���������� �������� ���������������� �� �������� XML.
Click the API icon to see the XML.==�������������� ���� ������������ API ������ ������������������ XML.
To see a list of all APIs, please visit the <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">API wiki page</a>.==������ ������������������ ������������ �������� API, ��������������������, ���������������� <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">wiki-���������������� API</a>.
Bookmarks \(user: #[user]# size: #[size]#\)==���������������� (������������������������: #[user]# ������������: #[size]#)
Explorer==������������������
Tag Manager==���������������� ����������
Select \(multiple\) tags ...==�������������� (������������������) ����������
>Import<==>������������<
Export==��������������
All tag actions are applied to the sub-set of bookmarks defined by this query.==������ ���������������� ���������� ���������������������� �� �������������� ����������������, ������������������������ �������� ����������������.
>help<==>������������<
>Query<==>������������<
Query Type==������ ��������������
Tags \(comma seperated\)==�������� (���������� ��������������)
Tags \(regexp\)==�������� (�������������������� ������������������)
Folders \(comma seperated\)==���������� (���������� ��������������)
Folders \(regexp\)==���������� (�������������������� ������������������)
Title \(regexp\)==������������������ (�������������������� ������������������)
Description \(regexp\)==���������������� (�������������������� ������������������)
Enter tags to add \(<i>replace with</i>\)==�������������� �������� ������ �������������������� (�� ����������������������)
\(comma separated tags\)==(�������������� �������� ���������� ��������������)
"Replace"=="����������������"
Select tags to remove ...==���������������� �������� ������ ����������������
Bookmark Importer==���������������� ����������������
If you put in your bookmarks here, you can access them anywhere where you have access to your YaCy peer. Think of it as your 'personal cloud' for bookmarking.==�� ���������������� ���������� ������������������, ���� ������������ ���������� ������������ ���� ������������ ����������, ������ ������ ���������� ���������������� ������ ��������. �������� "������������������������ ������������" ����������������.
Surrogate XML==������������������ XML
YaCy White/Black List==����������/������������ ������������ YaCy
YaCy Crawl Starts \(admin\)==������������������ ��������������������
>Crawl Start<==>������������������ ��������������������<
Bookmark file==�������� ����������������
Folder settings==������������������ ����������
A folder structure is helpful to organize your bookmarks in a hierarchical way.==���������� ���������� ���������������� ���������� ������������������������ ������������������������.
Source folder==���������������� ����������
Target folder==���������� ��������������������
>Imported Bookmarks==>������������������������������
Automatic tagging==���������������������������� �������������������� ����������
Tags are words that are attached to documents as metadata. It is possible to read all the documents and find the attached tags automatically.==�������� �������� �������������������������� �� �������������������� ������ ��������������������, ������ ������������ ������������������ ������������ �������� �������������������� �� ���������� ���������������������������� �������� 
Off==������������������
Only for empty tags==������������ �� �������������� ������������
Overwriting existing tags==������������������������ ������������������������ ��������
Merging with existing tags==�������������������� �� �������������������������� ������������
Automatic Indexing==���������������������������� ��������������������
While doing the bookmark import, YaCy can push all URLs to the indexing process==�������� ������������������������ ������������ ����������������, YaCy ���������� ������������ ���������������������������� �������� ������������
No indexing==������ ��������������������
>Index every bookmark entry<==>������������ ������������ ����������������<
Index every bookmark entry plus all directly linked pages==������������ �������� ���������������� ������������ ���� ���������� ������������������������ ��������������������
Index all domains from all bookmarks completely==������������ �������� �������������� ���� �������� ���������������� ������������������
include all media \(image/movie/document\) links==�������������� ������ ������������ ���� ����������-���������� (����������������������/��������/������������������)
Add & Edit Bookmark==���������������� �� �������������������������� ����������������
Public:==������������������
yes==����
no==������
URL:==URL
Title:==������������������
Description:==����������������
Folder \(/folder/subfolder\):==���������� (����������/����������������)
Tags \(comma separated\):==�������� (���������� ��������������)
Craw Start==������������ ����������������������������
>Bookmark<==>����������������<
Bookmarks==����������������
Restrict to start domain==���������������������� �������������������� ������������
Restrict to sub-path of given url==���������������������� ���������� ������������������ ������������
Crawling Depth==�������������� ����������������������������
bookmark only \(0\)==������������ ����������������
shallow crawl \(4\)==�������������������� ����������������������������
deep crawl \(8\)==���������������� ����������������������������
deeper crawl \(16\)==���������� ���������������� ����������������������������
indefinite \(99\)==����������������������������
Limitations==����������������������
not more than==���� ���������� ������
documents==��������������������
Dynamic URLs==������������������������ ������������
allow <a href="http://en.wikipedia.org/wiki/Query_string" target="_blank">==������������������ <a href="http://en.wikipedia.org/wiki/Query_string" target="_blank">
query-strings</a> \(urls with a '?' in the path\)==������������-��������������</a>(������������ �� '?' �� ��������)
Scheduler==����������������������
run this crawl once==������������������ �������� �������������������� ������������ �������� ������
scheduled, look every==��������������������������, ������������������ ������������
minutes==����������
hours==����������
days==��������
for new documents automatically.==������ ���������� �������������������� ��������������������������.
Filter:==������������
No filter==������ ��������������
multiple==������������������
Sorry, the function you have requested is not yet available!==����������������, ���������������������� �������� �������������� ���� ����������������!
"Import"=="������������"
#---------------------------




#File: Table_YMark_p.html
#---------------------------
Table Viewer==���������������� ������������
YMark Table Administration==YMark Tabellen Administration
Table Editor: showing table==���������������� ��������������: ���������������� ��������������
"Edit Selected Row"=="���������������� ������������������ ������������"
"Add a new Row"=="���������������� ���������� ������������"
"Delete Selected Rows"=="�������������� ������������������ ������������"
"Delete Table"=="�������������� ��������������"
"Rebuild Index"=="���������������������� ������������"
Primary Key==������������������ ��������
>Row Editor<==>���������������� ����������<
"Commit"=="������������������"
Table Selection==���������� ��������������
Select Table:==�������������� ��������������:
show max. entries==���������������� ���������������� ����������������
>all<==>������<
Display columns:==���������������� ��������������:
"load"=="����������������"
Search/Filter Table==����������/������������ ��������������
search rows for==���������� ������������
"Search"=="������������"
#>Tags<==>��������<
>select a tag<==>�������������� ������<
>Folders<==>����������<
>select a folder<==>�������������� ����������<
>Import Bookmarks<==>�������������������������� ����������������<
#Importer:==����������������:
#>XBEL Importer<==>XBEL ����������������<
#>Netscape HTML Importer<==>Netscape HTML ����������������<
"import"=="��������������������������"
#-----------------------------

#File: terminal_p.html
#---------------------------
YaCy System Terminal Monitor==������������������ �������������� YaCy
YaCy Peer Live Monitoring Terminal==���������������� ���������������������� ��������
Search Form==���������� ������������
Crawl Start==������������ ����������������������������
Status Page==���������������� ������������������
Confirm Shutdown==���������������������� ��������������������
>&lt;Shutdown==>&lt;������������������
Event Terminal==���������������� ��������������
Image Terminal==���������������� ����������������������
Domain Monitor==�������������� ������������
"Loading Processing software..."=="�������������� ���������������� ������������������..."
This browser does not have a Java Plug-in.==�������� �������������� ���� ������������������������ ������������ Java.
Get the latest Java Plug-in here.==������������������ Java-������������ ���������������� ����������.
Resource Monitor==�������������� ����������������
Network Monitor==�������������� ��������
#-----------------------------

#File: Threaddump_p.html
#---------------------------
YaCy Debugging: Thread Dump==O������������ YaCy: �������� ������������
Threaddump<==�������� ������������<
"Single Threaddump"=="�������������� �������� ������������"
"Multiple Dump Statistic"=="������������-�������� ������������"
#"create Threaddump"=="�������������� �������� ������������"
#-----------------------------

#File: User.html
#---------------------------
User Page==���������������� ������������������������
You are not logged in.<br />==���� ���� ��������������������.<br />  
Username:==������ ������������������������:
Password: <input==������������: <input
"login"=="����������"
You are currently logged in as \#\[username\]\#.==���� ���������� ������ #[username]#.
You have used==���� ������������ ������������������������
minutes of your onlinetime limit of==Minuten Ihres Online-Zeitlimits von
minutes per day.==Minuten pro Tag verbraucht.
old Password==������������ ������������
new Password<==���������� ������������<
new Password\(repetition\)==���������� ������������ ����������������
"Change"=="����������������"
You are currently logged in as admin.==���� ���������� ������ ��������������������������.
value="logout"==value="����������"
\(after logout you will be prompted for your password again. simply click "cancel"\)==(���������� ������������ �������������������� ������������ ������������ ����������������.)
Password was changed.==������������ ������ ��������������.
Old Password is wrong.==������������ ������������ ������������������������.
New Password and its repetition do not match.==���������� ������������ ���� ������������������ �� ����������������.
New Password is empty.==���������� ������������ ������������.
#-----------------------------

#File: ViewFile.html
#---------------------------
See the page info about the url.==���������������� �������������������� �� ������������.
YaCy \'\#\[clientname\]\#\': View URL Content==YaCy '#[clientname]#': ���������������� ���������������������� URL-������������
View URL Content==���������������� ���������������� ���� URL-������������
>Get URL Viewer<==>���������������� URL-������������<
"Show Metadata"=="���������������� ��������������������"
"Browse Host"=="���������������� ����������"
>URL Metadata<==>��������������������<
URL==URL
Search in Document:==���������� �� ������������������:
"Show Snippet"=="���������������� ����������������"
Hash==������
(click this for full metadata)==���������������� ������ ���������������������� ������������ ��������������������
In Metadata:==�� ��������������������:
In Cache:==�� ��������:
Word Count==���������� ��������
Description==����������������
Size==������������
MimeType:==������ ����������:
Collections==������������������
View as==���������������� ������
#Original==Original
Plain Text==�������������� ����������
Parsed Text==���������������������� ����������
Parsed Sentences==���������������������� ����������������������
Parsed Tokens/Words==���������������������� ��������������/����������
Link List==������������ ������������
Citation Report==���������� ����������������������
>CitationReport<==>���������� ����������������������<
"Show"=="����������������"
Unable to find URL Entry in DB==�������������������� ���������� ������������ ������������ �� �������� ������������.
Invalid URL==������������������������ URL-����������
Unable to download resource content.==�������������������� ������������������ �������������������� ��������������.
Unable to parse resource content.==���� �������������� ������������������ �������������������� ��������������.
Unsupported protocol.==�������������������������������� ����������������.
>Original Content from Web<==>������������������������ �������������������� ���� ������<
Parsed Content==������������ ����������������
>Original from Web<==>���������������� ���� ������<
>Original from Cache<==>���������������� ���� ��������<
>Parsed Tokens<==>���������������������� ��������������<
#-----------------------------

#File: ViewLog_p.html
#---------------------------
Server Log==������ ��������������
Lines==����������
reversed order==�� ���������������� ��������������
"refresh"=="����������������"
#-----------------------------

#File: ViewProfile.html
#---------------------------
Local Peer Profile:==�������������� �������������������� ��������:
Remote Peer Profile==�������������� �������������������� ��������
Wrong access of this page==���������������� ������������ ���� ������ ����������������
The requested peer is unknown or a potential peer.==���������������������� �������� ���������������������� ������ ��������������������������.
The profile can't be fetched.==�������� �������������� ���� ���������� �������� ������������.
The peer==��������
is not online.==���� ���� ����������.
This is the Profile of==��������������
>Name==>������
Nick Name==����������������
Homepage==���������������� ����������������
eMail==���������������������� ����������
#ICQ==ICQ
#Jabber==Jabber
#Yahoo!==Yahoo!
#MSN==MSN
#Skype==Skype
Comment==����������������������
View this profile as==���������������� ���������� �������������� ������ 
> or==> ������
#vCard==vCard
You can edit your profile <a href="ConfigProfile_p.html">here</a>==���� ������������ ���������������� �������� �������������� <a href="ConfigProfile_p.html">���� �������� ������������</a>
#-----------------------------

#File: Vocabulary_p.html
#---------------------------
YaCy '#\[clientname\]#': Federated Index==YaCy '#[clientname]#': �������������������� ����������������
The information that is presented on this page can also be retrieved as XML==�������������������� ���������������������������� ���� �������� ����������������, ���������� ���������� �������� ���������������� �� �������� XML.
Click the API icon to see the RDF Ontology definition for this vocabulary.==�������������� ���� ������������ API ������ ������������������ ���������������������� ������������������ RDF ������ ���������� ��������������.
To see a list of all APIs, please visit the <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">API wiki page</a>.==������ ������������������ ������������ �������� API, ��������������������, ���������������� <a href="http://www.yacy-websuche.de/wiki/index.php/Dev:API" target="_blank">���������������� API Wiki</a>.
Vocabulary Administration==�������������������� ����������������
Vocabularies can be used to produce a search navigation. A vocabulary must be created before content is indexed.==�������������� ���������� ���������������������������� ������ �������������������� ������������������ ���� ������������. �������������� ������������ �������� ������������ ���� �������������������� ���������������������� ����������.
The vocabulary is used to annotate the indexed content with a reference to the object that is denoted by the term of the vocabulary.==�������������� ������������������������ ������ ������������������������������ �������������������������������������� ���������������������� �� �������������� ���� ������������, ���������������� ������������������ ���������������� ���� ��������������.
The object can be denoted by a url stub that, combined with the term, becomes the url for the object.==������������ ���������� ������������������������ ���������������������� ��������������, �� ������������������ �� �������������� ���� ������������.
Vocabulary Selection==���������� ��������������
Vocabulary Name==���������������� ��������������
"View"=="����������������"
Vocabulary Production==���������������� ��������������
It is possible to produce a vocabulary out of the existing search index. This is done using a given \'objectspace\' which you can enter as a URL Stub.==���������������� ���������������� �������������� ���� �������������������������� �������������� ������������. ������ ���������������� ���������� �������������������������� ������������������ '��������������', �������������� ���������� �������� ������������ ������ ���������������������� ������������.
This stub is used to find all matching URLs. If the remaining path from the matching URLs then denotes a single file, the file name is used as vocabulary term.==������ ������������������������ ������ ������������ �������� ���������������������� ������������. �������� �������������������� �������� ���� ���������������������� ������������ �������������������� �������� ��������, ���� ������ ���������� ������������������������ �� ���������������� ���������������� ��������������.
This works best with wikis. Try to use a wiki url as objectspace path.==������ ���������� ���������������� �� Wiki . �������������������� ������������������������ wiki-������������ �� ���������������� ��������������.
#Vocabulary Name==���������������� ��������������
Objectspace==������������
Discover Terms:==������������������ ����������������:
no auto-discovery \(empty vocabulary\)==������������ ���������������� (�������������� ��������)
from file name==���� ���������������� ����������
from page title&nbsp;==���� ������������������ ����������������&nbsp;
from page title \(splitted\)==���� ������������������ ���������������� (����������������������)
from page author==���� ���������������� ������������
"Create"=="��������������"
Vocabulary Editor==���������������� ��������������
This produces the following triples in the==Das produziert die folgenden Tripel im
#>triplestore<==>triplestore<
if a term or synonym matches in a document:==�������� ���������������� ������ �������������� ������������������ �� ������������������
more Triples for linking into objectspace==������������ �������� ������������ ���� ������������
>Modify<==>����������������<
>Delete<==>��������������<
>Literal<==>������������������<
>Synonyms<==>����������������<
>Object Link<==>������������ ��������������<
>add<==>����������������<
clear table \(remove all terms\)==���������������� �������������� (�������������� ������ ����������������)
delete vocabulary<==�������������� ��������������<
"Submit"=="������������������"
#-----------------------------

#File: Crawler_p.html
#---------------------------
Click on this API button to see an XML with information about the crawler status==�������������� ������ ������������������ XML-���������� �� ���������������������� �� ������������������ ����������������������.
>Crawler<==>��������������������<
>Queues<==>�������������� ����������������������<
>Queue<==>��������������<
Pause/==����������/
Resume==��������
Crawler PPM==���������������� ����������������������
Error with profile management. Please stop YaCy, delete the file DATA/PLASMADB/crawlProfiles0.db==������������ ��������������. ��������������������, �������������������� YaCy, �������������� �������� DATA/PLASMADB/crawlProfiles0.db
and restart.==�� �������������������������� ������������������.
Error:==������������:
Application not yet initialized. Sorry. Please wait some seconds and repeat==�������������������� ���� ����������������. ������������������ ������������������ ������������ �� ������������������.
ERROR: Crawl filter==������������: ������������ ����������������������������
does not match with==���� ������������������ ��
crawl root==������������ ����������������������������
Please try again with different==�������������������� ������ ������ �� ������������
filter. ::==����������������. ::
Crawling of==����������������������������
failed. Reason:==����������������. ��������������:
Error with URL input==������������ �� ������������������ URL
Error with file input==������������ �� ������������������ ������������
started.==����������������.
Please wait some seconds,==��������������������, ������������������ ������������������ ������������,
it may take some seconds until the first result appears there.==���� ������������������ �������������� ��������������������.
If you crawl any un-wanted pages,==�������� ���� �������������������������������� �������������������������� ����������������,
you can delete them <a href="IndexCreateQueues_p.html?stack=LOCAL">here</a>.<br />== ���� ���� ������������ �������������� ���� <a href="http://IndexCreateQueues_p.html?stack=LOCAL">����������</a>.<br>
>Size==>������������
>Progress<==>������ ������������<
#Max==����������������������
"set"=="������������������"
#Indexing</td>==����������������������������</td>
Loader==����������������
>Index Size<==>������������ ��������������<
Seg-<br/>ments==����������������
>Documents<==>������������������<
>solr search api<==>API �������� Solr<
>Webgraph Edges<==>������-��������������<
Citations<br/>\(reverse link index\)==������������ (������������ ������������������ ��������������)
RWIs<br/>\(P2P Chunks\)==RWIs<br/>(P2P ����������)
Local Crawler==������������������
Limit Crawler==������������������������
Remote Crawler==������������������
No-Load Crawler==����������������
Speed / PPM<br/>\(Pages Per Minute\)==���������������� (���������������� �� ������������)
Database==�������� ������������
Entries==����������������
Segments==����������������
Indicator==��������������������
Level==����������������
Postprocessing Progress==��������������������������
Traffic \(Crawler\)==������������ ����������������������
>Load<==>���������������� ��������������������<
pending:==��������������:
idle==����������������
>Running Crawls==>���������������������� ��������������������
Name==���������������� ����������
Status==������������������
Running==����������������������
Terminate All==���������������� ������
Confirm Termination of All Crawls==���������������������� �������������������� �������� ������������������������
"Terminate"=="����������������"
Crawled Pages==������������������������������������ ����������������
Title==������������������
#-----------------------------

#File: WatchWebStructure_p.html
#---------------------------
Web Structure<==������-������������������<
The data that is visualized here can also be retrieved in a XML file, which lists the reference relation between the domains.==������ ������������, ���������� ���������� �������� ���������������� �� �������� XML-���������� �� �������������������������� ���������������� ���������� ����������������.
With a GET-property 'about' you get only reference relations about the host that you give in the argument field for 'about'.==������������ ���������������� "GET" 'about' ���� ���������������� ������������ ������������������������ ������������ �� ����������, �������������� ������������ �� �������� 'about'.
With a GET-property 'latest' you get a list of references that had been computed during the current run-time of YaCy, and with each next call only an update to the next list of references.==������������ ���������������� GET" 'latest'  ���� ���������������� ������������ ������������ ���������������������� ���� ���������� �������������� ������������ YaCy, �������������������������� ������ ������������ ������������������ ������������.
Click the API icon to see the XML file.==�������������� ���� ������������ API ������ ������������������ XML-����������.
To see a list of all APIs, please visit the==������ ������������������ ������������ �������� API, ��������������������, ����������������
API wiki page==���������������� API Wiki
Web Structure==������-������������������
>Host List<==>������������ ������������<
\#\[count\]\# outlinks==#[count]# �������������� ������������
host<==��������<
depth<==��������������<
nodes<==��������<
time<==����������<
size<==������������<
>Background<==>������<
>Text<==>����������<
>Line<==>����������<
>Pivot Dot<==>������������������ ����������<
>Other Dot<==>������������ ����������<
>Dot-end<==>��������������<
>Color <==>�������� <
"change"=="����������������"
"WebStructurePicture"=="���������������������� ������-������������������"
#-----------------------------

#File: Wiki.html
#---------------------------
YaCyWiki page:==Wiki-���������������� YaCy:
last edited by==������������������ ������������������
change date==�������� ������������������
Edit<==����������������<
only granted to admin==������������ ���������������������� ������������������������������
Grant Write Access to==������������������ ���������� ������������ 
# !!! Do not translate the input buttons because that breaks the function to switch rights !!!
#"all"=="��������"
#"admin"=="����������������������������"
Start Page==������������������ ����������������
Index==������������
Versions==������������
Author:==����������:
#Text:==����������:
You can use==���� ������������ ������������������������
Wiki Code</a> here.==Wiki-������</a> ����������.
"edit"=="����������������"
"Submit"=="������������������"
"Preview"=="������������������������"
"Discard"=="����������������"
>Preview==>������������������������
No changes have been submitted so far!==������������������ ���� �������� ����������������������!
Subject==��������
Change Date==�������� ������������������
Last Author==������������������ ����������
IO Error reading wiki database:==������������ ����������-������������ ������ ������������ �������� ������������ Wiki:
Select versions of page==���������������� ������������ ����������������
Compare version from==���������������� ������������ ����
"Show"=="����������������"
with version from==�� �������������� ����
"current"=="��������������"
"Compare"=="����������������"
Return to==������������������ ��
Changes will be published as announcement on YaCyNews==������������������ ���������� ������������������������ �� �������� ������������������ YaCy.
#-----------------------------

#File: WikiHelp.html
#---------------------------
Wiki Help==Wiki Hilfe
Wiki-Code==Wiki-Befehle
This table contains a short description of the tags that can be used in the Wiki and several other servlets==Diese Tabelle enth��lt eine kurze Beschreibung der Tags, die in diesem Wiki und an anderen Stellen
of YaCy. For a more detailed description visit the==in YaCy benutzt werden k��nnen. F��r eine detailliertere Beschreibung besuchen Sie bitte das
#YaCy Wiki==YaCy Wiki
Description==Beschreibung
\=headline===��berschrift
These tags create headlines. If a page has three or more headlines, a table of content will be created automatically.==Diese Tags erzeugen ��berschriften. Wenn die Seite drei oder mehr ��berschriften enth��lt, wird automatisch ein Inhaltsverzeichnis erstellt.
Headlines of level 1 will be ignored in the table of content.==��berschriften im ersten Level werden beim Erstellen des Inhaltsverzeichnisses ignoriert.
#text==Text
These tags create stressed texts. The first pair emphasizes the text \(most browsers will display it in italics\),==Diese Tags erzeugen hervorgehobenen Text. Das erste Paar betont den Text (die meisten Browser zeigen die Texte kursiv),
the second one emphazises it more strongly \(i.e. bold\) and the last tags create a combination of both.==das Zweite betont den Text st��rker (z.B. fett) und der letzte Tag erzeugt eine Mischung aus beidem.
Text will be displayed <span class=\"strike\">stricken through</span>.==Text wird <span class="strike">durchgestrichen</span> angezeigt.
Lines will be indented. This tag is supposed to mark citations, but may as well be used for styling purposes.==Der Text erscheint einger��ckt. Dieser Tag eignet sich, um Zitate zu markieren, wird aber auch zum Designen benutzt.
point==Punkt
These tags create a numbered list.==Diese Tags erstellen eine nummerierte Liste.
something<==etwas<
another thing==was anderes
and yet another==und wieder was anderes
something else==irgendwas
These tags create an unnumbered list.==Diese Tags erstellen eine unnummerierte Liste.
word==Wort
\:definition==:Definition
These tags create a definition list.==Diese Tags erstellen eine definierte Liste.
This tag creates a horizontal line.==Dieser Tag erzeugt eine horizontale Linie.
pagename==Seitenname
description\]\]==Beschreibung]]
This tag creates links to other pages of the wiki.==Dieser Tag erzeugt einen Link zu einer anderen Seite im Wiki.
This tag displays an image, it can be aligned left, right or center.==Dieser Tag f��gt ein Bild ein, es kann links (left), rechts (right) oder mittig (center) ausgerichtet werden.
This tag displays a Youtube or Vimeo video with the id specified and fixed width 425 pixels and height 350 pixels.==Dieser Tag f��gt ein Youtube oder Vimeo Video mit der angegeben id und einer fixen H��he von 425 Pixeln und einer fixen Breite von 350 Pixeln ein.
i.e. use==z.B. wird mit
to embed this video:==dieses Video eingebunden:
These tags create a table, whereas the first marks the beginning of the table, the second starts==Diese Tags erstellen eine Tabelle, wobei der erste den Anfang der Tabelle markiert, der zweite beginnt 
a new line, the third and fourth each create a new cell in the line. The last displayed tag==eine neue Zeile, der dritte und vierte erzeugen eine neue Zelle in der Zeile. Der zuletzt dargestellte Tag
closes the table.==schlie��t die Tabelle.
#The escape tags will cause all tags in the text between the starting and the closing tag to not be treated as wiki-code.==Durch diesen Tag wird der Text, der zwischen den Klammern steht, nicht interpretiert und unformatiert als normaler Text ausgegeben.
A text between these tags will keep all the spaces and linebreaks in it. Great for ASCII-art and program code.==Ein Text zwischen diesen Tags wird alle Leerzeichen und Zeilenumbr��che beinhalten. Gut geeignet f��r ASCII-Kunst und Programm Code.
If a line starts with a space, it will be displayed in a non-proportional font.==Wenn eine Zeile mit einem Leerzeichen anf��ngt, wird diese als nicht-proportionale Schriftart dargestellt.
url description==url Beschreibung
This tag creates links to external websites.==Dieser Tag erstellt einen Link zu einer externen Internetseite.
alt text==alt Beschreibung
#-----------------------------

#File: yacyinteractive.html
#---------------------------
YaCy Interactive Search==�������������������������� ����������
This search result can also be retrieved as RSS/<a href=\"http://www.opensearch.org\" target=\"_blank\">opensearch</a> output.==������������������ ������������ ���������� �������� ������������������ �� RSS-����������/<a href="http://www.opensearch.org">OpenSearch</a>.
The query format is similar to==������������ �������������� ��������������������
SRU==SRU
Click the API icon to see an example call to the search rss API.==�������������� ���� ������������ API ������ ������������������ �������������� ������������ API ������������ RSS-����������.
To see a list of all APIs, please visit the==������������ �������� API, ���������������� ���� ����������������
API wiki page==Wiki API
loading from local index...==���������������������� ���� �������������������� ��������������...
parsing result...==������������ ��������������������...
e="Search"==e="����������"
"Search..."=="�������������� ������������������ ������������..."
#-----------------------------

#File: yacysearch.html
#---------------------------
Search Page==���������������� ������������
This search result can also be retrieved as RSS/<a href=\"http://www.opensearch.org\" target=\"_blank\">opensearch</a> output.==������������������ ������������ ���������� �������� ������������������ �� RSS-����������/<a href="http://www.opensearch.org">OpenSearch</a>.
The query format is similar to==������������ �������������� ��������������������
SRU==SRU
Click the API icon to see an example call to the search rss API.==�������������� ������ ������������������ �������������� ������������ API ������������ RSS-����������.
To see a list of all APIs, please visit the==������������ �������� API, ���������������� ����
API wiki page==Wiki-���������������� API
"search"=="����������"
'Search'=='����������'
"search again"=="������������ ������"
#Text==����������
Images==����������������������
#Audio==����������
Video==����������
Applications==��������������������
more options==���������������������� ����������...
Illegal URL mask:==������������������������ ������������ URL:
\(not a valid regular expression\), mask ignored.==(������������������������ �������������������� ������������������), ������������ ������������������������.
Illegal prefer mask:==������������������������ �������������������������������� ������������:
Did you mean:==���������������� ���� ���������� ����������:
The following words are stop-words and had been excluded from the search:==������������������ ���������� ���������������� ��������-�������������� �� �������� ������������������ ���� ������������:
No Results.==������ ����������������������.
length of search words must be at least 2 characters==���������� ���������������� ���������� ������������ �������� ���� ���������� 2 ����������������
Searching the web with this peer is disabled for unauthorized users. Please==���������� �� �������������� ���������� �������� �������������������� ������ �������������������������������� ��������������������������. ��������������������, 
>log in<==>��������������<
as administrator to use the search function==������ ���������� �������������� ��������������, ������ �������������������������� ������������.
Location -- click on map to enlarge==���������������������������� -- �������������� ���� ���������� ������ ��������������������
Map \(c\) by <==���������� (��) <
#>OpenStreetMap<==>OpenStreetMap<
and contributors, CC-BY-SA==�� ������������������, ���������������� CC-BY-SA
>Media<==>����������<
#>URL<==>URL-����������<
> of==> ���� 
g> local,==g> ����������������,
g> remote\),==g> ����������������),
> from==> ����
remote YaCy peers.==������������������ ���������� YaCy.
>search<==>����������<
#-----------------------------

#File: yacysearchitem.html
#---------------------------
"bookmark"=="���������������� �� ����������������"
"recommend"=="��������������������������"
"delete"=="��������������"
Pictures==����������������������
#-----------------------------

#File: yacysearchtrailer.html
#---------------------------
Show search results for "\#\[query\]\#" on map==���������������� ������������������ ������������ "#[query]#" ���� ����������
>Provider==>����������
>Name Space==>������
>Author==>����������
>Protocol==>����������������
>Filetype==>������ ����������
>Language==>��������
>Please support YaCy!==>��������������������, �������������������� YaCy!
&nbsp;&nbsp;&nbsp;Peer-to-Peer&nbsp;&nbsp;&nbsp;&nbsp;==&nbsp;&nbsp;&nbsp;P2P&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;Stealth&nbsp;Mode&nbsp;&nbsp;&nbsp;==&nbsp;&nbsp;&nbsp;&nbsp;����������&nbsp;����������&nbsp;&nbsp;&nbsp;
"Privacy"=="��������������"
Context Ranking==������������ ���� ����������������
Sort by Date==������������ ���� ��������
Documents==������������������
Images==����������������������
"Your search is done using peers in the YaCy P2P network."=="������ ���������� ���������������������� �� ���������������������������� ���������� P2P-�������� YaCy."
"You can switch to 'Stealth Mode' which will switch off P2P, giving you full privacy. Expect less results then, because then only your own search index is used."=="���� ������������ �������������� �� ���������� ����������, �������������� ���������������� �������������������������� P2P, ���� ������������������ �������� ������������ ����������������������. �� �������� ������������ ���������������������� ������������ ���������� ������������, ������������ ������ ���������� ���������� ���������������������������� ������������ �� ������������������ ��������������."
"Your search is done using only your own peer, locally."=="���������� ���������������������� ������������ �� ���������� ������������������ ��������������."
"You can switch to 'Peer-to-Peer Mode' which will cause that your search is done using the other peers in the YaCy network."=="���� ������������ �������������� �� ���������� P2P, �������������� ���������������� ���������������������� ���������� �� ����������������������������  ������������ ���������� �������� YaCy."
#-----------------------------

### Subdirectory api ###
#File: api/table_p.html
#---------------------------
Table Viewer==���������������� ������������
#>PK<==>������������������ ��������<
"Edit Table"=="�������������������������� ��������������"
#-----------------------------

#File: api/yacydoc.html
#---------------------------
>Author<==>����������<
>Description<==>����������������<
>Subject<==>��������<
#>Publisher<==>����������������<
#>Contributor<==>Beitr��ger<
>Date<==>��������<
>Type<==>������<
>Identifier<==>��������������������������<
>Language<==>��������<
>Load Date<==>�������� ����������������<
>Referrer Identifier<==>���������������������� ��������������������������<
#>Referrer URL<==>������������ URL<
>Document size<==>������������ ������������������<
>Number of Words<==>�������������������� ��������<
#-----------------------------

#File: env/templates/metas.template
#---------------------------
English, Englisch==��������������, ��������������

#-----------------------------

### Subdirectory env/templates ###
#File: env/templates/header.template
#---------------------------
&nbsp;Administration==&nbsp;��������������������
Toggle navigation==������������������������ ��������������������
Administration &raquo;==�������������������� &raquo;
Re-Start<==��������������������<
Shutdown<==��������������������<
>Administration Tutorials<==>��������������������<
Download YaCy==���������������� ���������������� YaCy
Community \(Web Forums\)==����������
Project Wiki==Wiki-�������� ��������������
Search Interface==������������������ ������������
About This Page==������ ��������������
YaCy Administration==�������������������� YaCy
YaCy - Distributed Search Engine==YaCy - �������������� ������������������������������ ������������
### SEARCH DESIGN ###
Search&nbsp;Design==�������������������� ������������
Search Integration==�������������������� ������������
Portal Configuration==������������������ �������������������� ������������
Portal Design==������������������ ���������������� ��������
Ranking and Heuristics==������������������������ �� ������������������
### INDEX CONTROL ###
Index&nbsp;Production==����������������������������
Crawler / Harvester==���������������������������� / ������������ ��������
Crawler Monitor==�������������� ����������������������������
Index Administration==�������������������� ����������������
Filter &amp; Blacklists==������������ �� ������������ ������������
Content Semantic==�������������������������� ��������������
Target Analysis==������������ ��������
Process Scheduler==����������������������
### MONITORING ###
Monitoring==��������������������
YaCy Network==�������� YaCy
Index Browser==���������������� ��������������
Network Access==�������������� �������������� �� ��������������
Computation==������ ��������������
>Terminal==>����������������
>Bookmarks==>����������������
### PEER CONTROL ###
Peer&nbsp;Control==�������������������� ����������
Admin Console==�������������� ����������������������������
Confirm Re-Start==���������������������� ��������������������
Re-Start</a>==��������������������������</a>
Confirm Shutdown==���������������������� ��������������������
>Shutdown==>������������������
Project Wiki<==Wiki����������� ��������������<
Git Repository==Git-����������������������
Bugtracker==������������������
Peer Statistics==�������������������� YaCy
external==
>Search...<==>����������...<
"Search..."=="����������..."
### FIRST STEPS ###
"You just started a YaCy peer!"=="���� ������������������ �������� YaCy!"
"As a first-time-user you see only basic functions. Set a use case or name your peer to see more options. Start a first web crawl to see all monitoring options."=="������ �������������������� ������������������������, ���� ������������ ������������ ���������������� ��������������. ���������������� �������������� �������������������������� ������ �������������������� ������ ������������ �������� ������ ������������������ ������������ ����������. ������������������ ������-�������������������� ������ ������������������ �������������� ����������������������."
"You did not yet start a web crawl!"=="���� ���� ������������������ ������-��������������������!"
"You do not see all monitoring options here, because some belong to crawl result monitoring. Start a web crawl to see that!"=="���� ���� ������������ �������� �������������� ���������������������� ����������, ������������ ������ ������ ���������������������� ����������������������������. ������������������ ������-��������������������!"
First Steps==������������ ��������
Use Case &amp; Account==�������������� ������������ �� ���������������� ��������������������������
Load Web Pages, Crawler==���������������������������� ����������
RAM/Disk Usage &amp; Updates==�������������������������� ������������ �� �������������������� ��������������
System Status==�������������� ������������������������������������
Peer-to-Peer Network==�������� YaCy
Advanced Crawler==���������������������� ��������������������
Content Importer==������������ ����������������
System Administration==������������������ ��������������
Configuration==������������������������
Production==����������������������������
>Administration<==>�������������������� ����������<
Search Portal Integration==�������������������� ������������
#-----------------------------

#File: env/templates/simpleheader.template
#---------------------------
Toggle navigation==������������������������ ��������������������
Search Interfaces==�������������������� ������������
Administration &raquo;==�������������������� &raquo;
>Web Search<==>�������������������<
>File Search<==>���������� ������������<
>Compare Search<==>���������������� ����������<
>Index Browser<==>���������������� ������������<
>URL Viewer<==>���������������� ������������<
Example Calls to the Search API:==�������������� ���������������� �� API ������������:
Solr Default Core==������������������ �������� Solr
Solr Webgraph Core==������������������ �������������� Solr
Google Appliance API==������������������ API Google
>Administration Tutorials<==>��������������������<
Download YaCy==���������������� ���������������� YaCy
Community \(Web Forums\)==����������
Project Wiki==Wiki-�������� ��������������
Search Interface==������������������ ������������
About This Page==������ ��������������
external==
Bugtracker==������������������
Git Repository==Git-����������������������
Peer Statistics==�������������������� YaCy
#-----------------------------

#File: env/templates/submenuAccessTracker.template
#---------------------------
Access Tracker==�������������� �������������� �� ��������������
Server Access==�������������� �� ��������������
Access Grid==���������� ��������������������
Incoming Requests Overview==���������� ���������������� ����������������
Incoming Requests Details==���������������������� ���������������� ����������������
All Connections<==������ ��������������������<
Local Search<==������������������ ����������<
Log==������
Host Tracker==��������-������������
Remote Search<==������������������ ����������<
Cookie Menu==�������������� ��������
Incoming&nbsp;Cookies==���������������� ��������
Outgoing&nbsp;Cookies==������������������ ��������
#-----------------------------

#File: env/templates/submenuIndexImport.template
#-----------------------------
Content Importer==������������ ����������������
External Datasets==������������ ���� �������������� ��������������������
Database Reader==������������������������ ������ ������������
RSS Feed Importer==������������ RSS-��������
OAI-PMH Importer==������������ ������������ OAI-PMH
Database Reader for phpBB3 Forums==������������������������ ������ ������������ phpBB3�����������������
Dump Reader for MediaWiki dumps==������������������������ ������������ MediaWiki
#-----------------------------

#File: env/templates/submenuSearchIntegration.template
#---------------------------
Search Integration into External Sites==�������������������� ������������ ���� �������������� ����������
Live Search Anywhere=="����������" ���������� ����������
Search Box Anywhere==���������� ����������
#-----------------------------

#File: env/templates/submenuMaintenance.template
#---------------------------
RAM/Disk Usage &amp; Updates==�������������������������� ������������ �� �������������������� ��������������
>Performance<==>������������������������������������<
Web Cache==������-������
Download System Update==�������������������� ��������������
#---------------------------


#File: env/templates/submenuBlacklist.template
#---------------------------
Filter &amp; Blacklists==������������ �� ������������ ������������
Blacklist Administration==�������������������� ������������ ��������������
Blacklist Cleaner==�������������� �������������� ������������
Blacklist Test==�������� �������������� ������������
Import/Export==������������/��������������
Content Control==�������������������� ������������������
#-----------------------------

#File: env/templates/submenuComputation.template
#---------------------------
>Application Status<==>�������������� ������������������������������������<
>Status<==>������������������<
System==��������������
Thread Dump==�������� ������������
## Processes Submenu
>Processes<==>����������������<
>Server Log<==>������ ��������������<
>Concurrent Indexing<==>������������������������ ����������������������������<
>Memory Usage<==>�������������������������� ������������<
>Search Sequence<==>�������������������������������� ����������<
## Messages Submenu
>Messages<==>������������������<
>Overview<==>����������<
>Incoming&nbsp;News<==>����������������&nbsp;������������������<
>Processed&nbsp;News<==>������������������������&nbsp;������������������<
>Outgoing&nbsp;News<==>������������������&nbsp;������������������<
>Published&nbsp;News<==>����������������������������&nbsp;������������������<
## Community Data Submenu
>Community Data<==>�������������� ��������������������<
>Surftips<==>������������<
>Local Peer Wiki<==>Wiki �������������������� ��������<
#-----------------------------

#File: env/templates/submenuCrawler.template
#-----------------------------
Load Web Pages==���������������������������� ����������
Site Crawling==���������������������������� ����������
Parser Configuration==������������������������ ��������������
#-----------------------------


#File: env/templates/submenuConfig.template
#---------------------------
System Administration==������������������ ��������������
>Status==>������������������
Basic Configuration==���������������� ������������������
>Accounts==>�������������� ������������
Network Configuration==������������������ ��������
Advanced Settings==������������������ ��������������
Local robots.txt==������������������ robots.txt
Advanced Properties==���������������������� ������������������
>Thread Dump<==>�������� ������������<
Viewer and administration for database tables==���������������� �� �������������������� ������������������ �������� ������������
Performance Settings of Busy Queues==������������������ ������������������������������������
#-----------------------------

#File: env/templates/submenuDesign.template
#---------------------------
>Appearance<==>�������������� ������<
>Language<==>��������<
Search Page Layout==���������� ���������������� ������������
Design==������������������ ������������
#-----------------------------

#File: env/templates/submenuPortalConfiguration.template
#---------------------------
Search Box Anywhere==�������� ������������
Generic Search Portal==���������������� ������������ ������������
User Profile==�������������� ������������������������
Local robots.txt==������������������ robots.txt
Portal Configuration==�������������������� ������������
#-----------------------------

#File: env/templates/submenuUseCaseAccount.template
#---------------------------
Use Case &amp; Accounts==�������������� ������������ �� ���������������� �������������������������� YaCy
Basic Configuration==���������������� ������������������
>Accounts<==>�������������� ������������<
#---------------------------



#File: env/templates/submenuRanking.template
#---------------------------
Solr Ranking Config==������������������������ Solr
RWI Ranking Config==������������������������ RWI
>Heuristics<==>������������������<
Ranking and Heuristics==������������������������ �� ������������������
#-----------------------------


#File: env/templates/submenuContentIntegration.template
#---------------------------
External Content Integration==�������������������� ���������������� ����������������
Import phpBB3 forum==������������ ������������ phpBB3
Import Mediawiki dumps==������������ ������������ Mediawiki
Import OAI-PMH Sources==������������ OAI-PMH ��������������������
#-----------------------------

#-----------------------------

#File: env/templates/submenuCrawlMonitor.template
#---------------------------
Overview</a>==����������</a>
Receipts</a>==������������������ ����������������������������</a>
Queries</a>==��������������</a>
DHT Transfer==DHT-����������������
Proxy Use==�������������������������� ������������
Local Crawling</a>==������������������ ����������������������������</a>
Global Crawling</a>==�������������������� ����������������������������</a>
Surrogate Import</a>==�������������������� ������������</a>
Crawl Results==�������������������� ����������������������������
Processing Monitor==�������������� ������������������
Crawler Queues==�������������� ����������������������������
Web==
Crawler<==��������������������<
Loader<==���������������������� ������������<
Rejected URLs==���������������������� ������������
>Queues<==>��������������<
Local<==������������������<
Global==��������������������
Remote==������������������
No-Load==����������������
Crawler Steering==�������������������� ������������������������
Scheduler and Profile Editor<==���������������������� �� ���������������� ��������������<
robots.txt Monitor==�������������� robots.txt
#-----------------------------

#File: env/templates/submenuIndexControl.template
#---------------------------
Index Administration==�������������������� ����������������
URL Database Administration==�������������������� ���������� ������������ ��������������
Index Deletion==���������������� ��������������
Index Sources &amp; Targets==������������ �������������������� �� ����������
Solr Schema Editor==���������������� ���������� Solr
Field Re-Indexing==����������������������������
Reverse Word Index==���������������� ������������ ��������
Index Cleaner==�������������� ��������������
Content Analysis==������������ ����������������������
Web Cache==������-������
Parser Configuration==������������������������ ��������������
#-----------------------------

#File: env/templates/submenuIndexCreate.template
#---------------------------
Web Crawler Control==�������������������� ������-������������������������
Start a Web Crawl==������������ ������-����������������������
#Crawl Start==������������ ����������������������������
Crawl Profile Editor==������������������ �������������� ����������������������
Crawler Queues==�������������� ����������������������
Indexing<==����������������������������<
Full Site Crawl/ Sitemap Loader==���������������������������� ����������/���������������� ���������� ����������
Loader<==������������������<
URLs to be processed==���������������������� URL-������������
Processing Queues==������������������ ����������������
Local<==������������������<
Global<==��������������������<
#Remote<==������������������<
Overhang<==��berhang<
Media Crawl Queues==�������������� ���������������������������� ����������-������������
>Images==>����������������
>Movies==>������������
>Music==>������������
#--- New menu items ---
Index Creation==���������������� ��������������
Crawler/Spider<==��������������������<
Crawl Start \(Expert\)==���������������������� ����������������������������
Network Scanner==������������ ��������
#>Intranet<br/>Scanner<==>������������<br/>����������������<
Crawling of MediaWikis==���������������������������� MediaWiki
>Crawling of phpBB3 Forums<==>���������������������������� phpBB3�����������������<
Content Import<==������������ ����������������<
Network Harvesting<==�������� ����������������������������<
Remote Crawling==������������������ ����������������������������
Scraping Proxy==�������������������� ������������
>Database Reader<==>������������������������ ������ ������������<
#for phpBB3 Forums==������ �������������� phpBB3
Advanced Crawler==���������������������� ��������������������
#-----------------------------

#File: env/templates/submenuSemantic.template
#---------------------------
Content Semantic==�������������������������� ��������������
# Subemenu: Automated Annotation
>Automated Annotation<==>���������������������������� ������������������������������<
Auto-Annotation Vocabulary Editor==���������������� �������������� ��������-������������������������������
Knowledge Loader==���������������� ����������������
# Submenu Augmented Content
>Augmented Content<==>���������������������� ��������������<
Augmented Browsing==���������������������� ����������������
Filters and Modules==�������������� �� ������������
Augmented Parsing==���������������������� ������������
#-----------------------------

#File: env/templates/submenuTargetAnalysis.template
#---------------------------
Target Analysis==������������ ��������
Robots.txt Database==�������� ������������ Robots.txt
Mass Crawl Check==���������������� ���������������� ����������������������������
Regex Test==�������� ���������������������� ������������������
#-----------------------------

#File: env/templates/submenuPublication.template
#---------------------------
Publication==��������������������
#Wiki==Wiki
#Blog==��������
File Hosting==�������������� ������������
#-----------------------------

#File: env/templates/submenuSearchConfiguration.template
#---------------------------
Integrated Search Configuration==������������������������ �������������������������������� ������������
#-----------------------------

#File: env/templates/submenuViewLog.template
#---------------------------
Server Log Menu==�������� �������� ��������������
Server Log==������ ��������������
#-----------------------------

#File: env/templates/submenuWebStructure.template
#---------------------------
Web Visualization==���������������� ��������������
Web Structure==������-������������������
Image Collage==������������ ����������������������
Index Browser==���������������� ������������
#-----------------------------

#File: proxymsg/authfail.inc
#---------------------------
Your Username/Password is wrong.==���������� ��/������ ������������ ����������������.
Username</label>==����������</label>
Password</label>==������������</label>
"login"=="����������"
#-----------------------------

#File: proxymsg/error.html
#---------------------------
YaCy: Error Message==YaCy: ������������������ ���� ������������
request:==������������:
unspecified error==���������������������� ������������
not-yet-assigned error==��������-����-���������������������� ������������
You don't have an active internet connection. Please go online.==�� ������ ������ ������������������ �������������������� �� ����������������. ��������������������, ������������������������ �� ������������������.
Could not load resource. The file is not available.==���� �������� ������������������ ������������. �������� ��������������������.
Exception occurred==������������������ ��������������������
Generated \#\[date\]\# by==��������������������������: #[date]#
#-----------------------------

#File: proxymsg/proxylimits.inc
#---------------------------
Your Account is disabled for surfing.==������������ ���������������� ���������������� ����������������.
Your Timelimit \(\#\[timelimit\]\# Minutes per Day\) is reached.==������ ������������������ ���������� (#[timelimit]# ���������� �� ��������) ����������������.
#-----------------------------

#File: proxymsg/unknownHost.inc
#---------------------------
The server==������������
could not be found.==���� ������������.
Did you mean:==���� ���������� ����������:
#-----------------------------

#File: www/welcome.html
#---------------------------
YaCy: Default Page for Individual Peer Content==YaCy: ���������������� ����-������������������ ������ ���������������� ��������
Individual&nbsp;Web&nbsp;Page==������������ ������-����������������
Welcome to your own web page<br />in the <strong>YaCy Network==���������� �������������������� ���� �������� ������-����������������<br />im <strong>�� �������� YaCy
THIS IS A DEMONSTRATION PAGE FOR YOUR OWN INDIVIDUAL WEB SERVER!==������ �������������������������������� ���������������� ������ ������������ �������������� ������-��������������!
PLEASE REPLACE THIS PAGE BY PUTTING A FILE index.html INTO THE PATH==BITTE ERSETZEN SIE DIESE SEITE, INDEM SIE EINE DATEI MIT DEM NAMEN index.html IM VERZEICHNIS
&lt;YaCy-application-home&gt;<strong>\#\[wwwpath\]\#</strong>==&lt;YaCy-Programmpfad&gt;<strong>#[wwwpath]#</strong> ABLEGEN.
#-----------------------------

#File: js/Crawler.js
#---------------------------
"Continue this queue"=="������������������ ������ ��������������"
"Pause this queue"=="�������������������������� ������ ��������������"
#-----------------------------

#File: js/yacyinteractive.js
#---------------------------
>total results==>���������� ����������������������
&nbsp;topwords:==&nbsp;Topw��rter:
>Name==>����������������
>Size==>������������
>Date==>��������
#-----------------------------

#File: yacy/ui/js/jquery-flexigrid.js
#---------------------------
'Displaying \{from\} to \{to\} of \{total}\ items'=='������������������ {from} ���� {to} ���� {total} ������������������'
'Processing, please wait ...'=='������������������, ��������������������, ������������������ ...'
'No items'=='������ ����������������'
#-----------------------------

#File: yacy/ui/js/jquery-ui-1.7.2.min.js
#---------------------------
Loading&#8230;==����������������&#8230;
#-----------------------------

#File: yacy/ui/js/jquery.ui.all.min.js
#---------------------------
Loading&#8230;==����������������&#8230;
#-----------------------------

#File: yacy/ui/index.html
#---------------------------
About YaCy-UI==�� YaCy
Admin Console==�������������� ����������������������������
"Bookmarks"=="����������������"
>Bookmarks==>����������������
Server Log==������ ��������������
#-----------------------------

#File: yacy/ui/yacyui-admin.html
#---------------------------
Peer Control==�������������������� ������������
"Login"=="����������"
#Login==����������
Themes==��������
Messages==������������������
Re-Start==��������������������
Shutdown==��������������������
Web Indexing==������-����������������������������
Crawl Start==������������ ����������������������
Monitoring==��������������������
YaCy Network==�������� YaCy
>Settings==>������������������
"Basic Settings"=="���������������� ������������������"
\tBasic==����������������
Accounts==�������������� ������������
"Network"=="��������"
\tNetwork==��������
"Advanced Settings"=="���������������������� ������������������"
\tAdvanced==����������������������
"Update Settings"=="������������������ ��������������������"
\tUpdate==����������������������
>YaCy Project==>������������ YaCy
"YaCy Project Home"=="���������������� ���������������� YaCy"
\tProject==������������
"YaCy Statistics"=="YaCy ��������������������"
\tStatistics==��������������������
"YaCy Forum"=="���������� YaCy"
#Forum==����������
"Help"=="������������"
#"YaCy Wiki"=="YaCy Wiki"
#Wiki==Wiki
#-----------------------------

#File: yacy/ui/yacyui-bookmarks.html
#---------------------------
'Add'=='����������������'
'Crawl'=='��������������������'
'Edit'=='����������������'
'Delete'=='��������������'
'Rename'=='��������������������������'
'Help'=='��������������������������'

#"public bookmark"=="������������������ ����������������"
#"private bookmark"=="������������ ����������������"

#"delete bookmark"=="�������������� ����������������"
"YaCy Bookmarks"=="YaCy ����������������"
#>Title==>������������������
>Tags<==>��������<
#>Date==>��������
#'Hash'=='������'
'Public'=='����������'
'Title'=='������������������'
'Tags'=='��������'
'Folders'=='����������'
'Date'=='��������'
#-----------------------------

#File: yacy/ui/sidebar/sidebar_1.html
#---------------------------
YaCy P2P Websearch==YaCy P2P ����������
"Search"=="����������"
>Text==>����������
>Images==>����������������������
>Audio==>����������
>Video==>����������
>Applications==>��������������������
Search term:==�������������� ������������:
"help"=="������������"
Resource/Network:==������������/��������:
freeworld==freeworld
local peer==������������������ ��������
>bookmarks==>����������������
sciencenet==ScienceNet
>Language:==>��������:
any language==���������� ��������
Bookmark Folders==���������� ����������������
#-----------------------------

#File: yacy/ui/sidebar/sidebar_2.html
#---------------------------
Bookmark Tags<==���������������� �� ��������<
Search Options==���������� ������������
Constraint:==Einschr��nkungen:
all pages==������ ����������������
index pages==������������������������������������ ����������������
URL mask:==������������ URL-��������������:
Prefer mask:==�������������������������������� ������������:
Bookmark TagCloud==Lesezeichen TagWolke
Topwords<==Top W��rter<
alt="help"==alt="������������"
title="help"==title="������������"
#-----------------------------

#File: yacy/ui/yacyui-welcome.html
#---------------------------
>Overview==>����������
YaCy-UI is going to be a JavaScript based client for YaCy based on the existing XML and JSON API.==YaCy-UI wird ein in JavaScript geschriebener Client f��r YaCy, der auf der existierenden XML und JSON API aufbaut.
YaCy-UI is at most alpha status, as there is still problems with retriving the search results.==YaCy-UI ist bestenfalls im Alpha Stadium, da es immer noch Probleme beim Abholen der Suchergebnisse gibt.
I am currently changing the backend to a more application friendly format and getting good results with it \(I will check that in some time after the stable release 0.7\).==Ich ��ndere gerade das Backend in ein andwendungsfreundlicheres Format und bekomme gute Ergebnisse damit (Ich werde die ��nderungen einige Zeit nach der Ver��ffentlichung der stabilen Version 0.7 einchecken).
For now have a look at the bookmarks, performance has increased significantly, due to the use of JSON and Flexigrid!==Aktuell k��nnen Sie sich die Lesezeichen ansehen - Die Performance hat sich signifikant gebessert durch die Verwendung von JSON und Flexigrid!
#-----------------------------

#File: api/citation.html
#---------------------------
Document Citations for==������������ ������������������ ������
List of Sentences in==������������ ���������������������� ��
List of other web pages with citations==������������ ������������ ������-�������������� �� ����������������
#-----------------------------



# EOF
